{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Corgi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1zOzImggTR7FFFYu72MdiYvEzKhpyjTP5",
      "authorship_tag": "ABX9TyPCuApNwOeecETBlXTdCxRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konkuk-gaegul/3rd-Team-Project/blob/main/TensorFlow_Corgi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 웰시코기 수집 담당\n"
      ],
      "metadata": {
        "id": "Xae9UD6ZWt1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|이미지 세트|비만|정상|총 합|\n",
        "|------|---|---|----|\n",
        "|1차 수집|579|408|987|\n",
        "|2차 수집|617|624|1241|\n"
      ],
      "metadata": {
        "id": "ynelvawmD6ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 웰시코기 1차 이미지 수집\n",
        "- 웹 크롤링을 활용하여 약 6,000여 장 확보\n",
        "- 수기로 학습에 사용할 수 있는 이미지 1,000장 선정\n",
        "- 비만:정상 = 4:6 비율로 이미지 세트 분류\n",
        "    - 기존 목표 5:5 수집의 한계 존재\n",
        "        - 일반적으로 비만견 개체가 적은 편\n",
        "        - 크롤링 이미지에 중복된 자료 존재"
      ],
      "metadata": {
        "id": "8r_uL7S1t93U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 지도학습\n",
        "- Keras CNN으로 학습\n",
        "    - 강의 교안과 딥러닝 책에서 배운 신경 네트워크와 parameter 사용\n",
        "    - 이미지 전처리\n",
        "        - 스케일링과 이미지 증식\n",
        "        - 이미지 증식은 훈련용 자료에만 적용!\n",
        "- 정상 579장, 비만 408장\n",
        "- 구글 코랩 GPU 활용하여 학습\n",
        "- train / validation / test : 50% / 20% / 30% 비율로 세트 분할"
      ],
      "metadata": {
        "id": "HrHBBuoWcH4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9qyd_hgJ53x",
        "outputId": "4679cd04-bf29-4570-8221-70462240d45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R8O3amPJ8I8",
        "outputId": "f1ed9378-1293-46db-f028-533a7ecbfec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "941c639a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os, sys, json, cv2, shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e3de5b3",
        "outputId": "169f5cb6-ba5d-44c6-8f0f-99ef8d2d6308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/lab13/웰시코기/set_2\r\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc7eaa20",
        "outputId": "ffaeb9b9-71f2-4068-b211-bc7f3ba5bdee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/lab13/dog_pic/웰시코기\n"
          ]
        }
      ],
      "source": [
        "%cd dog_pic/웰시코기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04fbdd9e",
        "outputId": "d9fe85be-1f9b-45d1-af8a-76c0a709887a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/lab13\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51814022",
        "outputId": "8efc3345-e77c-4662-c9da-c7af2efa29a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "웰시코기_set_1\t웰시코기_set_1.zip  웰시코기_set_2  웰시코기_set_2.zip\r\n"
          ]
        }
      ],
      "source": [
        "!dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06da098f"
      },
      "source": [
        "# 웰시코기 학습 1\n",
        "- 기본 이미지 전처리\n",
        "    - 스케일링, 이미지 사이즈 통합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb022f4e",
        "outputId": "86d71f35-8fd5-4408-9970-b62d032e8600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "579\n",
            "408\n"
          ]
        }
      ],
      "source": [
        "base_dir = '/content/drive/MyDrive/3조/Dog_Pic/전처리 이미지(학습용)/리트리버/set_1'\n",
        "\n",
        "# 학습 이미지 경로\n",
        "nor_path = os.path.join(base_dir, '전처리_정상')\n",
        "fat_path = os.path.join(base_dir, '전처리_비만')\n",
        "\n",
        "nor_list = os.listdir(nor_path)\n",
        "fat_list = os.listdir(fat_path)\n",
        "\n",
        "print(len( nor_list ))\n",
        "print(len( fat_list ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7be8b82"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/3조/Dog_Pic/전처리 이미지(학습용)/리트리버/set_1'\n",
        "\n",
        "# # 훈련셋, 검증셋, 테스트셋을 미리 분할하기 위한 폴더 경로\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "# os.mkdir( train_path)/\n",
        "\n",
        "val_path = os.path.join(base_dir, 'validation')\n",
        "# os.mkdir( val_path)\n",
        "\n",
        "test_path = os.path.join(base_dir, 'test')\n",
        "# os.mkdir( test_path)\n",
        "\n",
        "\n",
        "# # train 정상 폴더\n",
        "train_nor_path = os.path.join(train_path, 'nor')\n",
        "# os.mkdir( train_nor_path)\n",
        "\n",
        "# # train 비만 폴더\n",
        "train_fat_path = os.path.join(train_path, 'fat')\n",
        "# os.mkdir( train_fat_path)\n",
        "\n",
        "# # validation 정상 폴더\n",
        "val_nor_path = os.path.join(val_path, 'nor')\n",
        "# os.mkdir( val_nor_path)\n",
        "\n",
        "# # validation 비만 폴더\n",
        "val_fat_path = os.path.join(val_path, 'fat')\n",
        "# os.mkdir( val_fat_path)\n",
        "\n",
        "# # test 정상 폴더\n",
        "test_nor_path = os.path.join(test_path, 'nor')\n",
        "# os.mkdir( test_nor_path)\n",
        "\n",
        "# # test 비만 폴더\n",
        "test_fat_path = os.path.join(test_path, 'fat')\n",
        "# os.mkdir( test_fat_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c955a796",
        "outputId": "9c566651-54d2-4fde-9240-b6906eb588db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set : 493\n",
            "validation set : 247\n",
            "test set : 247\n",
            "total set : 987\n"
          ]
        }
      ],
      "source": [
        "print(f'train set : {len(os.listdir(train_nor_path)) + len(os.listdir(train_fat_path))}')\n",
        "print(f'validation set : {len(os.listdir(val_nor_path)) + len(os.listdir(val_fat_path))}')\n",
        "print(f'test set : {len(os.listdir(test_nor_path)) + len(os.listdir(test_fat_path))}')\n",
        "print(f'total set : {len(nor_list) + len(fat_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "674c2896"
      },
      "source": [
        "## 이미지 전처리\n",
        "- 스케일링, 이미지 크기 조정\n",
        "- 학습 자료 수가 부족하다고 느낌\n",
        "    - 이미지 증식 활용\n",
        "        - 상/하, 좌/우 평행이동 및 수평 반전\n",
        "- batch_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a474483"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d00df8ff",
        "outputId": "cc69b980-985b-41dc-b702-43c86b6e71b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 493 images belonging to 2 classes.\n",
            "Found 247 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 데이터의 경로\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/3조/Dog_Pic/전처리 이미지(학습용)/리트리버/set_1'\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "val_path = os.path.join(base_dir, 'validation')\n",
        "test_path = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "# 모든 이미지의 픽셀값을 스케일링\n",
        "# 학습 이미지를 생성\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  rotation_range = 40,\n",
        "  width_shift_range= 0.3,\n",
        "  height_shift_range=0.3,\n",
        "  shear_range=0.3,\n",
        "  zoom_range=0.3,\n",
        "  horizontal_flip=True,\n",
        ")\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  target_size = (500, 500),\n",
        "  batch_size = 10,\n",
        "  class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "  val_path,\n",
        "  target_size = (500, 500),\n",
        "  batch_size = 10,\n",
        "  class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0254fcc9"
      },
      "source": [
        "## 네트워크 구성\n",
        "- Conv2D와 MaxPooling2D 층을 쌓아 올림\n",
        "- 첫 번째 층의 매개변수로 input_shape=(500, 500, 3)을 전달\n",
        "- 마지막 층에서 (29, 29, 128)크기인 출력 텐서를 완전 연결 네트워크에 주입\n",
        "- Flatten을 통해 1D텐서로 변환하여 Dense층에 1D 텐서 입력\n",
        "- 2개 클래스(비만, 정상)를 분류하기 위해 마지막 Dense층의 크기를 1로 설정 및 softmax 활성화 함수를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99eed944"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Convolution Layer\n",
        "model.add( tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(500, 500, 3)))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "# feature map -> input\n",
        "model.add( tf.keras.layers.Flatten() )\n",
        "\n",
        "# Neural Network\n",
        "model.add( tf.keras.layers.Dense(512, activation='relu') ) # hidden layer\n",
        "model.add( tf.keras.layers.Dense(1, activation='sigmoid') )# output layer\n",
        "\n",
        "# optimaze\n",
        "model.compile(\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['acc'],\n",
        "  optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C09KjzFRLVz3",
        "outputId": "0951ab98-7dcc-406f-c726-1c62277ff2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 498, 498, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 249, 249, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 247, 247, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 123, 123, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 121, 121, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 60, 60, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 58, 58, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 29, 29, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 107648)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               55116288  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,357,633\n",
            "Trainable params: 55,357,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "876cc8d4"
      },
      "source": [
        "## 학습 진행\n",
        "- 데이터 셋 자체가 적어서 큰 수의 parameter를 적용할 수 없음\n",
        "- train 수 / batch_size = steps_per_epoch가 적당해 보임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53604aee",
        "outputId": "1532466b-6b93-4d8a-b1b7-13b1a7629a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 27s 826ms/step - loss: 0.7307 - acc: 0.5633 - val_loss: 0.6666 - val_acc: 0.6150\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 0.6846 - acc: 0.5631 - val_loss: 0.6765 - val_acc: 0.5900\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 22s 723ms/step - loss: 0.7010 - acc: 0.5400 - val_loss: 0.6855 - val_acc: 0.5600\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 22s 714ms/step - loss: 0.6965 - acc: 0.5700 - val_loss: 0.6855 - val_acc: 0.5600\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 22s 724ms/step - loss: 0.6780 - acc: 0.5967 - val_loss: 0.6779 - val_acc: 0.5850\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 22s 734ms/step - loss: 0.6948 - acc: 0.5939 - val_loss: 0.6763 - val_acc: 0.5800\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 23s 779ms/step - loss: 0.7040 - acc: 0.5933 - val_loss: 0.6691 - val_acc: 0.6000\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 22s 757ms/step - loss: 0.6774 - acc: 0.5904 - val_loss: 0.6761 - val_acc: 0.5800\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 21s 710ms/step - loss: 0.6932 - acc: 0.5666 - val_loss: 0.6815 - val_acc: 0.5800\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 22s 723ms/step - loss: 0.7020 - acc: 0.5867 - val_loss: 0.6729 - val_acc: 0.5750\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 22s 717ms/step - loss: 0.6957 - acc: 0.5631 - val_loss: 0.6629 - val_acc: 0.6050\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 22s 736ms/step - loss: 0.6830 - acc: 0.5973 - val_loss: 0.6610 - val_acc: 0.6200\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 22s 732ms/step - loss: 0.6759 - acc: 0.5734 - val_loss: 0.6743 - val_acc: 0.5900\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 22s 734ms/step - loss: 0.6842 - acc: 0.5867 - val_loss: 0.6769 - val_acc: 0.6100\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 22s 726ms/step - loss: 0.6686 - acc: 0.5939 - val_loss: 0.6700 - val_acc: 0.5750\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 22s 734ms/step - loss: 0.6758 - acc: 0.5900 - val_loss: 0.6690 - val_acc: 0.6100\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 21s 707ms/step - loss: 0.6769 - acc: 0.5700 - val_loss: 0.6620 - val_acc: 0.6300\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 22s 725ms/step - loss: 0.6680 - acc: 0.6167 - val_loss: 0.6702 - val_acc: 0.6150\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 22s 719ms/step - loss: 0.6710 - acc: 0.5802 - val_loss: 0.7258 - val_acc: 0.5650\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 23s 763ms/step - loss: 0.6575 - acc: 0.6246 - val_loss: 0.6628 - val_acc: 0.6050\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 24s 790ms/step - loss: 0.6724 - acc: 0.6167 - val_loss: 0.6724 - val_acc: 0.5800\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 22s 738ms/step - loss: 0.6707 - acc: 0.5802 - val_loss: 0.6698 - val_acc: 0.5850\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 22s 722ms/step - loss: 0.6785 - acc: 0.5870 - val_loss: 0.6664 - val_acc: 0.5900\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 22s 730ms/step - loss: 0.6660 - acc: 0.6075 - val_loss: 0.6812 - val_acc: 0.5650\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 22s 734ms/step - loss: 0.6738 - acc: 0.5867 - val_loss: 0.6621 - val_acc: 0.5950\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 22s 714ms/step - loss: 0.6422 - acc: 0.6348 - val_loss: 0.6713 - val_acc: 0.6050\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 22s 730ms/step - loss: 0.6726 - acc: 0.6433 - val_loss: 0.6684 - val_acc: 0.5850\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 22s 729ms/step - loss: 0.6829 - acc: 0.6075 - val_loss: 0.6718 - val_acc: 0.5850\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 23s 750ms/step - loss: 0.6816 - acc: 0.5768 - val_loss: 0.6671 - val_acc: 0.6050\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 23s 779ms/step - loss: 0.6742 - acc: 0.6067 - val_loss: 0.6537 - val_acc: 0.6000\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch = 30,\n",
        "  epochs = 30,\n",
        "  validation_data = val_generator,\n",
        "  validation_steps= 20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37f0fb82"
      },
      "source": [
        "### loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "188fd628",
        "outputId": "f16158cd-cfbe-44a1-f895-15072a928a83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9cb3ebae10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot( hist.history['loss'], label='train loss')\n",
        "plt.plot( hist.history['val_loss'], label='validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5e2de60"
      },
      "source": [
        "### accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "8b04552b",
        "outputId": "e132e0d5-b4f7-466e-dc96-fcee3f01be4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9cb3e1d990>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot( hist.history['acc'], label='train accuracy')\n",
        "plt.plot( hist.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 웰시코기 학습 1 후기\n",
        "- 앞으로 생성할 모델의 기준점이 될 첫 학습\n",
        "- 로스와 정확도 모두 개선되는 모습을 보이지 않는다.\n",
        "- 들쭉 날쭉한 모형으로 학습이 제대로 이루어지지 않는 것으로 보인다.\n",
        "- 2차 이미지 수집 필요성을 느낌"
      ],
      "metadata": {
        "id": "GjE4scXWk_yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 웰시코기 2차 이미지 수집\n",
        "- 합계 1241장\n",
        "- SNS와 지인들의 반려견 이미지 수집\n",
        "- 수기로 비만/정상 이미지 분류\n",
        "- 정상 : 617장, 비만 : 624장 으로 균형있는 세트를 구성"
      ],
      "metadata": {
        "id": "1c-dA7epuErF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 웰시코기 학습 2"
      ],
      "metadata": {
        "id": "6ZVsUFF6xH-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "a0bef63d-b0ba-4661-dcf4-52a090a0c374",
        "id": "twUY8hmevSm9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "617\n",
            "624\n"
          ]
        }
      ],
      "source": [
        "base_dir = '/home/lab13/dog_pic/웰시코기/웰시코기_set_2'\n",
        "\n",
        "# 학습 이미지 경로\n",
        "nor_path = os.path.join(base_dir, '웰시코기_정상')\n",
        "fat_path = os.path.join(base_dir, '웰시코기_비만')\n",
        "\n",
        "nor_list = os.listdir(nor_path)\n",
        "fat_list = os.listdir(fat_path)\n",
        "\n",
        "print(len( nor_list ))\n",
        "print(len( fat_list ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJdw-ekovSnF"
      },
      "outputs": [],
      "source": [
        "base_dir = '/home/lab13/dog_pic/웰시코기/웰시코기_set_2'\n",
        "\n",
        "# # 훈련셋, 검증셋, 테스트셋을 미리 분할하기 위한 폴더 경로\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "# os.mkdir( train_path)/\n",
        "\n",
        "val_path = os.path.join(base_dir, 'validation')\n",
        "# os.mkdir( val_path)\n",
        "\n",
        "test_path = os.path.join(base_dir, 'test')\n",
        "# os.mkdir( test_path)\n",
        "\n",
        "\n",
        "# # train 정상 폴더\n",
        "train_nor_path = os.path.join(train_path, 'nor')\n",
        "# os.mkdir( train_nor_path)\n",
        "\n",
        "# # train 비만 폴더\n",
        "train_fat_path = os.path.join(train_path, 'fat')\n",
        "# os.mkdir( train_fat_path)\n",
        "\n",
        "# # validation 정상 폴더\n",
        "val_nor_path = os.path.join(val_path, 'nor')\n",
        "# os.mkdir( val_nor_path)\n",
        "\n",
        "# # validation 비만 폴더\n",
        "val_fat_path = os.path.join(val_path, 'fat')\n",
        "# os.mkdir( val_fat_path)\n",
        "\n",
        "# # test 정상 폴더\n",
        "test_nor_path = os.path.join(test_path, 'nor')\n",
        "# os.mkdir( test_nor_path)\n",
        "\n",
        "# # test 비만 폴더\n",
        "test_fat_path = os.path.join(test_path, 'fat')\n",
        "# os.mkdir( test_fat_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "760bbfb4-be6e-46db-a2fc-9363a4e0cc00",
        "id": "iCtqXzPJvSnF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set : 620\n",
            "validation set : 247\n",
            "test set : 374\n",
            "total set : 1241\n"
          ]
        }
      ],
      "source": [
        "print(f'train set : {len(os.listdir(train_nor_path)) + len(os.listdir(train_fat_path))}')\n",
        "print(f'validation set : {len(os.listdir(val_nor_path)) + len(os.listdir(val_fat_path))}')\n",
        "print(f'test set : {len(os.listdir(test_nor_path)) + len(os.listdir(test_fat_path))}')\n",
        "print(f'total set : {len(nor_list) + len(fat_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUr9gW7yvSnF"
      },
      "source": [
        "## 이미지 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2_85EGCvSnF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "141eccdf-c657-47a9-ad3f-3bd03d1c03ff",
        "id": "mI5xcYbbvSnF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 620 images belonging to 2 classes.\n",
            "Found 247 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 데이터의 경로\n",
        "\n",
        "base_dir = '/home/lab13/dog_pic/웰시코기/웰시코기_set_2'\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "val_path = os.path.join(base_dir, 'validation')\n",
        "test_path = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "# 모든 이미지의 픽셀값을 스케일링\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  target_size = (300, 300),\n",
        "  batch_size = 15,\n",
        "  class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "  val_path,\n",
        "  target_size = (300, 300),\n",
        "  batch_size = 15,\n",
        "  class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuSJgyT5vSnG"
      },
      "source": [
        "## 네트워크 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "b6c6aa20-6819-4cf7-e795-2732dedf0580",
        "id": "Nb4W0wGEvSnG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 15:12:42.680037: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-25 15:12:42.681145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-25 15:12:42.706577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 15:12:42.706920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-03-25 15:12:42.706944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-25 15:12:42.710176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-25 15:12:42.710269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-25 15:12:42.713204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-25 15:12:42.713592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-25 15:12:42.715577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-25 15:12:42.716317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-25 15:12:42.717484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-25 15:12:42.717629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 15:12:42.718012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 15:12:42.718287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-03-25 15:12:42.718634: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-25 15:12:42.718828: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-25 15:12:42.718970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 15:12:42.719278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-03-25 15:12:42.719295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-25 15:12:42.719316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-25 15:12:42.719327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-25 15:12:42.719339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-25 15:12:42.719350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-25 15:12:42.719361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-25 15:12:42.719373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-25 15:12:42.719384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-25 15:12:42.719445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 15:12:42.719781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 15:12:42.720054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-03-25 15:12:42.720083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_15815/2755452703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convolution Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Skip the init in FunctionalModel since model doesn't have input/output yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call\n\u001b[0;32m--> 118\u001b[0;31m         name=name, autocast=False)\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sequential'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_batch_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_model_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_init_batch_counters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# `evaluate`, and `predict`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariableAggregationV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONLY_FIRST_REPLICA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     self._predict_counter = variables.Variable(\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         shape=None):\n\u001b[1;32m    236\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m       shape=shape)\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1717\u001b[0m             initial_value = ops.convert_to_tensor(initial_value,\n\u001b[1;32m   1718\u001b[0m                                                   \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"initial_value\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m                                                   dtype=dtype)\n\u001b[0m\u001b[1;32m   1720\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m           \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextOptionsSetTfrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Convolution Layer\n",
        "model.add( tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "# feature map -> input\n",
        "model.add( tf.keras.layers.Flatten() )\n",
        "\n",
        "# Neural Network\n",
        "model.add( tf.keras.layers.Dense(512, activation='relu') ) # hidden layer\n",
        "model.add( tf.keras.layers.Dense(1, activation='sigmoid') )# output layer\n",
        "\n",
        "# optimaze\n",
        "model.compile(\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['acc'],\n",
        "  optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O2jKr3EvSnG"
      },
      "source": [
        "## 학습 진행\n",
        "- 학습 추세를 빠르게 알아보기 위해 epoch = 20으로 설정\n",
        "- 늘어난 학습/검증 자료 수 만큼 steps 또한 증가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "outputId": "fe0cab4d-25c2-45f6-9a34-b1cd1c7f5f4e",
        "id": "NSGU1l9NvSnG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 14:41:28.374492: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-03-25 14:41:28.391864: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 14:41:29.066299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-25 14:41:29.598871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-25 14:41:29.606008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 13s 214ms/step - loss: 0.7373 - acc: 0.5116 - val_loss: 0.6829 - val_acc: 0.5333\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.6673 - acc: 0.6168 - val_loss: 0.6212 - val_acc: 0.6578\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 7s 180ms/step - loss: 0.6114 - acc: 0.6798 - val_loss: 0.6093 - val_acc: 0.6622\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 7s 181ms/step - loss: 0.5421 - acc: 0.7127 - val_loss: 0.6009 - val_acc: 0.6711\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 7s 181ms/step - loss: 0.5308 - acc: 0.7366 - val_loss: 0.6301 - val_acc: 0.6756\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.5226 - acc: 0.7380 - val_loss: 0.5960 - val_acc: 0.6889\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.4456 - acc: 0.8203 - val_loss: 0.6071 - val_acc: 0.7111\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 7s 179ms/step - loss: 0.4275 - acc: 0.8434 - val_loss: 0.6669 - val_acc: 0.6622\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 7s 178ms/step - loss: 0.3848 - acc: 0.8393 - val_loss: 0.6245 - val_acc: 0.6844\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 7s 182ms/step - loss: 0.3801 - acc: 0.8173 - val_loss: 0.6969 - val_acc: 0.6667\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 7s 182ms/step - loss: 0.3314 - acc: 0.8642 - val_loss: 0.7919 - val_acc: 0.6667\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 7s 178ms/step - loss: 0.3183 - acc: 0.8848 - val_loss: 0.7923 - val_acc: 0.6667\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 7s 181ms/step - loss: 0.2702 - acc: 0.9000 - val_loss: 0.8903 - val_acc: 0.6444\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.2533 - acc: 0.9077 - val_loss: 0.7947 - val_acc: 0.6711\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.2162 - acc: 0.9174 - val_loss: 0.9402 - val_acc: 0.6578\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 7s 180ms/step - loss: 0.2064 - acc: 0.9179 - val_loss: 0.9871 - val_acc: 0.6489\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 7s 180ms/step - loss: 0.1673 - acc: 0.9358 - val_loss: 1.1778 - val_acc: 0.6400\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 7s 183ms/step - loss: 0.1387 - acc: 0.9476 - val_loss: 1.3591 - val_acc: 0.6178\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 7s 183ms/step - loss: 0.1379 - acc: 0.9610 - val_loss: 1.0771 - val_acc: 0.6489\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 7s 179ms/step - loss: 0.1153 - acc: 0.9669 - val_loss: 1.1293 - val_acc: 0.6311\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch = 40,\n",
        "  epochs = 20,\n",
        "  validation_data = val_generator,\n",
        "  validation_steps= 15\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKUa7PKWvSnG"
      },
      "source": [
        "### loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "a0e8701d-adf9-41b4-9f83-2e542d98cf06",
        "id": "rqneqWOrvSnG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8c0e1b52d0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot( hist.history['loss'], label='train loss')\n",
        "plt.plot( hist.history['val_loss'], label='validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT-sgUOCvSnG"
      },
      "source": [
        "### accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "69236aa6-f12f-4e56-f566-895e2b6774ea",
        "id": "zSnsEhVbvSnG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8bec1a5ed0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2JElEQVR4nO3dd3hUZd7/8fedTkhIDyWF0BN6CYQuRaSooCCiawMLVtD1WXd9dHd11d21Py6/RVlUFF3qqjSXoiAISksILUDoJb1Bes/cvz/OJISQQAJJZjL5vq4rFzNzzsz5Zph8cnKfuyitNUIIIZo+O0sXIIQQon5IoAshhI2QQBdCCBshgS6EEDZCAl0IIWyEg6UO7Ovrq0NCQix1eCGEaJL27duXrrX2q26bxQI9JCSEqKgoSx1eCCGaJKXU+Zq2SZOLEELYCAl0IYSwERLoQghhIyzWhl6dkpIS4uPjKSwstHQpwkq4uLgQGBiIo6OjpUsRwupZVaDHx8fj7u5OSEgISilLlyMsTGtNRkYG8fHxdOjQwdLlCGH1rKrJpbCwEB8fHwlzAYBSCh8fH/mLTYhasqpAByTMxRXk8yBE7VldoAshhC0qLTMRfeES/9h8kqOJ2Q1yDKtqQ7e0zMxMli5dyjPPPFPn506aNImlS5fi6elZ/4UJIZqkCxn5bD+Zxi8n0/n1dDo5haUoBd5uTnRv16rejyeBXklmZiYff/xxtYFeWlqKg0PNb9f69esbsrQbprVGa42dnfwxJkRDyyooYdfpDHacTOOXU+mcz8gHIMCzBbf3asuILn4M7eSDV0unBjm+/JRX8vLLL3P69Gn69u3LSy+9xLZt2xgxYgSTJ0+me/fuANx1110MGDCAHj16sHDhwornhoSEkJ6ezrlz5wgLC+OJJ56gR48e3HbbbRQUFFx1rHXr1hEREUG/fv249dZbSUlJASA3N5dZs2bRq1cvevfuzbfffgvAxo0b6d+/P3369GHs2LEAvP7667z//vsVr9mzZ0/OnTvHuXPn6NatGw8//DA9e/YkLi6Op59+mvDwcHr06MFrr71W8ZzIyEiGDh1Knz59GDRoEDk5OYwcOZIDBw5U7DN8+HAOHjxYf2+0EDaitMxE1LmL/N+PJ5j68a/0e+MHnvr3PlbvT6CLvxt/mdyDLf9zC7/8YTRvT+vN7b3bNliYgxWfof9l3ZF6b2fq3q4Vr93Zo8btb7/9NjExMRVhtm3bNqKjo4mJianoNrdo0SK8vb0pKChg4MCBTJs2DR8fnyte5+TJkyxbtoxPP/2Ue++9l2+//ZYHH3zwin2GDx/O7t27UUrx2Wef8e677/LBBx/w5ptv4uHhweHDhwG4dOkSaWlpPPHEE2zfvp0OHTpw8eLF636vJ0+eZPHixQwePBiAv/71r3h7e1NWVsbYsWM5dOgQoaGhzJgxgxUrVjBw4ECys7Np0aIFjz32GF9++SUfffQRJ06coLCwkD59+tT6fRbClp3PyGP7iTR2nExn1+kMcopKsVPQK9CTZ0d3ZkQXP/oGeeLk0Pjny1Yb6NZi0KBBV/SBnjdvHqtWrQIgLi6OkydPXhXoHTp0oG/fvgAMGDCAc+fOXfW68fHxzJgxg6SkJIqLiyuOsXnzZpYvX16xn5eXF+vWrWPkyJEV+3h7e1+37vbt21eEOcDKlStZuHAhpaWlJCUlcfToUZRStG3bloEDBwLQqpXRpjd9+nTefPNN3nvvPRYtWsTMmTOvezwhbJXWmiOJ2fxwJJmNR5I5kZILGM0od/S53Izi6dpwZ961ZbWBfq0z6cbUsmXLitvbtm1j8+bN7Nq1C1dXV0aNGlVtH2lnZ+eK2/b29tU2ucyZM4cXX3yRyZMns23bNl5//fU61+bg4IDJZKq4X7mWynWfPXuW999/n8jISLy8vJg5c+Y1+3a7uroybtw41qxZw8qVK9m3b1+daxOiKSszafadv8TGmGR+OJpM/KUC7BSEh3jzpzu6MybUnxAfV6vrVmu1gW4J7u7u5OTk1Lg9KysLLy8vXF1diY2NZffu3Td8rKysLAICAgBYvHhxxePjxo1j/vz5fPTRR4DR5DJ48GCeeeYZzp49W9Hk4u3tTUhICN9//z0A0dHRnD17ttpjZWdn07JlSzw8PEhJSWHDhg2MGjWKbt26kZSURGRkJAMHDiQnJ4cWLVrg4ODA448/zp133smIESPw8vK64e9TiKaiqLSMnacz2BSTzOZjKaTnFuNkb8fwLr7MGdOZW8Na4+PmfP0XsiAJ9Ep8fHwYNmwYPXv2ZOLEidx+++1XbJ8wYQILFiwgLCyMbt26XdGkUVevv/4606dPx8vLizFjxlSE8R//+EeeffZZevbsib29Pa+99hpTp05l4cKFTJ06FZPJhL+/Pz/++CPTpk3jq6++okePHkRERNC1a9dqj9WnTx/69etHaGgoQUFBDBs2DAAnJydWrFjBnDlzKCgooEWLFmzevBk3NzcGDBhAq1atmDVr1g1/j0JYu7yiUrYdT2PTkWR+ik0lt6iUlk72jA71Z3yPNozq5oe7S9OZR0hprS1y4PDwcF11gYtjx44RFhZmkXrElRITExk1ahSxsbEW7/IonwtRny7mFbP5WAo/HElm+8l0iktNeLd0YlxYa8b3bM3QTr64ONpbuswaKaX2aa3Dq9smZ+jiKl999RWvvvoqH374ocXDXIj6UFhSxg9HU1i9P4GfT6RRZtIEeLbggYhgxvdoQ3h7Lxzsm/5nXQJdXOXhhx/m4YcftnQZQtwUk0mz+2wGq6IT2BCTTG5RKW09XHh8RAfu6NWOngGtrO6i5s2SQBdC2JSTKTl8tz+BNfsTSMwqpKWTPRN7tWVqvwAiOvpgb2dbIV6ZBLoQoslLzSlk7YFEVh9IICYhG3s7xYguvvxhYii3dW9DCyfrbROvTxLoQogmqaC4jB+OJvNddAK/nEqnzKTpFeDBn+/ozp192uHnbt1dDBuCBLoQwupprckuLCU9t4gLF/P5/mASG2OSyCsuo52HC0+O7Mjd/QLo0trd0qValAT6TXJzcyM3N5fExETmzp3LN998c9U+o0aN4v333yc8vNqeRgB89NFHzJ49G1dXV0Cm4xW2rzyk03KKSM81f+UUkZZbRHpO8eXHcotJyy2iuPTyqGh3Zwdu792Wu/sFEtHBGzsbbhevCwn0etKuXbtqw7y2PvroIx588MGKQLfW6XhrItP0iuspb+feGJNMYmYB6bnFFJeZrtrP3k7h3dIJXzdnfN2c6OTvhp+bs3Hf3Ql/dxcGtPey6r7iliKBXsnLL79MUFAQzz77LGCM5nRzc+Opp55iypQpXLp0iZKSEt566y2mTJlyxXPPnTvHHXfcQUxMDAUFBcyaNYuDBw8SGhp6xVwuTz/9NJGRkRQUFHDPPffwl7/8hXnz5pGYmMjo0aPx9fVl69athISEEBUVha+vLx9++CGLFi0C4PHHH+eFF17g3LlzTJw4keHDh7Nz504CAgJYs2YNLVq0uKKudevW8dZbb1FcXIyPjw9LliyhdevW5ObmMmfOHKKiolBK8dprrzFt2jQ2btzIK6+8QllZGb6+vmzZsqXiffjd734HGNP0lk85MH78eCIiIti3bx/r16/n7bffvur7A2Oa3ueff568vDycnZ3ZsmULt99+O/PmzauYyGz48OHMnz9fZna0IYUlZfx4NIXvouPZfvJyO/eQTr74ujtdDmpzWPu5OePl6iRn3DfIegN9w8uQfLh+X7NNL5j4do2bZ8yYwQsvvFAR6CtXrmTTpk24uLiwatUqWrVqRXp6OoMHD2by5Mk19mH95JNPcHV15dixYxw6dIj+/ftXbKtuGtu5c+fy4YcfsnXrVnx9fa94rX379vHFF1+wZ88etNZERERwyy234OXlJdP0CquktSbq/CW+i47n+0NJ5BQa/b+fHNmRqf0D6ezvZukSbZb1BroF9OvXj9TUVBITE0lLS8PLy4ugoCBKSkp45ZVX2L59O3Z2diQkJJCSkkKbNm2qfZ3t27czd+5cAHr37k3v3r0rtlU3jW3l7VX98ssv3H333RWzJ06dOpUdO3YwefJkmaZXWJW4i/l8Gx3Pd9EJXLiYj6uTPRN6tmFa/0AG23j/b2thvYF+jTPphjR9+nS++eYbkpOTmTFjBgBLliwhLS2Nffv24ejoSEhIyDWnn61JXaexvR6ZpldYWnZhCRsOJ/HtvgT2nruIUjCkow/Pj+3ChJ5taOlsvRFji+QKVhUzZsxg+fLlfPPNN0yfPh0wprr19/fH0dGRrVu3cv78+Wu+xsiRI1m6dCkAMTExHDp0CKh+GttyNU3dO2LECFavXk1+fj55eXmsWrWKESNG1Pr7ud40veXKp+ndvn17xcyP5U0uISEhREdHA3Wfphe4YppegJycHEpLSwHjmsDcuXMZOHCgTNPbRJSWmdh2PJW5y/Yz8K3N/OHbw6TnFvHS+G788ocxLH1iMNMGBEqYW4C841X06NGDnJwcAgICaNu2LQAPPPAAd955J7169SI8PJzQ0NBrvsbTTz/NrFmzCAsLIywsjAEDBgA1T2MLMHv2bCZMmEC7du3YunVrxeP9+/dn5syZDBo0CDACsF+/ftU2r1RHpukV9SXuYj4rIuNYGRVHak4RHi0cuTc8iKn9A+gb5Glz86I0RTJ9rrCo2kzTK58LyyktM7ElNpWley6w/WQaAKO6+nFveBBjwvxxdpCug41Nps8VVkmm6bVeCZkFrNh7gRVRcaRkF9G6lTNzRndmxqBgAjxbXP8FhEXUKtCVUhOAfwD2wGda67erbG8PLAL8gIvAg1rr+HquVdgYmabXupSZNFtjU1m69wLbjqeigVu6+vHGlGDGhvrbxHzhtu66ga6UsgfmA+OAeCBSKbVWa3200m7vA19prRcrpcYAfwceupGCtNbSFicqWKpJsDlJyipgRWQcKyLjSMoqxM/dmWdGdWbGwCCCvF0tXZ6og9qcoQ8CTmmtzwAopZYDU4DKgd4deNF8eyuw+kaKcXFxISMjAx8fHwl1gdaajIwMXFxcLF2KzSkzabafSGPJngv8FJuCScOILr68dmd3xoa1xlHOxpuk2gR6ABBX6X48EFFln4PAVIxmmbsBd6WUj9Y6oy7FBAYGEh8fT1paWl2eJmyYi4sLgYGBli7DJhSVlhGTkM0vJ9NZGRVHQmYBvm5OPHlLJ+4fGEywj5yNN3X1dVH0d8A/lVIzge1AAlBWdSel1GxgNkBwcPBVL+Lo6FgxSlEIcXPScorYd/4S0Rcuse/8JQ7HZ1VMhjWssw+vTApjXPfWODnI2bitqE2gJwBBle4Hmh+roLVOxDhDRynlBkzTWmdWfSGt9UJgIRjdFm+sZCFEVWUmzfHkHPZduET0eSPAL1zMB8DJ3o5egR7MHBZC/2Av+rf3xN9dmrFsUW0CPRLoopTqgBHk9wG/qbyDUsoXuKi1NgH/i9HjRQjRQLILSzhwIbPiDHz/hUxyi4zRt75uzoS39+Khwe3p396LngGtpL94M3HdQNdalyqlngM2YXRbXKS1PqKUegOI0lqvBUYBf1dKaYwml2cbsGYhmqW4i/ms3p/A+phkYpOz0RrsFHRr04q7+rUjvL03A9p7EejVQjoVNFNWNVJUCHGlrPwS1scksSramPwKYFCIN8M6+zKgvRd9gjxwd3G0cJWiMclIUSGakOJSY/KrVfsT2HIsleIyE538WvLS+G5M6duOQC/pjSKqJ4EuhBXQWrM/LpNV0Ql8fyiRS/kl+LR04jcRwUztH0CvAA9pRhHXJYEuhAVdyMhn1f4EVh9I4Gx6Hs4Odozr3pqp/QMY0cVPBviIOpFAF6KRZeYX8/2hJFbvTyDq/CUABnf05ulbOjGhVxtaSZu4uEES6EI0kqLSMhZsO8P8bacoLjXRxd+N30/oxpS+ATKDoagXEuhCNIKocxd5+bvDnErN5Y7ebXnqlk70aNdK2sVFvZJAF6IBZReW8M6GWJbsuUCAZwu+mDmQ0aH+li5L2CgJdCEayMaYZF5bG0NaThGPDe/Ai+O6yjqbokHJp0uIepacVcif18Tww9EUwtq2YuFD4fQJ8rR0WaIZkEAXop6YTJole87zzsbjlJSZeHliKI8N7yBdD0WjkUAXoh6cSMnh5W8PEX0hk+Gdffnr3T1p79PS0mWJZkYCXYibUFhSxsdbT/HJz6dxc3bgw3v7cHe/AOm9IixCAl2IG7TnTAb/u+owZ9LymNovgFdvD8PHzdnSZYlmTAJdiDrKyi/h7xuOsTwyjiDvFnz16CBGdvWzdFlCSKALURcxCVnM+jKSi3nFPDmyI8/f2gVXJ/kxEtZBPolC1NLZ9DweWbQXF0d71jw7jJ4BHpYuSYgrSKALUQsp2YU89PkeNPD1Y4Po6Odm6ZKEuIp0kBXiOrLyS3j4871cyitm8SwJc2G95AxdiGsoKC7j0cWRnE3P48tHB9IrUJpZhPWSM3QhalBSZuLpJfvYf+ES8+7vy9BOvpYuSYhrkjN0IaphMmle+s9Bth1P4+9TezGhZ1tLlyTEdckZuhBVaK154/ujrD6QyEvju3H/oGBLlyRErUigC1HFP386xZc7z/HY8A48M6qTpcsRotYk0IWo5N+7z/PBjyeMofyTwmROFtGkSKALYfbfQ0n8aU0MY0L9eeee3tjZSZiLpkUCXQjgl5PpvLBiP+HtvZj/m/4yh7lokuRTK5q9A3GZzP46ik5+bnz2yEBaONlbuiQhboh0WxSN6nhyDh9vO0Wwtyv923vRP8gLD1dHi9VzKjWHWV/sxcfNia8eHYRHC8vVIsTNkkAXjSYxs4CHF+0hu6CUotIyTNp4vIu/GwPae9G/vRcD2nvR0bdlo1yMTMws4KHP92JvZ8e/H4vAv5VLgx9TiIYkgS4aRVZBCTO/2Et+URmrnh1KkJcrB+My2Xf+EvsuXGL94SSWR8YB4OXqSP9gLwaEeDEg2IvegZ713gxyMa+Yhz7fQ25hKcufHCzLxQmbIIEuGlxRaRlPfh1lzIcyaxChbVoBMLSzL0M7G8PpTSbN6bRcI+DNIb8lNhUABztFj3atKs7g+wR64uHqiKujPQ43cPEyr6iUWV9GEn+pgK8eHUSPdjI/i7ANSmttkQOHh4frqKgoixxbNB6TSfPCigOsPZjIh/f2YWr/wFo/92JeMfsvXKoI+YPxmRSWmK7Yx9nBDlcne1ydHGjpbE8LJwdamu+7OtnT0vny7fJ9NsYks+fsRRY8OIBx3VvX97csRINSSu3TWodXt03O0EWDenfTcdYeNIbQ1yXMAbxbOjE2rDVjw4zQLSkzcSwpm6OJ2eQWlZJXVEZ+cSn5xWXkFZdSUFxGXnEZ+UWlZOYXVGwr315+7mKn4J1pvSXMhc2RQBcN5utd51jw82keiAiulyH0jvZ29A70pHegZ52fq7WmqNREXlEp9nYKT1enm65HCGtTqwZIpdQEpdRxpdQppdTL1WwPVkptVUrtV0odUkpNqv9SRVPyw5FkXlt7hFvD/PnL5B4WH0KvlMLF0R4fN2cJc2GzrhvoSil7YD4wEegO3K+U6l5ltz8CK7XW/YD7gI/ru1DRdOy/cIm5y/fTK8CDeff3u6ELl0KIuqvNT9og4JTW+ozWuhhYDkypso8GWplvewCJ9VeiaErOpefx2OIo/N1d+HzmQFydpFVPiMZSm0APAOIq3Y83P1bZ68CDSql4YD0wp7oXUkrNVkpFKaWi0tLSbqBcYc0ycot45Iu9aK1Z/OggfN2cLV2SEM1Kff0tfD/wpdY6EJgEfK2Uuuq1tdYLtdbhWutwPz+/ejq0sAbG2ptRJGcV8vnMgXTwlYE6QjS22gR6AhBU6X6g+bHKHgNWAmitdwEugCzA2EyUmTRzlu3nUHwm8+7vR/9gL0uXJESzVJtAjwS6KKU6KKWcMC56rq2yzwVgLIBSKgwj0KVNpRnQWvPa2hg2H0vhL5N7ML5HG0uXJESzdd1A11qXAs8Bm4BjGL1Zjiil3lBKTTbv9j/AE0qpg8AyYKa21BBU0agW/HyGf+++wJO3dOThISGWLkeIZq1WXRC01usxLnZWfuzPlW4fBYbVb2nC2q05kMA7G2OZ3KcdfxgfaulyhGj2pIOwuCE7T6fzu/8cZHBHb96bLsu1CWENJNBFnR1PzuHJr/bRwbcl/3ooHGcHWeFHCGsggS7qJCGzgJlf7MXV2Z4vZskKP0JYExnGJ2rteHIOjyzaS15xKStmDyHAs4WlSxJCVCJn6KJWIs9dZPqCnZi0ZuWTQ+jertX1nySEaFRyhi6ua/PRFJ5dGk2AZwsWPzqIIG9XS5ckhKiGBLq4ppWRcfzvqsP0bNeKRTMH4iPzswhhtSTQRbW01ny87TTvbTrOiC6+LHhwAC2d5eMihDWTn1BxFZNJ8+Z/j/LFr+eY0rcd793TBycHudwihLWTQBdXKC418bv/HGTtwUQeHdaBP94eJoOGhGgiJNBFhdyiUp76eh+/nErnDxNCeeqWjhZfOk4IUXsS6AKA9NwiHv0ykiOJ2bx7T2/uDQ+6/pOEEFZFAl0QdzGfhxftJSmrgIUPDWBsWGtLlySEuAES6M3c0cRsHvliL8WlJpY8HsGA9t6WLkkIcYMk0Jux3WcyeGJxFG4uDix9aghdWrtbuiQhxE2QQG+mNsYkM3f5foK9Xfnq0UG0k3lZhGjyJNCboSV7zvOn1TH0CfJk0SMD8WrpZOmShBD1QAK9GUnNKeTtDbF8F53A6G5+zH+gP65O8hEQwlbIT3MzUFxq4sudZ5m35RTFpSaeGdWJ347riqO9jP4UwpZIoNu47SfSeH3dEc6k5TEm1J8/3dGdDr4tLV2WEKIBSKDbqLiL+bz5/VF+OJpCiI8ri2aGMyZU+pcLYcsk0G1MQXEZn/x8mn/9fBo7pXhpfDceH9FB1v0UohmQQLcRWms2xiTz1n+PkZBZwJ192vHKpFDaekh3RCGaCwl0G3AyJYfX1x3h11MZhLZxZ/nswQzu6GPpsoQQjUwCvQnLLizhH5tPsnjnOVyd7PnL5B48EBGMg/ReEaJZkkBvgkwmzTfR8by7MZaMvGLuGxjM727rKsvDCdHMSaA3IWUmzc8nUpm35RQH4jLpH+zJFzMH0SvQw9KlCSGsgAR6E5CaU8h/ouJZuucCCZkF+Ls788H0PtzdL0BWExJCVJBAt1Jaa3afuci/95xnU0wypSbNkI4+vDIpjHHdW8san0KIq0igW5ms/BK+jY5nyZ7znE7Lw6OFI48MDeH+QcF09nezdHlCCCsmgW4FtNYcjM9iye7zrDuUSGGJib5Bnrw/vQ939G6Li6MMChJCXJ8EugXlF5ey5kAiS/acJyYhG1cne+7uF8gDEcH0DLDSC51aQ34GtPS1dCVCiCok0C3geHIOS/acZ1V0AjlFpXRr7c6bU3pwV78A3F0cLV1ezZJjYP1LcGEX3L8Muk20dEVCiEok0BtRfnEpb35/lGV743Cyt+P23m15ICKYAe29UMqKe6sUZMLWv0Hkp+DiCT6dYNWT8OR28AqxcHFCiHK1CnSl1ATgH4A98JnW+u0q2/8PGG2+6wr4a60967HOJu9oYjZzlkVzJj2PJ0d25MlbOuFt7SsFmUxwcCn8+BoUXITwR2H0q1CYBf+6BVY+Ao/9AA4yoEkIa3DdQFdK2QPzgXFAPBCplFqrtT5avo/W+reV9p8D9GuAWpskrTWLd57jb+tj8XR15N+PRTCscxNof06INppXEqIgKAImfQdt+xjbXL3h7k9g+W9g4//CHR9atlYhBFC7M/RBwCmt9RkApdRyYApwtIb97wdeq5/ymraLecW89J+DbIlNZUyoP+/d09v6h+fnZcBPb8C+xdDSD+5aAH3ug6pNQqG3w9C5sHMeBA+B3tMtU68QokJtAj0AiKt0Px6IqG5HpVR7oAPwUw3bZwOzAYKDg+tUaFOz81Q6L6w4QGZ+Ca/f2Z1HhoZYdzu5qQz2fQk/vQmF2TD4aRj1Mrhco7fN2D9DfBSsex7a9ga/bo1WrhDiavU93PA+4ButdVl1G7XWC7XW4VrrcD8/v3o+tHUoKTPx7sZYHvh8D+4uDqx+dhgzh3Ww7jCP2wsLR8F/X4TWPeGpX2DC368d5gD2jnDPInByhRUPQVFuo5QrhKhebQI9AQiqdD/Q/Fh17gOW3WxRTVXcxXymL9jFx9tOMyM8iHVzhtO9XStLl1Wz3FRY9TR8Pg7y0o1wfmQdtO5e+9do1RamfQYZJ+H73xr91IUQFlGbJpdIoItSqgNGkN8H/KbqTkqpUMAL2FWvFTYRaw4k8MdVMaBg/m/6c3vvtpYuqWZlpUYXxK1/g5ICGPYCjHwJnG9waoGOo2DUK7D1LQgeDAMfq89qhRC1dN1A11qXKqWeAzZhdFtcpLU+opR6A4jSWq8173ofsFzr5nWKlldUymtrj/DNvngGtPfiH/f1JdDL1dJlVa8wC46tg13zIfUodBoDE98F3y43/9oj/gfi9sDGlyGgP7STjk5CNDZlqfwNDw/XUVFRFjl2fYlJyGLOsv2cz8jjuTFdmDums/WtFlRaDKd+hEMr4fgGKCsC704w7i8QesfVvVduRv5FWDAC7OyMQUctvOrvtYUQACil9mmtw6vbJiNFb4DJpFn061ne2RiLT0tnlj5hZWt4mkwQt9sI8SOroDATXH1hwCPQ614IDK/fIC/n6g33LoZFE4y2+fuWGuFeX7SGExsh5jvoPhm63V6/ry9EEyeBXkeZ+cW8sOIA246ncVv31rwzrTde1jLiMzUWDq2Aw99A1gVwdDX6i/e6FzqNNnqlNLTAcBj/V9jwe6OP+vAX6ud1M04bzTknfwAHFzi8Eny7wfDfQq97Gud7E8LKSaDXgcmkeX75AXadzuDNu3ryYESw5bsjZidCzLdGkCcfBmVvhPeYPxphfqMXOm/GoNlwfidseQMCB0LIsBt/reI82PGh8cvB3hnG/w3CH4PY7+GX/4PVTxkXd4fNhX4PgmOL+vs+hGhipA29Dj7bcYa3/nuMN+/qyUOD21uukPKLm4dWwNkdgIaAAcaZeM+p4OZvudrKFWbDp6OhKAee3AHurev2fK3h6BrY9Cpkx0Pv+4x2f/c2V+5z8gfY/j7E74WW/jDkGSPwXay4u6gQN+FabegS6LV0OD6LqZ/8yphQfxY8OKBhz8zLSiEnCbLiISvO+MqMu3z/4hkoKwbvjkaI977XmAHR2qQcgU/HGs0wD60G+1r+QZh23GiyObMNWveCSe9B+yE17681nP8VdnwAp38CZw+ImA0RT8m87cLmSKDfpNyiUu6Yt4OiUhMbnh+Bp+tNtpkX5dYc1lnxRjNK1cG2rj7gEQQegUZ4h00xugdausnneg4shdVPG90ax/752vsW5cDP78DuT8CpJYz5EwyYVftfBACJ+40mmmPrjLb2ATNh6HPG+yaEDZBeLjfptTVHuHAxn2VPDK57mGsNmefh/C64sNP4N+PklfvYOUCrduARDO2Hgac5uD2CLoe4k5X2bb+evr8xFsTY8YExa2PX8VfvozUc/g/88CfITYZ+D8Gtr9/Y2XW7fjDja+Ms/5ePYO9CiPzMmGBs+G+t8y+ZxmIywa5/wi8fQtu+xl92YXeCs7ulKxP1RM7Qr2P1/gReWHGA58d24bfjul7/CSaTMWjnwi7j6/wuyEk0trl4QNBgCBoIXh0uh7V7G7Cz4XVDSwqM6QUy4+CpHeBZaWK2ilWQdhphPOkDCBxQf8e+dB52/j/Y/7XRTNV9Cgx5Dtzq2KZfnxxcwK2R5zLKToRVT8HZnyFkBGReME40HFoYK0/1ngGdx0pvoSZAmlxu0PmMPCb9Ywc92nmw9ImI6gcNlRYbf+aXn33H7TYuWgK4tzPafoOHQPuh4BfWfPtNZ5w2JgDz7QKzNhghv+3vsPdT4xfdra8bZ+YN9f7kpsLuj2HvZ1Cc0zDHqIue98Btbxp/mTW0Y+tg7RwoLYIJb0P/h43H4yONC+sx3xkLmLTwhh53G2fuQRHW35zXTEmg34DiUhPTF+zkXEY+658fQYBni8sXK9OPw4XdRoAnREFpofEkny7mAB9q/OvZXn4oKju2DlY8CJ1vhcQDV66C5OrdODUUZMKJTcbZuqVknDKuE9g7wi2/h4inwaEBxjIU5xkLkEQvNhYnmfZ59dM8lJUYF5MPrYDY9VBaYHx2e003wl2mRbYqEui1VZRjXJTMjGPjzkhOn4rl7g4m2qkMo7kgJxG0ydhX2RtzgAcPNSakCh7S+H9GN0WbXjXacYMijN4r5asgNTcXzxphe2KDcSIw6V1jbp36kngAvn3c+OUxbC6M/mPtfmkU5UDsf41wP7PN+Ly37WP0pup1z5XdRoVFSKBXVlJgnKFlnjf3LIk39zKJM4bIV1KGPfaeAcbFSo/AyxcrvToYPUzkYlLdmcog+RC06dN8m58qO7EJNvwBLp01LlCO/9uV1xjqymQyBmH99Jax4tTdC6DjLTf2WjkpxqC1wyuNZkVlBx1GXh553BjNReIqEuiVbX/P+LADOLe6fGHSHNbZzm15YWM6Ba7t+OK5O3BxtpJh/cJ2lRQaf7Vsf9+4P+J/YOgccHSp2+tkJ8KqJ+HsduOXw53z6q8pK/2kMTfQ4ZVw6ZzxmGd749pQ+TUin87SxNgIJNArWzga0PDwmqtW5DGZNLO+jGT3mQzWPjecbm3kDFw0osw4+OFVY4SsVwhMeAe6Tajdcytf+Jz4jnGBuSHCVWtIOmgM5Dq/07iWlJ9ubGvpZ25+NDdDtuldtzEEolakH3q5nGRIjDbmOalmebVFv57l5xNpvHlXTwlz0fg8g+Der+D0VmOk7LIZ0HWCsRygd8fqn1OcZ0xaFv2V0bd82ufg27nhalQK2vU1voY8awR8xilzuO8y/j22ztjXyc2Yy6f8LD4wXObaaWDNK9BPbDL+7Trxqk2H47N4Z2Ms43u05sEI217AWli5TqPhqV9hzwJj5Oz8wcaFzeEvXjnALCEavnvC6BI6/LfGqlEN0VvmWpQyes74djGmZwaj6af87P3CLmPyNDTYORpjDcp7ggVHNL0580uLjTENwUPqtlRjI2leTS7L7jdmJHzh8BV/jtb70H4h6kt2Evz4J2MkrUeQcdE09PZKFz79Yeq/jIuV1qrgkrEQeflZfEI0mEqMbf7dL7fBBw8BjwDL1noteRmw8iGjuQmg2yTjekdgta0fDUba0MHo3fJOB2OK1dvfv2LTiysPsHp/AsueGEyENS1UIUS5c78aI2pTj4B7W2M8RNhkuPMfjdeHv76UFEDCvsvTYcTtheJcY5tn8OVxHMFDjTN/a7jQmnoMls4wmm0nvWe8/7s/MXrGdRhpBHuHWxqlVmlDB+PKf2nBVReZVu2P57voBJ4f20XCXFivkGHGsn5Rn0Pk5zD6lYa78NnQHFtAyHDjC4wBeykxl9vgT2+BQ8uNba6+xgXW8jN4S1xoPbEJvnnMaO6atf7yGfmQZ2Hfl7Dzn/DVFGMK6+EvGmfuFuqS23zO0Ne9YHS7+v2Ziu5g59LzuH3eDrq3a8WyJwZb33qgQjRHWhvXBcqn07iw83JXSceWEDTI6NbZeWzD17FrPvzwR2jTC+5fVv2snSWFcHAZ/PqRUadfqBHsPac1yC8faXLRGj7sbgwGum8JYAztv2fBTs5XHtovhLBO2UlGsF/YDcc3Gkss1sdArJqUFsN/fwv7/200bd29wJjS+VrKSo01fH/50Jigz7M9DHse+j5Q9zEF13CtQG8ep6TJh4xh+90u92754IfjHIrP4p1pvSTMhbB2rdoaZ7yT3oM5UcZc+Sc3wz8Hws/vGmfJ9SUv3WhC2f9vGPl7mL74+mEOxtl47+lGD6X7lhn98v/7IvyjN/z6D2NahQbWPAL9+EZAQRdjLu7tJ9L41/YzPBARzISebS1bmxCibhycYeTv4LlIY379rX+FjyPMP+c3KeWosXRiwj6jT/+YV+veHm5nB6GT4PHN8Mg68A+DH/8M/9fT6MKZf/Hm66zp0A32ytbkxAbjQoabH2k5Rby48iBdW7vxpzusrx+pEKKWygdiPbQa7J2MgVhL7jXa32/EiU3GvP2lRcYUz73uubn6lDJ6wDy8Bh7/ybgI/PM7RrAfXH5zr10D2w/07CRjYqGuRu+WxTvPcTGviP93f39cHG14UQkhmovygVi3vWX0Ef94MGx5E4rza/d8rY1FUJbOMFa0emJr/S6yAsbr3bcEntlttP37hdbv65vZfqCfNI8ONbefbz6WQniItwztF8KWODgZPV+ei4Lud8GO92H+IGNenGt1/CgtgjXPGT1Zuk82zswbcnCTf5gxEKxd3wZ5edsP9OMbjRF2/t1JyCwgNjmHsaH+lq5KCNEQWrWFaZ/CzPXGbKorH4av74a0E1fvW37x88C/4ZY/wD1f1u7ipxWz7UAvKTAm6e86AZTip2MpAIwNs+B6kkKIhlc+EGviu8ZUA58MMRYhL+9pUn7xM3E/3LPIGKhlA/Pz2/ZI0SqjQzcfSyXEx5VOfk37t7AQohbsHSDiSegxFba8bsx/c2glDJhpzD/v5GaM/Ayo5/ZyC2r6v5Ku5fgG4z8tZAR5RaXsOp3BmNDWqKY4XFoIcWPc/GDKfHhsM7i3hp/fNhbjmL3VpsIcbPkMXWujG1Kn0eDgzC/HkykuM3FrmLSfC9EsBQ00erCc2wGBg66cithG2O4ZetJBY3Soee7zn46l4u7sQHhIE5uZTghRf+zsoeMomwxzsOVAP1E+OvQ2TCbNlthURnbzw8nBdr9lIUTzZrvpdvzy6NDDCVmk5xZJd0UhhE2rVaArpSYopY4rpU4ppV6uYZ97lVJHlVJHlFJL67fMOspOgqQDFaNDtxxLwU7B6G4S6EII23Xdi6JKKXtgPjAOiAcilVJrtdZHK+3TBfhfYJjW+pJSyrLJedXo0FQGtPfCq6UsLSeEsF21OUMfBJzSWp/RWhcDy4EpVfZ5Apivtb4EoLVOrd8y6+j4RvAIBv/uJGUVcDQpmzGhMphICGHbahPoAUBcpfvx5scq6wp0VUr9qpTarZSaQDWUUrOVUlFKqai0tLQbq/h6ykeHdjNGh245Zvxuke6KQghbV18XRR2ALsAo4H7gU6WUZ9WdtNYLtdbhWutwPz+/ejp0FWd+NkaHmtvPf4pNJci7BZ393RrmeEIIYSVqE+gJQFCl+4HmxyqLB9ZqrUu01meBExgB3/hOlI8OHU5BcRm/nkpnrIwOFUI0A7UJ9Eigi1Kqg1LKCbgPWFtln9UYZ+copXwxmmDO1F+ZtVRldOivp9IpKjUxVppbhBDNwHUDXWtdCjwHbAKOASu11keUUm8opSabd9sEZCiljgJbgZe01hkNVXSNkg5CTlLF6NAtsSm4OTsQ0cGn0UsRQojGVqu5XLTW64H1VR77c6XbGnjR/GU5lUaHaq3ZciyVkV19ZXSoEKJZsK2kO74BAgeCmx8xCdmk5hRJd0UhRLNhO4FePjq0Yu7zFJSC0d0aqDeNEEJYGdsJ9BMbjX/LZ1eMTaVfkCc+bs4WLEoIIRqPbQW6ZzD4h5GSXcjhhCxZak4I0azYRqAX51+5dmisMTpUuisKIZoT2wj0s9uhtPCK2RUDPFvQrbW7hQsTQojGYxuBXml0aGFJGb+cSufWMH8ZHSqEaFaafqBXjA4dAw7O7DydTmGJiTHSfi6EaGaafqAnHTBGh1aa+9zVyZ7BHWXtUCFE89L0A/34laNDfzqWyoguvjg72Fu6MiGEaFRNP9BPbICgQdDSlyOJ2SRnF0p3RSFEs9S0Az070ZiQq+t4wBhMpGTtUCFEM9W0A/2Eee3Q8tkVj6XQJ9ATP3cZHSqEaH6aeKBfHh2amlPIwfgsWWpOCNFsNd1ArxgdOhGUYqt5dKjMriiEaK6abqCf/dkYHdqtfHRoKu08XAhrK6NDhRDNU9MN9OMbwMkd2hujQ3ecTGeMjA4VQjRjTTPQTSbjgmjnMeDgxK4zGRSUlEl3RSFEs9Y0Az35IOQmV0zG9dOxVFo42jOko6wdKoRovppmoB+vunZoCsO7+OLiKKNDhRDNV9MM9EqjQ2OTc0jMKpTuikKIZq/pBXrF6NDLc5+DjA4VQoimF+jla4eaZ1fcEptKn0AP/Fu5WLAoIYSwvKYX6L5dYdBs8AslPbeIA3GZMphICCEAB0sXUGchw40vjMm4tJa1Q4UQApriGXolPx1LpU0rF3q0a2XpUoQQwuKabKAXlZax42SajA4VQgizJhvoe85cJK+4TLorCiGEWZMN9C3HUnBxtGNoJ19LlyKEEFahSQa61potsakM7yyjQ4UQolyTDPQTKbnEXyqQ7opCCFFJkwz0zebRodJdUQghLmuSgf5TbCq9AjxoLaNDhRCiQpML9IzcIqIvXGJMqJydCyFEZbUKdKXUBKXUcaXUKaXUy9Vsn6mUSlNKHTB/PV7/pRq2HU9Da7hVFrMQQogrXHfov1LKHpgPjAPigUil1Fqt9dEqu67QWj/XADVewd3FgXHdW8voUCGEqKI2c7kMAk5prc8AKKWWA1OAqoHeKG7r0YbberSxxKGFEMKq1abJJQCIq3Q/3vxYVdOUUoeUUt8opYKqeyGl1GylVJRSKiotLe0GyhVCCFGT+rooug4I0Vr3Bn4EFle3k9Z6odY6XGsd7ufnV0+HFkIIAbUL9ASg8hl3oPmxClrrDK11kfnuZ8CA+ilPCCFEbdUm0COBLkqpDkopJ+A+YG3lHZRSbSvdnQwcq78ShRBC1MZ1L4pqrUuVUs8BmwB7YJHW+ohS6g0gSmu9FpirlJoMlAIXgZkNWLMQQohqKK21RQ4cHh6uo6KiLHJsIYRoqpRS+7TW4dVta3IjRYUQQlRPAl0IIWyExZpclFJpwPkbfLovkF6P5dQ3qe/mSH03z9prlPpuXHutdbX9vi0W6DdDKRVVUxuSNZD6bo7Ud/OsvUapr2FIk4sQQtgICXQhhLARTTXQF1q6gOuQ+m6O1HfzrL1Gqa8BNMk2dCGEEFdrqmfoQgghqpBAF0IIG2HVgV6Lpe+clVIrzNv3KKVCGrG2IKXUVqXUUaXUEaXU89XsM0oplVVpab4/N1Z95uOfU0odNh/7qnkWlGGe+f07pJTq34i1dav0vhxQSmUrpV6osk+jv39KqUVKqVSlVEylx7yVUj8qpU6a//Wq4bmPmPc5qZR6pJFqe08pFWv+/1ullPKs4bnX/Cw0cI2vK6USKv0/Tqrhudf8eW/A+lZUqu2cUupADc9tlPfwpmitrfILYyKw00BHwAk4CHSvss8zwALz7fswlsFrrPraAv3Nt92BE9XUNwr43oLv4TnA9xrbJwEbAAUMBvZY8P86GWPAhEXfP2Ak0B+IqfTYu8DL5tsvA+9U8zxv4Iz5Xy/zba9GqO02wMF8+53qaqvNZ6GBa3wd+F0tPgPX/HlvqPqqbP8A+LMl38Ob+bLmM/SKpe+01sVA+dJ3lU3h8mIa3wBjlVKqMYrTWidpraPNt3MwpgyubiUnazYF+EobdgOeVaZCbixjgdNa6xsdOVxvtNbbMWYMrazy52wxcFc1Tx0P/Ki1vqi1voSx0MuEhq5Na/2D1rrUfHc3xnoFFlPD+1cbtfl5v2nXqs+cHfcCy+r7uI3FmgO9NkvfVexj/lBnAT6NUl0l5qaefsCeajYPUUodVEptUEr1aNzK0MAPSql9SqnZ1Wyv7fKCDe0+av4hsuT7V6611jrJfDsZaF3NPtbwXj6K8RdXda73WWhoz5mbhRbV0GRlDe/fCCBFa32yhu2Wfg+vy5oDvUlQSrkB3wIvaK2zq2yOxmhG6AP8P2B1I5c3XGvdH5gIPKuUGtnIx78uZSyaMhn4TzWbLf3+XUUbf3tbXV9fpdSrGOsRLKlhF0t+Fj4BOgF9gSSMZg1rdD/XPju3+p8naw706y59V3kfpZQD4AFkNEp1xjEdMcJ8idb6u6rbtdbZWutc8+31gKNSyrex6tNaJ5j/TQVWYfxZW1lt3uOGNhGI1lqnVN1g6fevkpTypijzv6nV7GOx91IpNRO4A3jA/AvnKrX4LDQYrXWK1rpMa20CPq3h2Bb9LJrzYyqwoqZ9LPke1pY1B/p1l74z3y/vTXAP8FNNH+j6Zm5v+xw4prX+sIZ92pS36SulBmG8343yC0cp1VIp5V5+G+PiWUyV3dYCD5t7uwwGsio1LTSWGs+KLPn+VVH5c/YIsKaafTYBtymlvMxNCreZH2tQSqkJwO+ByVrr/Br2qc1noSFrrHxd5u4ajl2bn/eGdCsQq7WOr26jpd/DWrP0VdlrfWH0wjiBcfX7VfNjb2B8eAFcMP5UPwXsBTo2Ym3DMf70PgQcMH9NAp4CnjLv8xxwBOOK/W5gaCPW19F83IPmGsrfv8r1KWC++f09DIQ38v9vS4yA9qj0mEXfP4xfLklACUY77mMY12W2ACeBzYC3ed9w4LNKz33U/Fk8BcxqpNpOYbQ9l38Gy3t9tQPWX+uz0Ijv39fmz9chjJBuW7VG8/2rft4boz7z41+Wf+4q7WuR9/BmvmTovxBC2AhrbnIRQghRBxLoQghhIyTQhRDCRkigCyGEjZBAF0IIGyGBLoQQNkICXQghbMT/B00sCJ8v9z9MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot( hist.history['acc'], label='train accuracy')\n",
        "plt.plot( hist.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 웰시코기 학습 2 후기\n",
        "- 과적합 발생\n",
        "- 학습 3에서는 과적합을 줄일 수 있는 방법을 사용하자\n",
        "    - DropOut\n",
        "    - L1규제 , L2규제"
      ],
      "metadata": {
        "id": "j7flTeWNx1nG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 웰시코기 학습 3\n",
        "- 과적합을 제거하기 위해 DropOut층 추가"
      ],
      "metadata": {
        "id": "Gv-L0EhqFPOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56e64876"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8129653"
      },
      "source": [
        "## 이미지 전처리\n",
        "- 스케일링, 이미지 증식\n",
        "- 이미지 크기 300 x 300\n",
        "- batch_size = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1149218",
        "outputId": "6fb0b449-1bb9-4cc2-acb7-1b559819dcae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 620 images belonging to 2 classes.\n",
            "Found 247 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 학습 이미지를 생성\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  rotation_range = 40,\n",
        "  width_shift_range= 0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# 검증 이미지는 증식하지 않는다.\n",
        "# 검증 데이터는 학습 과정에서 절대로 사용되어선 안된다.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  target_size = (300, 300), \n",
        "  batch_size = 15,\n",
        "  class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "  val_path,\n",
        "  target_size = (300, 300), \n",
        "  batch_size = 15,\n",
        "  class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4534e3db"
      },
      "source": [
        "## 네트워크 구성 및 규제 추가\n",
        "- Dense층에 입력하기 전에 Dropout층 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29813b98"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec60cf11",
        "outputId": "b56c6eb4-d4c2-44bc-ae69-36dfe655e51b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 23:08:26.137192: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-25 23:08:26.138212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-25 23:08:26.195148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.195744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-03-25 23:08:26.195768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-25 23:08:26.198713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-25 23:08:26.198795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-25 23:08:26.200523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-25 23:08:26.200879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-25 23:08:26.202770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-25 23:08:26.203499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-25 23:08:26.203687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-25 23:08:26.203818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.204462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.204999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-03-25 23:08:26.205513: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-25 23:08:26.205719: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-25 23:08:26.205855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.206431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-03-25 23:08:26.206450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-25 23:08:26.206473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-25 23:08:26.206485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-25 23:08:26.206497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-25 23:08:26.206508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-25 23:08:26.206519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-25 23:08:26.206532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-25 23:08:26.206543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-25 23:08:26.206604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.207241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.207776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-03-25 23:08:26.207806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-25 23:08:26.825673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-03-25 23:08:26.825709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-03-25 23:08:26.825717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-03-25 23:08:26.825985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.826612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.827210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-25 23:08:26.827752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Convolution Layer\n",
        "model.add( tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "# feature map -> input\n",
        "model.add( tf.keras.layers.Flatten() )\n",
        "\n",
        "# DropOut Layer\n",
        "model.add( tf.keras.layers.Dropout(0.5) )\n",
        "\n",
        "# Neural Network\n",
        "model.add( tf.keras.layers.Dense(512, activation='relu') ) # hidden layer\n",
        "# Neural Network\n",
        "model.add( tf.keras.layers.Dense(1, activation='sigmoid') )# output layer\n",
        "\n",
        "\n",
        "# optimaze\n",
        "model.compile(\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['acc'],\n",
        "  optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "48d4dfe1",
        "outputId": "ac066f8b-7f74-4055-db1c-b84115cd81ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 23:08:41.351709: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-03-25 23:08:41.371119: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 23:08:42.064124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-25 23:08:42.616554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-25 23:08:42.623878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 21s 428ms/step - loss: 0.7188 - acc: 0.4875 - val_loss: 0.6813 - val_acc: 0.6311\n",
            "Epoch 2/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.6835 - acc: 0.5594 - val_loss: 0.6239 - val_acc: 0.6578\n",
            "Epoch 3/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.6730 - acc: 0.5893 - val_loss: 0.6273 - val_acc: 0.6578\n",
            "Epoch 4/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.6378 - acc: 0.6416 - val_loss: 0.6031 - val_acc: 0.6667\n",
            "Epoch 5/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.6308 - acc: 0.6314 - val_loss: 0.6122 - val_acc: 0.6578\n",
            "Epoch 6/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.6474 - acc: 0.6060 - val_loss: 0.6436 - val_acc: 0.6533\n",
            "Epoch 7/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.6020 - acc: 0.6681 - val_loss: 0.5921 - val_acc: 0.6756\n",
            "Epoch 8/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.6151 - acc: 0.6655 - val_loss: 0.6075 - val_acc: 0.6578\n",
            "Epoch 9/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.6190 - acc: 0.6297 - val_loss: 0.5896 - val_acc: 0.6667\n",
            "Epoch 10/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5767 - acc: 0.7047 - val_loss: 0.6173 - val_acc: 0.6267\n",
            "Epoch 11/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.6185 - acc: 0.6484 - val_loss: 0.6529 - val_acc: 0.6578\n",
            "Epoch 12/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.6374 - acc: 0.6323 - val_loss: 0.6383 - val_acc: 0.6533\n",
            "Epoch 13/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.6369 - acc: 0.6261 - val_loss: 0.5715 - val_acc: 0.7111\n",
            "Epoch 14/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.6098 - acc: 0.6637 - val_loss: 0.6377 - val_acc: 0.6489\n",
            "Epoch 15/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.6061 - acc: 0.6616 - val_loss: 0.6761 - val_acc: 0.6311\n",
            "Epoch 16/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.6097 - acc: 0.6597 - val_loss: 0.6160 - val_acc: 0.6711\n",
            "Epoch 17/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.5848 - acc: 0.6653 - val_loss: 0.6306 - val_acc: 0.6622\n",
            "Epoch 18/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.6330 - acc: 0.6340 - val_loss: 0.6013 - val_acc: 0.6800\n",
            "Epoch 19/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.5938 - acc: 0.6658 - val_loss: 0.5780 - val_acc: 0.6756\n",
            "Epoch 20/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5573 - acc: 0.7165 - val_loss: 0.5628 - val_acc: 0.6800\n",
            "Epoch 21/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5829 - acc: 0.6749 - val_loss: 0.5639 - val_acc: 0.6889\n",
            "Epoch 22/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.6125 - acc: 0.6331 - val_loss: 0.5441 - val_acc: 0.7111\n",
            "Epoch 23/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.5476 - acc: 0.7177 - val_loss: 0.5892 - val_acc: 0.6844\n",
            "Epoch 24/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.5764 - acc: 0.6607 - val_loss: 0.5701 - val_acc: 0.6756\n",
            "Epoch 25/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.5679 - acc: 0.6575 - val_loss: 0.5837 - val_acc: 0.6933\n",
            "Epoch 26/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.6076 - acc: 0.6809 - val_loss: 0.5699 - val_acc: 0.6933\n",
            "Epoch 27/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5802 - acc: 0.6712 - val_loss: 0.5749 - val_acc: 0.6800\n",
            "Epoch 28/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.5887 - acc: 0.6583 - val_loss: 0.5657 - val_acc: 0.6800\n",
            "Epoch 29/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5876 - acc: 0.6754 - val_loss: 0.5598 - val_acc: 0.7022\n",
            "Epoch 30/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5594 - acc: 0.7145 - val_loss: 0.5650 - val_acc: 0.6800\n",
            "Epoch 31/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5540 - acc: 0.7041 - val_loss: 0.6203 - val_acc: 0.6800\n",
            "Epoch 32/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.6144 - acc: 0.6740 - val_loss: 0.6248 - val_acc: 0.6711\n",
            "Epoch 33/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.5818 - acc: 0.6772 - val_loss: 0.5908 - val_acc: 0.6711\n",
            "Epoch 34/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.6002 - acc: 0.6652 - val_loss: 0.6010 - val_acc: 0.6800\n",
            "Epoch 35/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.5713 - acc: 0.6808 - val_loss: 0.5695 - val_acc: 0.6978\n",
            "Epoch 36/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5826 - acc: 0.6986 - val_loss: 0.5908 - val_acc: 0.6978\n",
            "Epoch 37/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5961 - acc: 0.6674 - val_loss: 0.5756 - val_acc: 0.6844\n",
            "Epoch 38/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.5739 - acc: 0.7158 - val_loss: 0.5862 - val_acc: 0.6933\n",
            "Epoch 39/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.5718 - acc: 0.6981 - val_loss: 0.5710 - val_acc: 0.6800\n",
            "Epoch 40/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.5711 - acc: 0.6921 - val_loss: 0.5731 - val_acc: 0.7022\n",
            "Epoch 41/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5943 - acc: 0.6886 - val_loss: 0.5357 - val_acc: 0.7067\n",
            "Epoch 42/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.5709 - acc: 0.6938 - val_loss: 0.5637 - val_acc: 0.6889\n",
            "Epoch 43/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5642 - acc: 0.6763 - val_loss: 0.6446 - val_acc: 0.6711\n",
            "Epoch 44/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5986 - acc: 0.6830 - val_loss: 0.5745 - val_acc: 0.6800\n",
            "Epoch 45/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5207 - acc: 0.7318 - val_loss: 0.5517 - val_acc: 0.7244\n",
            "Epoch 46/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.5478 - acc: 0.7148 - val_loss: 0.5557 - val_acc: 0.6978\n",
            "Epoch 47/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.5956 - acc: 0.6559 - val_loss: 0.5686 - val_acc: 0.6800\n",
            "Epoch 48/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5301 - acc: 0.7271 - val_loss: 0.5443 - val_acc: 0.6978\n",
            "Epoch 49/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.5438 - acc: 0.7310 - val_loss: 0.5700 - val_acc: 0.7067\n",
            "Epoch 50/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.5595 - acc: 0.6924 - val_loss: 0.5928 - val_acc: 0.6889\n",
            "Epoch 51/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.5260 - acc: 0.7372 - val_loss: 0.5715 - val_acc: 0.7111\n",
            "Epoch 52/4000\n",
            "40/40 [==============================] - 16s 418ms/step - loss: 0.5496 - acc: 0.6945 - val_loss: 0.5825 - val_acc: 0.6756\n",
            "Epoch 53/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5828 - acc: 0.6924 - val_loss: 0.5699 - val_acc: 0.7067\n",
            "Epoch 54/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.5267 - acc: 0.7057 - val_loss: 0.6233 - val_acc: 0.6711\n",
            "Epoch 55/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.5700 - acc: 0.7004 - val_loss: 0.6295 - val_acc: 0.6667\n",
            "Epoch 56/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.5147 - acc: 0.7318 - val_loss: 0.5620 - val_acc: 0.7378\n",
            "Epoch 57/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.5311 - acc: 0.7312 - val_loss: 0.5846 - val_acc: 0.7022\n",
            "Epoch 58/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.5557 - acc: 0.7134 - val_loss: 0.5963 - val_acc: 0.7022\n",
            "Epoch 59/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.5642 - acc: 0.7012 - val_loss: 0.6600 - val_acc: 0.6844\n",
            "Epoch 60/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.5515 - acc: 0.7110 - val_loss: 0.5732 - val_acc: 0.7244\n",
            "Epoch 61/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.5334 - acc: 0.7218 - val_loss: 0.6940 - val_acc: 0.6667\n",
            "Epoch 62/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.5590 - acc: 0.6982 - val_loss: 0.5776 - val_acc: 0.7156\n",
            "Epoch 63/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.5527 - acc: 0.7114 - val_loss: 0.5845 - val_acc: 0.6933\n",
            "Epoch 64/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.5217 - acc: 0.7378 - val_loss: 0.6784 - val_acc: 0.6800\n",
            "Epoch 65/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.5307 - acc: 0.7253 - val_loss: 0.5762 - val_acc: 0.6933\n",
            "Epoch 66/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.5574 - acc: 0.7043 - val_loss: 0.6449 - val_acc: 0.6622\n",
            "Epoch 67/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.5577 - acc: 0.7246 - val_loss: 0.5757 - val_acc: 0.7067\n",
            "Epoch 68/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.5274 - acc: 0.7404 - val_loss: 0.6189 - val_acc: 0.6933\n",
            "Epoch 69/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.5492 - acc: 0.7029 - val_loss: 0.6271 - val_acc: 0.7067\n",
            "Epoch 70/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5254 - acc: 0.7489 - val_loss: 0.6106 - val_acc: 0.6889\n",
            "Epoch 71/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5132 - acc: 0.7131 - val_loss: 0.6104 - val_acc: 0.6933\n",
            "Epoch 72/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.5547 - acc: 0.7348 - val_loss: 0.6748 - val_acc: 0.6622\n",
            "Epoch 73/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4769 - acc: 0.7752 - val_loss: 0.5908 - val_acc: 0.7022\n",
            "Epoch 74/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.5160 - acc: 0.7431 - val_loss: 0.5706 - val_acc: 0.6933\n",
            "Epoch 75/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.5342 - acc: 0.7429 - val_loss: 0.5903 - val_acc: 0.7022\n",
            "Epoch 76/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5101 - acc: 0.6994 - val_loss: 0.5587 - val_acc: 0.6933\n",
            "Epoch 77/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5425 - acc: 0.7220 - val_loss: 0.6257 - val_acc: 0.7200\n",
            "Epoch 78/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5034 - acc: 0.7507 - val_loss: 0.5697 - val_acc: 0.7333\n",
            "Epoch 79/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4748 - acc: 0.7893 - val_loss: 0.5673 - val_acc: 0.6978\n",
            "Epoch 80/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.5017 - acc: 0.7364 - val_loss: 0.6419 - val_acc: 0.7244\n",
            "Epoch 81/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4770 - acc: 0.7616 - val_loss: 0.6546 - val_acc: 0.6844\n",
            "Epoch 82/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.5154 - acc: 0.7300 - val_loss: 0.6510 - val_acc: 0.7067\n",
            "Epoch 83/4000\n",
            "40/40 [==============================] - 16s 417ms/step - loss: 0.5411 - acc: 0.7351 - val_loss: 0.5961 - val_acc: 0.7156\n",
            "Epoch 84/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5078 - acc: 0.7737 - val_loss: 0.6191 - val_acc: 0.6844\n",
            "Epoch 85/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.5346 - acc: 0.7306 - val_loss: 0.6204 - val_acc: 0.7289\n",
            "Epoch 86/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.5036 - acc: 0.7579 - val_loss: 0.5963 - val_acc: 0.6889\n",
            "Epoch 87/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.5084 - acc: 0.7488 - val_loss: 0.5949 - val_acc: 0.6800\n",
            "Epoch 88/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.5284 - acc: 0.7516 - val_loss: 0.6431 - val_acc: 0.6800\n",
            "Epoch 89/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.4795 - acc: 0.7651 - val_loss: 0.6445 - val_acc: 0.6933\n",
            "Epoch 90/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.5008 - acc: 0.7331 - val_loss: 0.6872 - val_acc: 0.6978\n",
            "Epoch 91/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.5033 - acc: 0.7449 - val_loss: 0.8015 - val_acc: 0.6622\n",
            "Epoch 92/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4599 - acc: 0.7800 - val_loss: 0.6566 - val_acc: 0.7067\n",
            "Epoch 93/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.4791 - acc: 0.7501 - val_loss: 0.6955 - val_acc: 0.6800\n",
            "Epoch 94/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4923 - acc: 0.7413 - val_loss: 0.6166 - val_acc: 0.6933\n",
            "Epoch 95/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4972 - acc: 0.7289 - val_loss: 0.6780 - val_acc: 0.6578\n",
            "Epoch 96/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5076 - acc: 0.7338 - val_loss: 0.7141 - val_acc: 0.6622\n",
            "Epoch 97/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.4782 - acc: 0.7729 - val_loss: 0.6459 - val_acc: 0.7022\n",
            "Epoch 98/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4711 - acc: 0.7524 - val_loss: 0.7401 - val_acc: 0.6756\n",
            "Epoch 99/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.4498 - acc: 0.8037 - val_loss: 0.5849 - val_acc: 0.7156\n",
            "Epoch 100/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4887 - acc: 0.7518 - val_loss: 0.6031 - val_acc: 0.6889\n",
            "Epoch 101/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4653 - acc: 0.7650 - val_loss: 0.6215 - val_acc: 0.6578\n",
            "Epoch 102/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4778 - acc: 0.7397 - val_loss: 0.6483 - val_acc: 0.6800\n",
            "Epoch 103/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.5106 - acc: 0.7585 - val_loss: 0.6241 - val_acc: 0.7156\n",
            "Epoch 104/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4682 - acc: 0.7711 - val_loss: 0.7551 - val_acc: 0.6844\n",
            "Epoch 105/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4785 - acc: 0.7640 - val_loss: 0.5776 - val_acc: 0.7422\n",
            "Epoch 106/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4843 - acc: 0.7446 - val_loss: 0.6549 - val_acc: 0.6933\n",
            "Epoch 107/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.4910 - acc: 0.7576 - val_loss: 0.6458 - val_acc: 0.6933\n",
            "Epoch 108/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4774 - acc: 0.7610 - val_loss: 0.6602 - val_acc: 0.7022\n",
            "Epoch 109/4000\n",
            "40/40 [==============================] - 16s 399ms/step - loss: 0.5017 - acc: 0.7702 - val_loss: 0.6743 - val_acc: 0.7022\n",
            "Epoch 110/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5035 - acc: 0.7299 - val_loss: 0.6187 - val_acc: 0.7156\n",
            "Epoch 111/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.5024 - acc: 0.7439 - val_loss: 0.6249 - val_acc: 0.7022\n",
            "Epoch 112/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4708 - acc: 0.7457 - val_loss: 0.7614 - val_acc: 0.7289\n",
            "Epoch 113/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.5559 - acc: 0.7395 - val_loss: 0.7153 - val_acc: 0.6933\n",
            "Epoch 114/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4809 - acc: 0.7684 - val_loss: 0.6165 - val_acc: 0.6978\n",
            "Epoch 115/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4747 - acc: 0.7621 - val_loss: 0.6873 - val_acc: 0.6756\n",
            "Epoch 116/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5183 - acc: 0.7244 - val_loss: 0.6840 - val_acc: 0.6978\n",
            "Epoch 117/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4336 - acc: 0.7578 - val_loss: 0.6752 - val_acc: 0.7022\n",
            "Epoch 118/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.4809 - acc: 0.7561 - val_loss: 0.6991 - val_acc: 0.6844\n",
            "Epoch 119/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4704 - acc: 0.7836 - val_loss: 0.7053 - val_acc: 0.7022\n",
            "Epoch 120/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4675 - acc: 0.7578 - val_loss: 0.8006 - val_acc: 0.6489\n",
            "Epoch 121/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.5221 - acc: 0.7515 - val_loss: 0.7407 - val_acc: 0.6844\n",
            "Epoch 122/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4670 - acc: 0.7735 - val_loss: 0.7407 - val_acc: 0.6622\n",
            "Epoch 123/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4330 - acc: 0.8021 - val_loss: 0.7093 - val_acc: 0.6844\n",
            "Epoch 124/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4676 - acc: 0.7537 - val_loss: 0.7288 - val_acc: 0.6533\n",
            "Epoch 125/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4708 - acc: 0.7756 - val_loss: 0.6216 - val_acc: 0.6667\n",
            "Epoch 126/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4697 - acc: 0.7503 - val_loss: 0.7316 - val_acc: 0.7067\n",
            "Epoch 127/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4818 - acc: 0.7647 - val_loss: 0.7110 - val_acc: 0.7067\n",
            "Epoch 128/4000\n",
            "40/40 [==============================] - 17s 421ms/step - loss: 0.4605 - acc: 0.7884 - val_loss: 0.7067 - val_acc: 0.6889\n",
            "Epoch 129/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4397 - acc: 0.7796 - val_loss: 0.6636 - val_acc: 0.7244\n",
            "Epoch 130/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4970 - acc: 0.7864 - val_loss: 0.7482 - val_acc: 0.7067\n",
            "Epoch 131/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4204 - acc: 0.8183 - val_loss: 0.8433 - val_acc: 0.6800\n",
            "Epoch 132/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4477 - acc: 0.7875 - val_loss: 0.8060 - val_acc: 0.6711\n",
            "Epoch 133/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4637 - acc: 0.8176 - val_loss: 0.6937 - val_acc: 0.7111\n",
            "Epoch 134/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4252 - acc: 0.7904 - val_loss: 0.6794 - val_acc: 0.7289\n",
            "Epoch 135/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4619 - acc: 0.7827 - val_loss: 0.8606 - val_acc: 0.6933\n",
            "Epoch 136/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4602 - acc: 0.7950 - val_loss: 0.7146 - val_acc: 0.7333\n",
            "Epoch 137/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4649 - acc: 0.7708 - val_loss: 0.8933 - val_acc: 0.6756\n",
            "Epoch 138/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4661 - acc: 0.7693 - val_loss: 0.6813 - val_acc: 0.6978\n",
            "Epoch 139/4000\n",
            "40/40 [==============================] - 17s 421ms/step - loss: 0.4646 - acc: 0.7490 - val_loss: 0.8185 - val_acc: 0.6889\n",
            "Epoch 140/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4494 - acc: 0.7886 - val_loss: 0.6978 - val_acc: 0.6533\n",
            "Epoch 141/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4663 - acc: 0.8060 - val_loss: 0.8018 - val_acc: 0.6756\n",
            "Epoch 142/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4537 - acc: 0.7898 - val_loss: 0.8492 - val_acc: 0.6978\n",
            "Epoch 143/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4655 - acc: 0.7697 - val_loss: 0.7645 - val_acc: 0.7022\n",
            "Epoch 144/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4780 - acc: 0.7373 - val_loss: 0.6879 - val_acc: 0.6844\n",
            "Epoch 145/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4443 - acc: 0.8037 - val_loss: 0.8456 - val_acc: 0.6578\n",
            "Epoch 146/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4965 - acc: 0.7468 - val_loss: 0.8233 - val_acc: 0.6756\n",
            "Epoch 147/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4487 - acc: 0.7575 - val_loss: 0.7739 - val_acc: 0.6800\n",
            "Epoch 148/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4741 - acc: 0.7738 - val_loss: 0.8780 - val_acc: 0.7022\n",
            "Epoch 149/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.4846 - acc: 0.7614 - val_loss: 0.8408 - val_acc: 0.6889\n",
            "Epoch 150/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4458 - acc: 0.7683 - val_loss: 0.7743 - val_acc: 0.7289\n",
            "Epoch 151/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4169 - acc: 0.7952 - val_loss: 0.8007 - val_acc: 0.6978\n",
            "Epoch 152/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4462 - acc: 0.7854 - val_loss: 0.7749 - val_acc: 0.6978\n",
            "Epoch 153/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4092 - acc: 0.8118 - val_loss: 0.8674 - val_acc: 0.6978\n",
            "Epoch 154/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4604 - acc: 0.7996 - val_loss: 0.8576 - val_acc: 0.6933\n",
            "Epoch 155/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3892 - acc: 0.8127 - val_loss: 0.8342 - val_acc: 0.6800\n",
            "Epoch 156/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4016 - acc: 0.8117 - val_loss: 0.9627 - val_acc: 0.7022\n",
            "Epoch 157/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4630 - acc: 0.7767 - val_loss: 0.9884 - val_acc: 0.6978\n",
            "Epoch 158/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.4390 - acc: 0.7915 - val_loss: 0.8336 - val_acc: 0.7067\n",
            "Epoch 159/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4308 - acc: 0.8066 - val_loss: 0.7428 - val_acc: 0.6756\n",
            "Epoch 160/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.4522 - acc: 0.7787 - val_loss: 0.8041 - val_acc: 0.6800\n",
            "Epoch 161/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4452 - acc: 0.7804 - val_loss: 0.8204 - val_acc: 0.6978\n",
            "Epoch 162/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4113 - acc: 0.7952 - val_loss: 0.7696 - val_acc: 0.7111\n",
            "Epoch 163/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4629 - acc: 0.7900 - val_loss: 0.8527 - val_acc: 0.7022\n",
            "Epoch 164/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4487 - acc: 0.8069 - val_loss: 0.7426 - val_acc: 0.7111\n",
            "Epoch 165/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4329 - acc: 0.7768 - val_loss: 0.7628 - val_acc: 0.7067\n",
            "Epoch 166/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4388 - acc: 0.7969 - val_loss: 0.8638 - val_acc: 0.7022\n",
            "Epoch 167/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4214 - acc: 0.7856 - val_loss: 0.8294 - val_acc: 0.6800\n",
            "Epoch 168/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4221 - acc: 0.7856 - val_loss: 0.9535 - val_acc: 0.6756\n",
            "Epoch 169/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4239 - acc: 0.7926 - val_loss: 0.7540 - val_acc: 0.7156\n",
            "Epoch 170/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4526 - acc: 0.7885 - val_loss: 0.8821 - val_acc: 0.6889\n",
            "Epoch 171/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.4196 - acc: 0.7967 - val_loss: 0.7522 - val_acc: 0.7333\n",
            "Epoch 172/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4485 - acc: 0.7830 - val_loss: 0.7389 - val_acc: 0.7111\n",
            "Epoch 173/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4229 - acc: 0.8048 - val_loss: 0.7780 - val_acc: 0.6933\n",
            "Epoch 174/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4069 - acc: 0.8080 - val_loss: 0.8267 - val_acc: 0.7244\n",
            "Epoch 175/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4522 - acc: 0.7983 - val_loss: 0.8461 - val_acc: 0.6667\n",
            "Epoch 176/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4277 - acc: 0.8022 - val_loss: 0.7352 - val_acc: 0.6844\n",
            "Epoch 177/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4704 - acc: 0.7791 - val_loss: 0.7982 - val_acc: 0.7022\n",
            "Epoch 178/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4270 - acc: 0.7843 - val_loss: 0.8580 - val_acc: 0.6711\n",
            "Epoch 179/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.3923 - acc: 0.8123 - val_loss: 0.8344 - val_acc: 0.6711\n",
            "Epoch 180/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4387 - acc: 0.7883 - val_loss: 0.7321 - val_acc: 0.7067\n",
            "Epoch 181/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4536 - acc: 0.8073 - val_loss: 0.8904 - val_acc: 0.7156\n",
            "Epoch 182/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.5439 - acc: 0.7591 - val_loss: 0.7810 - val_acc: 0.7022\n",
            "Epoch 183/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4075 - acc: 0.8189 - val_loss: 1.0443 - val_acc: 0.6844\n",
            "Epoch 184/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4545 - acc: 0.7717 - val_loss: 1.0045 - val_acc: 0.7067\n",
            "Epoch 185/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4208 - acc: 0.8213 - val_loss: 0.7085 - val_acc: 0.7200\n",
            "Epoch 186/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.3960 - acc: 0.8239 - val_loss: 0.9741 - val_acc: 0.6756\n",
            "Epoch 187/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4182 - acc: 0.7777 - val_loss: 0.7471 - val_acc: 0.7200\n",
            "Epoch 188/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4308 - acc: 0.8086 - val_loss: 1.0892 - val_acc: 0.6933\n",
            "Epoch 189/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3868 - acc: 0.8282 - val_loss: 1.0868 - val_acc: 0.6622\n",
            "Epoch 190/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4121 - acc: 0.8034 - val_loss: 0.8487 - val_acc: 0.6533\n",
            "Epoch 191/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.4058 - acc: 0.7962 - val_loss: 0.6938 - val_acc: 0.6844\n",
            "Epoch 192/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4292 - acc: 0.7913 - val_loss: 0.8993 - val_acc: 0.6844\n",
            "Epoch 193/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4560 - acc: 0.7851 - val_loss: 0.9816 - val_acc: 0.6756\n",
            "Epoch 194/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4263 - acc: 0.7804 - val_loss: 0.8598 - val_acc: 0.6889\n",
            "Epoch 195/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4226 - acc: 0.7962 - val_loss: 0.7583 - val_acc: 0.6756\n",
            "Epoch 196/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.4391 - acc: 0.7946 - val_loss: 0.8808 - val_acc: 0.6844\n",
            "Epoch 197/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3798 - acc: 0.8230 - val_loss: 0.7733 - val_acc: 0.6800\n",
            "Epoch 198/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.4221 - acc: 0.8068 - val_loss: 0.7954 - val_acc: 0.7200\n",
            "Epoch 199/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4362 - acc: 0.7825 - val_loss: 1.0779 - val_acc: 0.7022\n",
            "Epoch 200/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4102 - acc: 0.7992 - val_loss: 0.8442 - val_acc: 0.6933\n",
            "Epoch 201/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.4499 - acc: 0.8232 - val_loss: 0.9315 - val_acc: 0.7022\n",
            "Epoch 202/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4057 - acc: 0.8097 - val_loss: 0.9014 - val_acc: 0.6756\n",
            "Epoch 203/4000\n",
            "40/40 [==============================] - 17s 421ms/step - loss: 0.3692 - acc: 0.8167 - val_loss: 0.6593 - val_acc: 0.7200\n",
            "Epoch 204/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4522 - acc: 0.7785 - val_loss: 0.9954 - val_acc: 0.6756\n",
            "Epoch 205/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4166 - acc: 0.7983 - val_loss: 0.7243 - val_acc: 0.7022\n",
            "Epoch 206/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4085 - acc: 0.8341 - val_loss: 0.9053 - val_acc: 0.7067\n",
            "Epoch 207/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3913 - acc: 0.8064 - val_loss: 0.7887 - val_acc: 0.6800\n",
            "Epoch 208/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3764 - acc: 0.8113 - val_loss: 0.9145 - val_acc: 0.6889\n",
            "Epoch 209/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4274 - acc: 0.8043 - val_loss: 0.8567 - val_acc: 0.6711\n",
            "Epoch 210/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3954 - acc: 0.8111 - val_loss: 0.8461 - val_acc: 0.6844\n",
            "Epoch 211/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3961 - acc: 0.8020 - val_loss: 0.9180 - val_acc: 0.6800\n",
            "Epoch 212/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.4143 - acc: 0.8065 - val_loss: 0.9273 - val_acc: 0.6400\n",
            "Epoch 213/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4301 - acc: 0.7636 - val_loss: 1.1461 - val_acc: 0.6711\n",
            "Epoch 214/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3741 - acc: 0.8434 - val_loss: 0.8899 - val_acc: 0.7067\n",
            "Epoch 215/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4572 - acc: 0.7940 - val_loss: 0.9800 - val_acc: 0.6711\n",
            "Epoch 216/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3851 - acc: 0.8107 - val_loss: 0.8446 - val_acc: 0.6889\n",
            "Epoch 217/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4238 - acc: 0.8105 - val_loss: 0.8614 - val_acc: 0.6578\n",
            "Epoch 218/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4332 - acc: 0.8141 - val_loss: 0.9620 - val_acc: 0.6800\n",
            "Epoch 219/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4003 - acc: 0.8143 - val_loss: 0.8571 - val_acc: 0.6844\n",
            "Epoch 220/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3796 - acc: 0.8347 - val_loss: 1.0205 - val_acc: 0.7111\n",
            "Epoch 221/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4110 - acc: 0.7883 - val_loss: 1.2592 - val_acc: 0.6711\n",
            "Epoch 222/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4784 - acc: 0.7441 - val_loss: 0.9988 - val_acc: 0.6756\n",
            "Epoch 223/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4205 - acc: 0.8025 - val_loss: 0.9321 - val_acc: 0.6933\n",
            "Epoch 224/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4160 - acc: 0.8120 - val_loss: 1.0047 - val_acc: 0.6711\n",
            "Epoch 225/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4052 - acc: 0.8011 - val_loss: 1.0332 - val_acc: 0.6578\n",
            "Epoch 226/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3795 - acc: 0.8219 - val_loss: 1.0149 - val_acc: 0.6933\n",
            "Epoch 227/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4294 - acc: 0.8004 - val_loss: 1.0836 - val_acc: 0.7111\n",
            "Epoch 228/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4373 - acc: 0.8149 - val_loss: 1.0014 - val_acc: 0.6800\n",
            "Epoch 229/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4034 - acc: 0.8323 - val_loss: 0.9560 - val_acc: 0.6756\n",
            "Epoch 230/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3903 - acc: 0.8235 - val_loss: 1.0226 - val_acc: 0.6844\n",
            "Epoch 231/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4280 - acc: 0.7862 - val_loss: 0.9830 - val_acc: 0.6844\n",
            "Epoch 232/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.4335 - acc: 0.7925 - val_loss: 1.0646 - val_acc: 0.6756\n",
            "Epoch 233/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.3629 - acc: 0.8346 - val_loss: 1.0865 - val_acc: 0.6667\n",
            "Epoch 234/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3844 - acc: 0.8089 - val_loss: 0.8522 - val_acc: 0.6889\n",
            "Epoch 235/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3909 - acc: 0.8273 - val_loss: 1.0769 - val_acc: 0.7067\n",
            "Epoch 236/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4087 - acc: 0.8344 - val_loss: 1.1216 - val_acc: 0.6844\n",
            "Epoch 237/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4096 - acc: 0.8230 - val_loss: 1.0936 - val_acc: 0.7022\n",
            "Epoch 238/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4001 - acc: 0.8361 - val_loss: 0.8154 - val_acc: 0.6800\n",
            "Epoch 239/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3915 - acc: 0.8079 - val_loss: 0.8643 - val_acc: 0.7111\n",
            "Epoch 240/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3808 - acc: 0.8067 - val_loss: 1.0561 - val_acc: 0.7111\n",
            "Epoch 241/4000\n",
            "40/40 [==============================] - 17s 422ms/step - loss: 0.3774 - acc: 0.8379 - val_loss: 1.0234 - val_acc: 0.6800\n",
            "Epoch 242/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4365 - acc: 0.7935 - val_loss: 1.0425 - val_acc: 0.7067\n",
            "Epoch 243/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4357 - acc: 0.7808 - val_loss: 0.9830 - val_acc: 0.6800\n",
            "Epoch 244/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.4293 - acc: 0.8071 - val_loss: 0.9159 - val_acc: 0.7111\n",
            "Epoch 245/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3998 - acc: 0.8129 - val_loss: 0.9115 - val_acc: 0.7022\n",
            "Epoch 246/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3656 - acc: 0.8465 - val_loss: 1.1139 - val_acc: 0.6444\n",
            "Epoch 247/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4489 - acc: 0.8055 - val_loss: 1.1416 - val_acc: 0.6756\n",
            "Epoch 248/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.4096 - acc: 0.8104 - val_loss: 1.0608 - val_acc: 0.6489\n",
            "Epoch 249/4000\n",
            "40/40 [==============================] - 17s 422ms/step - loss: 0.3799 - acc: 0.8244 - val_loss: 0.8035 - val_acc: 0.7067\n",
            "Epoch 250/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.3591 - acc: 0.8579 - val_loss: 0.9642 - val_acc: 0.6978\n",
            "Epoch 251/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3876 - acc: 0.8387 - val_loss: 1.1370 - val_acc: 0.6622\n",
            "Epoch 252/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.3826 - acc: 0.8290 - val_loss: 0.9907 - val_acc: 0.7111\n",
            "Epoch 253/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3992 - acc: 0.8026 - val_loss: 0.9490 - val_acc: 0.7022\n",
            "Epoch 254/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.3497 - acc: 0.8091 - val_loss: 0.9091 - val_acc: 0.7156\n",
            "Epoch 255/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4020 - acc: 0.8113 - val_loss: 1.0942 - val_acc: 0.6756\n",
            "Epoch 256/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4032 - acc: 0.8119 - val_loss: 1.1224 - val_acc: 0.6489\n",
            "Epoch 257/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3613 - acc: 0.8316 - val_loss: 0.9556 - val_acc: 0.7111\n",
            "Epoch 258/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4460 - acc: 0.8090 - val_loss: 1.0088 - val_acc: 0.6622\n",
            "Epoch 259/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3525 - acc: 0.8299 - val_loss: 1.2258 - val_acc: 0.6711\n",
            "Epoch 260/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3909 - acc: 0.8327 - val_loss: 1.0059 - val_acc: 0.6844\n",
            "Epoch 261/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.4254 - acc: 0.8433 - val_loss: 0.8702 - val_acc: 0.7333\n",
            "Epoch 262/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3557 - acc: 0.8322 - val_loss: 0.9849 - val_acc: 0.6578\n",
            "Epoch 263/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3529 - acc: 0.8460 - val_loss: 1.1665 - val_acc: 0.6489\n",
            "Epoch 264/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.4333 - acc: 0.7974 - val_loss: 1.2377 - val_acc: 0.7156\n",
            "Epoch 265/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3918 - acc: 0.8269 - val_loss: 0.8786 - val_acc: 0.7111\n",
            "Epoch 266/4000\n",
            "40/40 [==============================] - 16s 415ms/step - loss: 0.3619 - acc: 0.8430 - val_loss: 0.9489 - val_acc: 0.6889\n",
            "Epoch 267/4000\n",
            "40/40 [==============================] - 16s 414ms/step - loss: 0.3935 - acc: 0.8245 - val_loss: 1.3778 - val_acc: 0.6844\n",
            "Epoch 268/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3851 - acc: 0.8356 - val_loss: 0.9675 - val_acc: 0.6889\n",
            "Epoch 269/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3654 - acc: 0.8384 - val_loss: 0.9717 - val_acc: 0.6933\n",
            "Epoch 270/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3866 - acc: 0.8386 - val_loss: 1.1360 - val_acc: 0.7067\n",
            "Epoch 271/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4721 - acc: 0.7868 - val_loss: 1.0658 - val_acc: 0.6800\n",
            "Epoch 272/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4430 - acc: 0.8137 - val_loss: 0.9245 - val_acc: 0.6889\n",
            "Epoch 273/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.3759 - acc: 0.8214 - val_loss: 1.0366 - val_acc: 0.6711\n",
            "Epoch 274/4000\n",
            "40/40 [==============================] - 17s 422ms/step - loss: 0.4083 - acc: 0.8052 - val_loss: 1.2104 - val_acc: 0.6711\n",
            "Epoch 275/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3926 - acc: 0.8215 - val_loss: 0.7878 - val_acc: 0.6578\n",
            "Epoch 276/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4054 - acc: 0.7972 - val_loss: 1.1013 - val_acc: 0.7067\n",
            "Epoch 277/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4153 - acc: 0.8139 - val_loss: 1.2796 - val_acc: 0.7244\n",
            "Epoch 278/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3555 - acc: 0.8427 - val_loss: 1.0962 - val_acc: 0.6844\n",
            "Epoch 279/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4187 - acc: 0.8144 - val_loss: 0.8516 - val_acc: 0.7289\n",
            "Epoch 280/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3652 - acc: 0.8348 - val_loss: 1.0175 - val_acc: 0.6889\n",
            "Epoch 281/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3366 - acc: 0.8798 - val_loss: 1.1347 - val_acc: 0.6667\n",
            "Epoch 282/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3772 - acc: 0.8234 - val_loss: 0.9181 - val_acc: 0.7067\n",
            "Epoch 283/4000\n",
            "40/40 [==============================] - 17s 420ms/step - loss: 0.4157 - acc: 0.8085 - val_loss: 1.0889 - val_acc: 0.6889\n",
            "Epoch 284/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3564 - acc: 0.8446 - val_loss: 0.9254 - val_acc: 0.7111\n",
            "Epoch 285/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3471 - acc: 0.8527 - val_loss: 1.0888 - val_acc: 0.7156\n",
            "Epoch 286/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3561 - acc: 0.8537 - val_loss: 1.1852 - val_acc: 0.7333\n",
            "Epoch 287/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.4238 - acc: 0.8241 - val_loss: 0.8802 - val_acc: 0.6933\n",
            "Epoch 288/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3858 - acc: 0.8306 - val_loss: 0.8493 - val_acc: 0.6844\n",
            "Epoch 289/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3552 - acc: 0.8288 - val_loss: 0.9576 - val_acc: 0.6978\n",
            "Epoch 290/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3368 - acc: 0.8315 - val_loss: 1.0432 - val_acc: 0.6844\n",
            "Epoch 291/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3296 - acc: 0.8663 - val_loss: 1.2955 - val_acc: 0.6800\n",
            "Epoch 292/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.4197 - acc: 0.8137 - val_loss: 1.1169 - val_acc: 0.6756\n",
            "Epoch 293/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3642 - acc: 0.8483 - val_loss: 1.0343 - val_acc: 0.6622\n",
            "Epoch 294/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3580 - acc: 0.8603 - val_loss: 1.0776 - val_acc: 0.7289\n",
            "Epoch 295/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3311 - acc: 0.8368 - val_loss: 1.3633 - val_acc: 0.6444\n",
            "Epoch 296/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4042 - acc: 0.8147 - val_loss: 1.0349 - val_acc: 0.6933\n",
            "Epoch 297/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3170 - acc: 0.8670 - val_loss: 1.3772 - val_acc: 0.6978\n",
            "Epoch 298/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3798 - acc: 0.8290 - val_loss: 1.0733 - val_acc: 0.6889\n",
            "Epoch 299/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.4135 - acc: 0.8257 - val_loss: 0.8820 - val_acc: 0.6711\n",
            "Epoch 300/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3561 - acc: 0.8293 - val_loss: 1.0936 - val_acc: 0.6444\n",
            "Epoch 301/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3685 - acc: 0.8376 - val_loss: 0.9928 - val_acc: 0.6844\n",
            "Epoch 302/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3852 - acc: 0.8367 - val_loss: 0.9669 - val_acc: 0.7244\n",
            "Epoch 303/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3564 - acc: 0.8152 - val_loss: 1.0751 - val_acc: 0.6711\n",
            "Epoch 304/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3261 - acc: 0.8558 - val_loss: 0.9196 - val_acc: 0.6711\n",
            "Epoch 305/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3495 - acc: 0.8373 - val_loss: 0.9188 - val_acc: 0.6933\n",
            "Epoch 306/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3500 - acc: 0.8705 - val_loss: 1.2981 - val_acc: 0.6667\n",
            "Epoch 307/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3823 - acc: 0.8243 - val_loss: 1.0354 - val_acc: 0.7067\n",
            "Epoch 308/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3974 - acc: 0.8186 - val_loss: 1.3058 - val_acc: 0.6889\n",
            "Epoch 309/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3758 - acc: 0.8659 - val_loss: 1.3075 - val_acc: 0.6800\n",
            "Epoch 310/4000\n",
            "40/40 [==============================] - 16s 419ms/step - loss: 0.4060 - acc: 0.8325 - val_loss: 1.0630 - val_acc: 0.6889\n",
            "Epoch 311/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3093 - acc: 0.8488 - val_loss: 0.9832 - val_acc: 0.6844\n",
            "Epoch 312/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3522 - acc: 0.8420 - val_loss: 1.3872 - val_acc: 0.7378\n",
            "Epoch 313/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.3149 - acc: 0.8764 - val_loss: 1.1963 - val_acc: 0.6711\n",
            "Epoch 314/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3921 - acc: 0.8421 - val_loss: 1.1762 - val_acc: 0.6800\n",
            "Epoch 315/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3917 - acc: 0.8363 - val_loss: 1.1576 - val_acc: 0.6756\n",
            "Epoch 316/4000\n",
            "40/40 [==============================] - 17s 423ms/step - loss: 0.3606 - acc: 0.8349 - val_loss: 1.1536 - val_acc: 0.6844\n",
            "Epoch 317/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3819 - acc: 0.8509 - val_loss: 0.9755 - val_acc: 0.6889\n",
            "Epoch 318/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3511 - acc: 0.8572 - val_loss: 0.8916 - val_acc: 0.6978\n",
            "Epoch 319/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3603 - acc: 0.8355 - val_loss: 0.9416 - val_acc: 0.6800\n",
            "Epoch 320/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3088 - acc: 0.8552 - val_loss: 1.3602 - val_acc: 0.6756\n",
            "Epoch 321/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3348 - acc: 0.8465 - val_loss: 1.5526 - val_acc: 0.6622\n",
            "Epoch 322/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3423 - acc: 0.8343 - val_loss: 1.3853 - val_acc: 0.6800\n",
            "Epoch 323/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.3758 - acc: 0.8531 - val_loss: 0.8354 - val_acc: 0.6889\n",
            "Epoch 324/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3397 - acc: 0.8463 - val_loss: 1.2159 - val_acc: 0.6711\n",
            "Epoch 325/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3855 - acc: 0.8417 - val_loss: 1.2194 - val_acc: 0.6889\n",
            "Epoch 326/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2758 - acc: 0.8770 - val_loss: 1.1540 - val_acc: 0.6800\n",
            "Epoch 327/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3644 - acc: 0.8205 - val_loss: 1.3033 - val_acc: 0.6444\n",
            "Epoch 328/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3184 - acc: 0.8631 - val_loss: 1.3187 - val_acc: 0.6800\n",
            "Epoch 329/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3030 - acc: 0.8780 - val_loss: 1.1322 - val_acc: 0.7156\n",
            "Epoch 330/4000\n",
            "40/40 [==============================] - 16s 418ms/step - loss: 0.4303 - acc: 0.8216 - val_loss: 0.8409 - val_acc: 0.6933\n",
            "Epoch 331/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3710 - acc: 0.8379 - val_loss: 0.8740 - val_acc: 0.6889\n",
            "Epoch 332/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3530 - acc: 0.8415 - val_loss: 1.1503 - val_acc: 0.7156\n",
            "Epoch 333/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3605 - acc: 0.8815 - val_loss: 1.2446 - val_acc: 0.7067\n",
            "Epoch 334/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3452 - acc: 0.8475 - val_loss: 1.1094 - val_acc: 0.6844\n",
            "Epoch 335/4000\n",
            "40/40 [==============================] - 16s 399ms/step - loss: 0.3060 - acc: 0.8589 - val_loss: 1.4087 - val_acc: 0.6933\n",
            "Epoch 336/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3645 - acc: 0.8212 - val_loss: 1.2335 - val_acc: 0.6889\n",
            "Epoch 337/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3564 - acc: 0.8345 - val_loss: 1.0761 - val_acc: 0.6933\n",
            "Epoch 338/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3424 - acc: 0.8327 - val_loss: 1.1267 - val_acc: 0.6756\n",
            "Epoch 339/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3475 - acc: 0.8446 - val_loss: 0.9877 - val_acc: 0.6667\n",
            "Epoch 340/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3963 - acc: 0.8395 - val_loss: 1.5136 - val_acc: 0.6756\n",
            "Epoch 341/4000\n",
            "40/40 [==============================] - 17s 421ms/step - loss: 0.4363 - acc: 0.8215 - val_loss: 1.1930 - val_acc: 0.6711\n",
            "Epoch 342/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3143 - acc: 0.8555 - val_loss: 1.0622 - val_acc: 0.6889\n",
            "Epoch 343/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3320 - acc: 0.8798 - val_loss: 1.3145 - val_acc: 0.6756\n",
            "Epoch 344/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3542 - acc: 0.8316 - val_loss: 1.2139 - val_acc: 0.6400\n",
            "Epoch 345/4000\n",
            "40/40 [==============================] - 17s 424ms/step - loss: 0.3611 - acc: 0.8426 - val_loss: 1.8597 - val_acc: 0.6356\n",
            "Epoch 346/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4475 - acc: 0.8136 - val_loss: 1.1467 - val_acc: 0.7022\n",
            "Epoch 347/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3006 - acc: 0.8592 - val_loss: 1.4349 - val_acc: 0.6667\n",
            "Epoch 348/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3827 - acc: 0.8409 - val_loss: 1.5227 - val_acc: 0.6844\n",
            "Epoch 349/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3262 - acc: 0.8441 - val_loss: 1.0102 - val_acc: 0.6622\n",
            "Epoch 350/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.3679 - acc: 0.8257 - val_loss: 0.9943 - val_acc: 0.7200\n",
            "Epoch 351/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3141 - acc: 0.8767 - val_loss: 0.9950 - val_acc: 0.6933\n",
            "Epoch 352/4000\n",
            "40/40 [==============================] - 17s 422ms/step - loss: 0.3503 - acc: 0.8291 - val_loss: 1.0587 - val_acc: 0.7156\n",
            "Epoch 353/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3461 - acc: 0.8494 - val_loss: 1.4303 - val_acc: 0.7200\n",
            "Epoch 354/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.3124 - acc: 0.8552 - val_loss: 1.1265 - val_acc: 0.7067\n",
            "Epoch 355/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3010 - acc: 0.8593 - val_loss: 1.0552 - val_acc: 0.6844\n",
            "Epoch 356/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3613 - acc: 0.8581 - val_loss: 1.0737 - val_acc: 0.7289\n",
            "Epoch 357/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3405 - acc: 0.8568 - val_loss: 0.9595 - val_acc: 0.7022\n",
            "Epoch 358/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3393 - acc: 0.8369 - val_loss: 1.2992 - val_acc: 0.6889\n",
            "Epoch 359/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3201 - acc: 0.8429 - val_loss: 1.0392 - val_acc: 0.6800\n",
            "Epoch 360/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3415 - acc: 0.8508 - val_loss: 1.3095 - val_acc: 0.7111\n",
            "Epoch 361/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3469 - acc: 0.8481 - val_loss: 1.3039 - val_acc: 0.6978\n",
            "Epoch 362/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3585 - acc: 0.8237 - val_loss: 0.9161 - val_acc: 0.6933\n",
            "Epoch 363/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3677 - acc: 0.8410 - val_loss: 0.9934 - val_acc: 0.6889\n",
            "Epoch 364/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3323 - acc: 0.8638 - val_loss: 1.1217 - val_acc: 0.6622\n",
            "Epoch 365/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2879 - acc: 0.8561 - val_loss: 1.5055 - val_acc: 0.6978\n",
            "Epoch 366/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3774 - acc: 0.8375 - val_loss: 1.2184 - val_acc: 0.7067\n",
            "Epoch 367/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4064 - acc: 0.8537 - val_loss: 1.5943 - val_acc: 0.6978\n",
            "Epoch 368/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3832 - acc: 0.8456 - val_loss: 1.1150 - val_acc: 0.6978\n",
            "Epoch 369/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3330 - acc: 0.8365 - val_loss: 1.2504 - val_acc: 0.6800\n",
            "Epoch 370/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3172 - acc: 0.8693 - val_loss: 1.3266 - val_acc: 0.7289\n",
            "Epoch 371/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4041 - acc: 0.8134 - val_loss: 1.2185 - val_acc: 0.6711\n",
            "Epoch 372/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.3076 - acc: 0.8794 - val_loss: 1.2894 - val_acc: 0.6756\n",
            "Epoch 373/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3294 - acc: 0.8881 - val_loss: 1.0353 - val_acc: 0.7067\n",
            "Epoch 374/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3486 - acc: 0.8799 - val_loss: 1.1289 - val_acc: 0.6978\n",
            "Epoch 375/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3075 - acc: 0.8458 - val_loss: 1.0282 - val_acc: 0.6844\n",
            "Epoch 376/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3584 - acc: 0.8762 - val_loss: 1.3081 - val_acc: 0.6800\n",
            "Epoch 377/4000\n",
            "40/40 [==============================] - 16s 419ms/step - loss: 0.2987 - acc: 0.8697 - val_loss: 3.1827 - val_acc: 0.5956\n",
            "Epoch 378/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3513 - acc: 0.8399 - val_loss: 1.1616 - val_acc: 0.6800\n",
            "Epoch 379/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2973 - acc: 0.8790 - val_loss: 1.0907 - val_acc: 0.7067\n",
            "Epoch 380/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3814 - acc: 0.8280 - val_loss: 0.9587 - val_acc: 0.6889\n",
            "Epoch 381/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3527 - acc: 0.8326 - val_loss: 0.8972 - val_acc: 0.7200\n",
            "Epoch 382/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2900 - acc: 0.8644 - val_loss: 1.2292 - val_acc: 0.6756\n",
            "Epoch 383/4000\n",
            "40/40 [==============================] - 17s 420ms/step - loss: 0.3357 - acc: 0.8535 - val_loss: 0.9220 - val_acc: 0.7022\n",
            "Epoch 384/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3142 - acc: 0.8608 - val_loss: 1.4333 - val_acc: 0.7200\n",
            "Epoch 385/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2824 - acc: 0.8614 - val_loss: 1.2756 - val_acc: 0.6667\n",
            "Epoch 386/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3807 - acc: 0.8056 - val_loss: 1.1286 - val_acc: 0.7067\n",
            "Epoch 387/4000\n",
            "40/40 [==============================] - 17s 410ms/step - loss: 0.2898 - acc: 0.8789 - val_loss: 1.0848 - val_acc: 0.6800\n",
            "Epoch 388/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3359 - acc: 0.8488 - val_loss: 1.0598 - val_acc: 0.6889\n",
            "Epoch 389/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3190 - acc: 0.8678 - val_loss: 1.2652 - val_acc: 0.7022\n",
            "Epoch 390/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3507 - acc: 0.8497 - val_loss: 1.2801 - val_acc: 0.6844\n",
            "Epoch 391/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3142 - acc: 0.8772 - val_loss: 1.1753 - val_acc: 0.6711\n",
            "Epoch 392/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3500 - acc: 0.8421 - val_loss: 1.4149 - val_acc: 0.6889\n",
            "Epoch 393/4000\n",
            "40/40 [==============================] - 16s 401ms/step - loss: 0.3445 - acc: 0.8628 - val_loss: 1.1512 - val_acc: 0.7378\n",
            "Epoch 394/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3136 - acc: 0.8624 - val_loss: 1.3982 - val_acc: 0.6756\n",
            "Epoch 395/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3623 - acc: 0.8499 - val_loss: 1.5756 - val_acc: 0.7022\n",
            "Epoch 396/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.4033 - acc: 0.8281 - val_loss: 1.4875 - val_acc: 0.6978\n",
            "Epoch 397/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.3968 - acc: 0.8379 - val_loss: 1.3019 - val_acc: 0.7022\n",
            "Epoch 398/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3519 - acc: 0.8394 - val_loss: 2.0406 - val_acc: 0.6756\n",
            "Epoch 399/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3567 - acc: 0.8539 - val_loss: 1.1539 - val_acc: 0.6356\n",
            "Epoch 400/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3017 - acc: 0.8696 - val_loss: 1.2253 - val_acc: 0.6800\n",
            "Epoch 401/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.2857 - acc: 0.8839 - val_loss: 1.2685 - val_acc: 0.6622\n",
            "Epoch 402/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3173 - acc: 0.8618 - val_loss: 1.3967 - val_acc: 0.7022\n",
            "Epoch 403/4000\n",
            "40/40 [==============================] - 17s 420ms/step - loss: 0.2788 - acc: 0.8769 - val_loss: 1.2220 - val_acc: 0.7022\n",
            "Epoch 404/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3392 - acc: 0.8564 - val_loss: 1.5554 - val_acc: 0.6978\n",
            "Epoch 405/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4337 - acc: 0.8153 - val_loss: 1.1114 - val_acc: 0.6889\n",
            "Epoch 406/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3591 - acc: 0.8616 - val_loss: 1.2627 - val_acc: 0.6489\n",
            "Epoch 407/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3917 - acc: 0.8563 - val_loss: 1.3099 - val_acc: 0.7067\n",
            "Epoch 408/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3881 - acc: 0.8311 - val_loss: 1.0219 - val_acc: 0.7156\n",
            "Epoch 409/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3453 - acc: 0.8535 - val_loss: 1.2620 - val_acc: 0.7289\n",
            "Epoch 410/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3656 - acc: 0.8444 - val_loss: 1.1692 - val_acc: 0.6844\n",
            "Epoch 411/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3480 - acc: 0.8505 - val_loss: 1.0400 - val_acc: 0.6933\n",
            "Epoch 412/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3159 - acc: 0.8619 - val_loss: 1.3790 - val_acc: 0.6800\n",
            "Epoch 413/4000\n",
            "40/40 [==============================] - 16s 414ms/step - loss: 0.3291 - acc: 0.8783 - val_loss: 1.2631 - val_acc: 0.6711\n",
            "Epoch 414/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3369 - acc: 0.8386 - val_loss: 1.3310 - val_acc: 0.7200\n",
            "Epoch 415/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.4045 - acc: 0.8643 - val_loss: 1.1397 - val_acc: 0.6533\n",
            "Epoch 416/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3695 - acc: 0.8569 - val_loss: 1.3157 - val_acc: 0.6711\n",
            "Epoch 417/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3385 - acc: 0.8652 - val_loss: 1.4999 - val_acc: 0.6667\n",
            "Epoch 418/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3583 - acc: 0.8427 - val_loss: 1.3905 - val_acc: 0.7333\n",
            "Epoch 419/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3840 - acc: 0.8558 - val_loss: 1.6252 - val_acc: 0.6444\n",
            "Epoch 420/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2837 - acc: 0.8821 - val_loss: 1.0036 - val_acc: 0.6622\n",
            "Epoch 421/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3009 - acc: 0.8843 - val_loss: 1.3742 - val_acc: 0.7067\n",
            "Epoch 422/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3470 - acc: 0.8524 - val_loss: 0.9977 - val_acc: 0.6933\n",
            "Epoch 423/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3397 - acc: 0.8585 - val_loss: 1.4259 - val_acc: 0.6578\n",
            "Epoch 424/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3134 - acc: 0.8469 - val_loss: 1.4566 - val_acc: 0.6533\n",
            "Epoch 425/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3599 - acc: 0.8327 - val_loss: 1.2007 - val_acc: 0.6844\n",
            "Epoch 426/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3421 - acc: 0.8777 - val_loss: 1.0582 - val_acc: 0.6578\n",
            "Epoch 427/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2761 - acc: 0.8821 - val_loss: 1.5776 - val_acc: 0.6711\n",
            "Epoch 428/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3296 - acc: 0.8410 - val_loss: 1.4737 - val_acc: 0.7022\n",
            "Epoch 429/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3741 - acc: 0.8532 - val_loss: 1.2377 - val_acc: 0.6489\n",
            "Epoch 430/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3785 - acc: 0.8428 - val_loss: 1.3800 - val_acc: 0.6667\n",
            "Epoch 431/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4170 - acc: 0.8184 - val_loss: 1.0119 - val_acc: 0.7111\n",
            "Epoch 432/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2997 - acc: 0.8828 - val_loss: 1.3331 - val_acc: 0.6844\n",
            "Epoch 433/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3561 - acc: 0.8406 - val_loss: 1.5688 - val_acc: 0.6800\n",
            "Epoch 434/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2601 - acc: 0.8872 - val_loss: 1.3381 - val_acc: 0.6622\n",
            "Epoch 435/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3067 - acc: 0.8426 - val_loss: 0.9704 - val_acc: 0.7156\n",
            "Epoch 436/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3043 - acc: 0.8730 - val_loss: 1.2988 - val_acc: 0.6844\n",
            "Epoch 437/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.3053 - acc: 0.8661 - val_loss: 1.7405 - val_acc: 0.7244\n",
            "Epoch 438/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3135 - acc: 0.8840 - val_loss: 1.1994 - val_acc: 0.6800\n",
            "Epoch 439/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2950 - acc: 0.8600 - val_loss: 1.2987 - val_acc: 0.6800\n",
            "Epoch 440/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2572 - acc: 0.9014 - val_loss: 1.3286 - val_acc: 0.6756\n",
            "Epoch 441/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4137 - acc: 0.8594 - val_loss: 1.4501 - val_acc: 0.6889\n",
            "Epoch 442/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3051 - acc: 0.8674 - val_loss: 1.4653 - val_acc: 0.7200\n",
            "Epoch 443/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3253 - acc: 0.8719 - val_loss: 1.3456 - val_acc: 0.7378\n",
            "Epoch 444/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3127 - acc: 0.8544 - val_loss: 1.3713 - val_acc: 0.6400\n",
            "Epoch 445/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3090 - acc: 0.8641 - val_loss: 1.3387 - val_acc: 0.6844\n",
            "Epoch 446/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3743 - acc: 0.8447 - val_loss: 1.6420 - val_acc: 0.7022\n",
            "Epoch 447/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.3339 - acc: 0.8861 - val_loss: 1.5066 - val_acc: 0.6667\n",
            "Epoch 448/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3277 - acc: 0.8538 - val_loss: 1.5099 - val_acc: 0.6622\n",
            "Epoch 449/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3577 - acc: 0.8685 - val_loss: 1.2677 - val_acc: 0.6889\n",
            "Epoch 450/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3428 - acc: 0.8454 - val_loss: 1.3660 - val_acc: 0.6889\n",
            "Epoch 451/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3150 - acc: 0.8756 - val_loss: 1.3533 - val_acc: 0.7156\n",
            "Epoch 452/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3118 - acc: 0.8651 - val_loss: 1.2651 - val_acc: 0.6711\n",
            "Epoch 453/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3585 - acc: 0.8518 - val_loss: 1.1710 - val_acc: 0.6933\n",
            "Epoch 454/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2457 - acc: 0.8926 - val_loss: 1.5207 - val_acc: 0.6756\n",
            "Epoch 455/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3697 - acc: 0.8354 - val_loss: 1.1277 - val_acc: 0.7200\n",
            "Epoch 456/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2828 - acc: 0.8627 - val_loss: 1.2139 - val_acc: 0.6800\n",
            "Epoch 457/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3451 - acc: 0.8453 - val_loss: 1.2532 - val_acc: 0.6844\n",
            "Epoch 458/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3322 - acc: 0.8783 - val_loss: 1.3817 - val_acc: 0.6844\n",
            "Epoch 459/4000\n",
            "40/40 [==============================] - 16s 401ms/step - loss: 0.3116 - acc: 0.8647 - val_loss: 1.5481 - val_acc: 0.6889\n",
            "Epoch 460/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.2834 - acc: 0.8914 - val_loss: 1.0244 - val_acc: 0.6844\n",
            "Epoch 461/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.3266 - acc: 0.8549 - val_loss: 1.4147 - val_acc: 0.7067\n",
            "Epoch 462/4000\n",
            "40/40 [==============================] - 17s 410ms/step - loss: 0.3220 - acc: 0.8584 - val_loss: 1.3984 - val_acc: 0.6578\n",
            "Epoch 463/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3182 - acc: 0.8413 - val_loss: 1.8244 - val_acc: 0.6800\n",
            "Epoch 464/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3567 - acc: 0.8442 - val_loss: 2.0069 - val_acc: 0.6489\n",
            "Epoch 465/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.4253 - acc: 0.8350 - val_loss: 1.5099 - val_acc: 0.6622\n",
            "Epoch 466/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3129 - acc: 0.8678 - val_loss: 1.3857 - val_acc: 0.6756\n",
            "Epoch 467/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3281 - acc: 0.8683 - val_loss: 1.0518 - val_acc: 0.6889\n",
            "Epoch 468/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3346 - acc: 0.8600 - val_loss: 1.0777 - val_acc: 0.6533\n",
            "Epoch 469/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3018 - acc: 0.8657 - val_loss: 1.1752 - val_acc: 0.7244\n",
            "Epoch 470/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3619 - acc: 0.8558 - val_loss: 1.4710 - val_acc: 0.7467\n",
            "Epoch 471/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.4048 - acc: 0.8299 - val_loss: 1.5684 - val_acc: 0.6533\n",
            "Epoch 472/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3400 - acc: 0.8648 - val_loss: 1.0341 - val_acc: 0.7067\n",
            "Epoch 473/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2816 - acc: 0.8795 - val_loss: 1.2166 - val_acc: 0.6489\n",
            "Epoch 474/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3271 - acc: 0.8461 - val_loss: 1.2727 - val_acc: 0.6978\n",
            "Epoch 475/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3704 - acc: 0.8180 - val_loss: 1.1706 - val_acc: 0.6489\n",
            "Epoch 476/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3280 - acc: 0.8708 - val_loss: 0.9557 - val_acc: 0.7244\n",
            "Epoch 477/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3145 - acc: 0.8673 - val_loss: 1.0223 - val_acc: 0.6889\n",
            "Epoch 478/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2662 - acc: 0.8611 - val_loss: 1.3061 - val_acc: 0.6978\n",
            "Epoch 479/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2812 - acc: 0.8850 - val_loss: 1.4318 - val_acc: 0.7422\n",
            "Epoch 480/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2988 - acc: 0.8853 - val_loss: 1.3688 - val_acc: 0.6800\n",
            "Epoch 481/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2950 - acc: 0.8846 - val_loss: 1.4792 - val_acc: 0.6622\n",
            "Epoch 482/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3522 - acc: 0.8331 - val_loss: 1.5272 - val_acc: 0.6844\n",
            "Epoch 483/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3189 - acc: 0.8403 - val_loss: 1.6930 - val_acc: 0.7111\n",
            "Epoch 484/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3688 - acc: 0.8138 - val_loss: 1.5492 - val_acc: 0.6800\n",
            "Epoch 485/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3518 - acc: 0.8801 - val_loss: 1.2096 - val_acc: 0.7200\n",
            "Epoch 486/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3121 - acc: 0.8666 - val_loss: 1.6479 - val_acc: 0.6578\n",
            "Epoch 487/4000\n",
            "40/40 [==============================] - 16s 418ms/step - loss: 0.2313 - acc: 0.9108 - val_loss: 1.2119 - val_acc: 0.7111\n",
            "Epoch 488/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3311 - acc: 0.8362 - val_loss: 1.2869 - val_acc: 0.6889\n",
            "Epoch 489/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2741 - acc: 0.8799 - val_loss: 1.6591 - val_acc: 0.6756\n",
            "Epoch 490/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3431 - acc: 0.8481 - val_loss: 1.5496 - val_acc: 0.7467\n",
            "Epoch 491/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3817 - acc: 0.8430 - val_loss: 1.3477 - val_acc: 0.7244\n",
            "Epoch 492/4000\n",
            "40/40 [==============================] - 16s 418ms/step - loss: 0.2713 - acc: 0.8591 - val_loss: 2.7714 - val_acc: 0.6400\n",
            "Epoch 493/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3521 - acc: 0.8238 - val_loss: 1.5205 - val_acc: 0.6578\n",
            "Epoch 494/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3260 - acc: 0.8709 - val_loss: 1.1111 - val_acc: 0.6933\n",
            "Epoch 495/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3052 - acc: 0.8705 - val_loss: 1.6338 - val_acc: 0.6667\n",
            "Epoch 496/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3091 - acc: 0.8723 - val_loss: 0.9889 - val_acc: 0.7467\n",
            "Epoch 497/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2875 - acc: 0.8674 - val_loss: 1.6422 - val_acc: 0.6667\n",
            "Epoch 498/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3591 - acc: 0.8598 - val_loss: 1.5362 - val_acc: 0.7289\n",
            "Epoch 499/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2686 - acc: 0.8679 - val_loss: 1.6422 - val_acc: 0.6978\n",
            "Epoch 500/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3021 - acc: 0.8810 - val_loss: 1.3763 - val_acc: 0.6889\n",
            "Epoch 501/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2473 - acc: 0.9017 - val_loss: 1.2709 - val_acc: 0.6756\n",
            "Epoch 502/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3287 - acc: 0.8523 - val_loss: 1.0693 - val_acc: 0.6978\n",
            "Epoch 503/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3019 - acc: 0.8745 - val_loss: 1.0865 - val_acc: 0.6844\n",
            "Epoch 504/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2850 - acc: 0.8745 - val_loss: 1.4490 - val_acc: 0.6711\n",
            "Epoch 505/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3276 - acc: 0.8639 - val_loss: 1.4627 - val_acc: 0.6844\n",
            "Epoch 506/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3764 - acc: 0.8693 - val_loss: 1.2760 - val_acc: 0.6756\n",
            "Epoch 507/4000\n",
            "40/40 [==============================] - 17s 420ms/step - loss: 0.2764 - acc: 0.8822 - val_loss: 1.5334 - val_acc: 0.7111\n",
            "Epoch 508/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2692 - acc: 0.8888 - val_loss: 1.3894 - val_acc: 0.6978\n",
            "Epoch 509/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2975 - acc: 0.8703 - val_loss: 1.3771 - val_acc: 0.6933\n",
            "Epoch 510/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3837 - acc: 0.8459 - val_loss: 1.2039 - val_acc: 0.7022\n",
            "Epoch 511/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3086 - acc: 0.8704 - val_loss: 1.3025 - val_acc: 0.7289\n",
            "Epoch 512/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2846 - acc: 0.8755 - val_loss: 1.2224 - val_acc: 0.6622\n",
            "Epoch 513/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2759 - acc: 0.8815 - val_loss: 1.2022 - val_acc: 0.6933\n",
            "Epoch 514/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3340 - acc: 0.8686 - val_loss: 1.8193 - val_acc: 0.7156\n",
            "Epoch 515/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2993 - acc: 0.8784 - val_loss: 1.8141 - val_acc: 0.7111\n",
            "Epoch 516/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2662 - acc: 0.8837 - val_loss: 1.1238 - val_acc: 0.6578\n",
            "Epoch 517/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2954 - acc: 0.8610 - val_loss: 1.2272 - val_acc: 0.7067\n",
            "Epoch 518/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3614 - acc: 0.8568 - val_loss: 1.3238 - val_acc: 0.6933\n",
            "Epoch 519/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.2536 - acc: 0.9023 - val_loss: 1.0583 - val_acc: 0.7067\n",
            "Epoch 520/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3167 - acc: 0.8717 - val_loss: 1.7160 - val_acc: 0.6844\n",
            "Epoch 521/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3140 - acc: 0.8771 - val_loss: 1.4283 - val_acc: 0.6800\n",
            "Epoch 522/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2749 - acc: 0.9029 - val_loss: 1.3645 - val_acc: 0.6800\n",
            "Epoch 523/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3105 - acc: 0.8770 - val_loss: 1.1853 - val_acc: 0.6711\n",
            "Epoch 524/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2764 - acc: 0.8790 - val_loss: 1.0074 - val_acc: 0.6844\n",
            "Epoch 525/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3191 - acc: 0.8875 - val_loss: 1.3367 - val_acc: 0.6933\n",
            "Epoch 526/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3564 - acc: 0.8289 - val_loss: 1.2122 - val_acc: 0.7244\n",
            "Epoch 527/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3056 - acc: 0.8785 - val_loss: 1.4421 - val_acc: 0.7244\n",
            "Epoch 528/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3539 - acc: 0.8460 - val_loss: 1.4087 - val_acc: 0.6489\n",
            "Epoch 529/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2882 - acc: 0.8760 - val_loss: 1.4266 - val_acc: 0.6889\n",
            "Epoch 530/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2903 - acc: 0.8528 - val_loss: 1.5320 - val_acc: 0.6800\n",
            "Epoch 531/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.3200 - acc: 0.8480 - val_loss: 1.5237 - val_acc: 0.6667\n",
            "Epoch 532/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2752 - acc: 0.8831 - val_loss: 1.1004 - val_acc: 0.7200\n",
            "Epoch 533/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2954 - acc: 0.8831 - val_loss: 0.9471 - val_acc: 0.7644\n",
            "Epoch 534/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2322 - acc: 0.8874 - val_loss: 1.8531 - val_acc: 0.5911\n",
            "Epoch 535/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2936 - acc: 0.9003 - val_loss: 1.1624 - val_acc: 0.6933\n",
            "Epoch 536/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.3150 - acc: 0.8718 - val_loss: 1.7519 - val_acc: 0.7111\n",
            "Epoch 537/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2778 - acc: 0.8834 - val_loss: 1.6829 - val_acc: 0.6711\n",
            "Epoch 538/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3470 - acc: 0.8648 - val_loss: 1.1434 - val_acc: 0.6844\n",
            "Epoch 539/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3254 - acc: 0.8629 - val_loss: 1.4556 - val_acc: 0.6756\n",
            "Epoch 540/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2722 - acc: 0.8871 - val_loss: 1.6376 - val_acc: 0.6933\n",
            "Epoch 541/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2824 - acc: 0.8838 - val_loss: 1.2871 - val_acc: 0.7378\n",
            "Epoch 542/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2441 - acc: 0.9000 - val_loss: 1.3160 - val_acc: 0.7067\n",
            "Epoch 543/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2927 - acc: 0.8653 - val_loss: 1.3454 - val_acc: 0.6800\n",
            "Epoch 544/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2833 - acc: 0.8774 - val_loss: 1.4430 - val_acc: 0.6667\n",
            "Epoch 545/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3609 - acc: 0.8466 - val_loss: 1.4261 - val_acc: 0.6622\n",
            "Epoch 546/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3472 - acc: 0.8914 - val_loss: 1.5790 - val_acc: 0.6844\n",
            "Epoch 547/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2948 - acc: 0.8600 - val_loss: 1.8783 - val_acc: 0.7156\n",
            "Epoch 548/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2311 - acc: 0.9007 - val_loss: 1.4943 - val_acc: 0.7378\n",
            "Epoch 549/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3517 - acc: 0.8637 - val_loss: 1.3303 - val_acc: 0.6889\n",
            "Epoch 550/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2632 - acc: 0.8757 - val_loss: 1.4996 - val_acc: 0.6933\n",
            "Epoch 551/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3790 - acc: 0.8378 - val_loss: 1.4427 - val_acc: 0.7067\n",
            "Epoch 552/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3255 - acc: 0.8754 - val_loss: 1.3202 - val_acc: 0.7333\n",
            "Epoch 553/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2765 - acc: 0.8596 - val_loss: 1.5287 - val_acc: 0.7422\n",
            "Epoch 554/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3614 - acc: 0.8575 - val_loss: 1.4048 - val_acc: 0.7067\n",
            "Epoch 555/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2908 - acc: 0.8987 - val_loss: 1.1807 - val_acc: 0.7022\n",
            "Epoch 556/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.3217 - acc: 0.8546 - val_loss: 1.3016 - val_acc: 0.6978\n",
            "Epoch 557/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3141 - acc: 0.8621 - val_loss: 1.0078 - val_acc: 0.7200\n",
            "Epoch 558/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2563 - acc: 0.8801 - val_loss: 1.0277 - val_acc: 0.6889\n",
            "Epoch 559/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3035 - acc: 0.8823 - val_loss: 1.3545 - val_acc: 0.7378\n",
            "Epoch 560/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2243 - acc: 0.9136 - val_loss: 1.5891 - val_acc: 0.7289\n",
            "Epoch 561/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2474 - acc: 0.8922 - val_loss: 2.0441 - val_acc: 0.7200\n",
            "Epoch 562/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.2520 - acc: 0.8951 - val_loss: 1.4156 - val_acc: 0.7156\n",
            "Epoch 563/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2604 - acc: 0.8673 - val_loss: 1.5979 - val_acc: 0.7378\n",
            "Epoch 564/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3112 - acc: 0.8529 - val_loss: 1.3421 - val_acc: 0.6933\n",
            "Epoch 565/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2709 - acc: 0.8936 - val_loss: 2.4208 - val_acc: 0.6978\n",
            "Epoch 566/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.3420 - acc: 0.8752 - val_loss: 1.0852 - val_acc: 0.6978\n",
            "Epoch 567/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2913 - acc: 0.8636 - val_loss: 1.3938 - val_acc: 0.6756\n",
            "Epoch 568/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3790 - acc: 0.8419 - val_loss: 1.1813 - val_acc: 0.7244\n",
            "Epoch 569/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3326 - acc: 0.8431 - val_loss: 1.6089 - val_acc: 0.7111\n",
            "Epoch 570/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3227 - acc: 0.8493 - val_loss: 1.5536 - val_acc: 0.6933\n",
            "Epoch 571/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3498 - acc: 0.8461 - val_loss: 2.1698 - val_acc: 0.6889\n",
            "Epoch 572/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2618 - acc: 0.9064 - val_loss: 1.3009 - val_acc: 0.7200\n",
            "Epoch 573/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.3923 - acc: 0.8500 - val_loss: 1.4645 - val_acc: 0.7022\n",
            "Epoch 574/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2812 - acc: 0.8687 - val_loss: 1.5644 - val_acc: 0.7022\n",
            "Epoch 575/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3933 - acc: 0.8486 - val_loss: 1.2958 - val_acc: 0.6844\n",
            "Epoch 576/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.3344 - acc: 0.8625 - val_loss: 1.3888 - val_acc: 0.7067\n",
            "Epoch 577/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3333 - acc: 0.8622 - val_loss: 1.1436 - val_acc: 0.7156\n",
            "Epoch 578/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3361 - acc: 0.8496 - val_loss: 1.1583 - val_acc: 0.6756\n",
            "Epoch 579/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3215 - acc: 0.8678 - val_loss: 1.0805 - val_acc: 0.7200\n",
            "Epoch 580/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2570 - acc: 0.8989 - val_loss: 1.3526 - val_acc: 0.7022\n",
            "Epoch 581/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.2889 - acc: 0.8716 - val_loss: 1.0754 - val_acc: 0.7067\n",
            "Epoch 582/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2994 - acc: 0.8822 - val_loss: 1.5233 - val_acc: 0.7244\n",
            "Epoch 583/4000\n",
            "40/40 [==============================] - 16s 416ms/step - loss: 0.2705 - acc: 0.8832 - val_loss: 1.1863 - val_acc: 0.6844\n",
            "Epoch 584/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3043 - acc: 0.8795 - val_loss: 1.3546 - val_acc: 0.6933\n",
            "Epoch 585/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3082 - acc: 0.8846 - val_loss: 1.4955 - val_acc: 0.7289\n",
            "Epoch 586/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2655 - acc: 0.8950 - val_loss: 2.1260 - val_acc: 0.6933\n",
            "Epoch 587/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2726 - acc: 0.8805 - val_loss: 1.2479 - val_acc: 0.6533\n",
            "Epoch 588/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2994 - acc: 0.8580 - val_loss: 1.3836 - val_acc: 0.6889\n",
            "Epoch 589/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2818 - acc: 0.8663 - val_loss: 1.5544 - val_acc: 0.6800\n",
            "Epoch 590/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2582 - acc: 0.8893 - val_loss: 1.1377 - val_acc: 0.6711\n",
            "Epoch 591/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3141 - acc: 0.8689 - val_loss: 1.7922 - val_acc: 0.6667\n",
            "Epoch 592/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2937 - acc: 0.8615 - val_loss: 1.7514 - val_acc: 0.6800\n",
            "Epoch 593/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3039 - acc: 0.8891 - val_loss: 1.4346 - val_acc: 0.7289\n",
            "Epoch 594/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3200 - acc: 0.8749 - val_loss: 1.0438 - val_acc: 0.7333\n",
            "Epoch 595/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3024 - acc: 0.8681 - val_loss: 1.3881 - val_acc: 0.6667\n",
            "Epoch 596/4000\n",
            "40/40 [==============================] - 16s 416ms/step - loss: 0.3257 - acc: 0.8653 - val_loss: 1.6737 - val_acc: 0.6978\n",
            "Epoch 597/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2583 - acc: 0.8951 - val_loss: 2.0052 - val_acc: 0.6711\n",
            "Epoch 598/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3799 - acc: 0.8641 - val_loss: 1.6297 - val_acc: 0.7111\n",
            "Epoch 599/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3845 - acc: 0.8637 - val_loss: 1.4387 - val_acc: 0.7022\n",
            "Epoch 600/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.2776 - acc: 0.8656 - val_loss: 1.5079 - val_acc: 0.7067\n",
            "Epoch 601/4000\n",
            "40/40 [==============================] - 16s 416ms/step - loss: 0.2811 - acc: 0.8876 - val_loss: 1.2885 - val_acc: 0.7156\n",
            "Epoch 602/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.2646 - acc: 0.9032 - val_loss: 1.4100 - val_acc: 0.6978\n",
            "Epoch 603/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3415 - acc: 0.8712 - val_loss: 1.9694 - val_acc: 0.6756\n",
            "Epoch 604/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3569 - acc: 0.8486 - val_loss: 1.7763 - val_acc: 0.6933\n",
            "Epoch 605/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2822 - acc: 0.8926 - val_loss: 1.4113 - val_acc: 0.7067\n",
            "Epoch 606/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.2259 - acc: 0.8966 - val_loss: 1.3599 - val_acc: 0.7156\n",
            "Epoch 607/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3443 - acc: 0.8510 - val_loss: 1.1603 - val_acc: 0.7422\n",
            "Epoch 608/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2906 - acc: 0.8707 - val_loss: 1.4075 - val_acc: 0.6267\n",
            "Epoch 609/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3071 - acc: 0.8518 - val_loss: 1.4683 - val_acc: 0.7022\n",
            "Epoch 610/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2896 - acc: 0.9004 - val_loss: 1.7074 - val_acc: 0.7422\n",
            "Epoch 611/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3082 - acc: 0.8711 - val_loss: 1.7494 - val_acc: 0.6889\n",
            "Epoch 612/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3226 - acc: 0.8665 - val_loss: 1.7188 - val_acc: 0.7067\n",
            "Epoch 613/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.2939 - acc: 0.8825 - val_loss: 1.3648 - val_acc: 0.7067\n",
            "Epoch 614/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2797 - acc: 0.8656 - val_loss: 1.6821 - val_acc: 0.7111\n",
            "Epoch 615/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2881 - acc: 0.8775 - val_loss: 1.7897 - val_acc: 0.6756\n",
            "Epoch 616/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3418 - acc: 0.8786 - val_loss: 1.3102 - val_acc: 0.6489\n",
            "Epoch 617/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2926 - acc: 0.8702 - val_loss: 1.0866 - val_acc: 0.7022\n",
            "Epoch 618/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3090 - acc: 0.8595 - val_loss: 1.1178 - val_acc: 0.7511\n",
            "Epoch 619/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2747 - acc: 0.9081 - val_loss: 1.4188 - val_acc: 0.7022\n",
            "Epoch 620/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2816 - acc: 0.8723 - val_loss: 1.3450 - val_acc: 0.7022\n",
            "Epoch 621/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2733 - acc: 0.8970 - val_loss: 1.2177 - val_acc: 0.6844\n",
            "Epoch 622/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2974 - acc: 0.8750 - val_loss: 1.2403 - val_acc: 0.7067\n",
            "Epoch 623/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2406 - acc: 0.9003 - val_loss: 1.5956 - val_acc: 0.6578\n",
            "Epoch 624/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.4047 - acc: 0.8525 - val_loss: 1.1918 - val_acc: 0.7022\n",
            "Epoch 625/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3668 - acc: 0.8365 - val_loss: 1.5874 - val_acc: 0.6756\n",
            "Epoch 626/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3315 - acc: 0.8663 - val_loss: 1.6133 - val_acc: 0.6711\n",
            "Epoch 627/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2782 - acc: 0.8886 - val_loss: 1.5395 - val_acc: 0.7022\n",
            "Epoch 628/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.2706 - acc: 0.8976 - val_loss: 1.6254 - val_acc: 0.6800\n",
            "Epoch 629/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3109 - acc: 0.8493 - val_loss: 1.2255 - val_acc: 0.7422\n",
            "Epoch 630/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3192 - acc: 0.8983 - val_loss: 1.6763 - val_acc: 0.6756\n",
            "Epoch 631/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3457 - acc: 0.8267 - val_loss: 1.2018 - val_acc: 0.7289\n",
            "Epoch 632/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3020 - acc: 0.8820 - val_loss: 1.1202 - val_acc: 0.7600\n",
            "Epoch 633/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2308 - acc: 0.9165 - val_loss: 1.2570 - val_acc: 0.7289\n",
            "Epoch 634/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2796 - acc: 0.8832 - val_loss: 1.2851 - val_acc: 0.7111\n",
            "Epoch 635/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2673 - acc: 0.9003 - val_loss: 1.6684 - val_acc: 0.7022\n",
            "Epoch 636/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3032 - acc: 0.8788 - val_loss: 1.3052 - val_acc: 0.7067\n",
            "Epoch 637/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2632 - acc: 0.8793 - val_loss: 1.8027 - val_acc: 0.6978\n",
            "Epoch 638/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.2895 - acc: 0.8960 - val_loss: 1.8209 - val_acc: 0.6756\n",
            "Epoch 639/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4449 - acc: 0.8599 - val_loss: 1.3620 - val_acc: 0.6889\n",
            "Epoch 640/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2877 - acc: 0.8804 - val_loss: 1.4040 - val_acc: 0.6844\n",
            "Epoch 641/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3767 - acc: 0.8435 - val_loss: 1.1514 - val_acc: 0.7378\n",
            "Epoch 642/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3062 - acc: 0.8668 - val_loss: 1.1695 - val_acc: 0.7156\n",
            "Epoch 643/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2825 - acc: 0.8743 - val_loss: 1.0618 - val_acc: 0.7200\n",
            "Epoch 644/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2384 - acc: 0.8927 - val_loss: 1.1996 - val_acc: 0.6978\n",
            "Epoch 645/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2871 - acc: 0.8663 - val_loss: 1.3168 - val_acc: 0.6533\n",
            "Epoch 646/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2635 - acc: 0.8951 - val_loss: 1.2128 - val_acc: 0.7200\n",
            "Epoch 647/4000\n",
            "40/40 [==============================] - 17s 426ms/step - loss: 0.3047 - acc: 0.8909 - val_loss: 1.2907 - val_acc: 0.6756\n",
            "Epoch 648/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2767 - acc: 0.8644 - val_loss: 1.4571 - val_acc: 0.6844\n",
            "Epoch 649/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2821 - acc: 0.8666 - val_loss: 1.5759 - val_acc: 0.7244\n",
            "Epoch 650/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2966 - acc: 0.8999 - val_loss: 1.5543 - val_acc: 0.7244\n",
            "Epoch 651/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2993 - acc: 0.8931 - val_loss: 1.9297 - val_acc: 0.6044\n",
            "Epoch 652/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2710 - acc: 0.8726 - val_loss: 1.8155 - val_acc: 0.6844\n",
            "Epoch 653/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.4209 - acc: 0.8617 - val_loss: 1.1100 - val_acc: 0.7244\n",
            "Epoch 654/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3026 - acc: 0.8915 - val_loss: 1.3527 - val_acc: 0.6844\n",
            "Epoch 655/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2944 - acc: 0.8689 - val_loss: 1.7684 - val_acc: 0.7111\n",
            "Epoch 656/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3326 - acc: 0.8579 - val_loss: 2.0122 - val_acc: 0.6800\n",
            "Epoch 657/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2964 - acc: 0.8581 - val_loss: 1.5276 - val_acc: 0.7111\n",
            "Epoch 658/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3695 - acc: 0.8582 - val_loss: 1.5181 - val_acc: 0.6978\n",
            "Epoch 659/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2736 - acc: 0.8711 - val_loss: 1.6924 - val_acc: 0.7022\n",
            "Epoch 660/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3832 - acc: 0.8688 - val_loss: 1.4167 - val_acc: 0.7111\n",
            "Epoch 661/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2794 - acc: 0.8825 - val_loss: 1.3312 - val_acc: 0.7022\n",
            "Epoch 662/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2614 - acc: 0.8808 - val_loss: 1.7029 - val_acc: 0.6844\n",
            "Epoch 663/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2842 - acc: 0.8920 - val_loss: 1.3168 - val_acc: 0.6889\n",
            "Epoch 664/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3054 - acc: 0.8932 - val_loss: 1.6041 - val_acc: 0.7156\n",
            "Epoch 665/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2719 - acc: 0.8908 - val_loss: 1.7224 - val_acc: 0.7067\n",
            "Epoch 666/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2674 - acc: 0.8951 - val_loss: 2.0937 - val_acc: 0.6622\n",
            "Epoch 667/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3776 - acc: 0.8092 - val_loss: 2.1430 - val_acc: 0.6622\n",
            "Epoch 668/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2812 - acc: 0.8903 - val_loss: 1.0737 - val_acc: 0.7244\n",
            "Epoch 669/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2946 - acc: 0.8732 - val_loss: 1.1669 - val_acc: 0.7111\n",
            "Epoch 670/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3290 - acc: 0.8893 - val_loss: 1.9993 - val_acc: 0.7156\n",
            "Epoch 671/4000\n",
            "40/40 [==============================] - 17s 418ms/step - loss: 0.2746 - acc: 0.8764 - val_loss: 1.7388 - val_acc: 0.7200\n",
            "Epoch 672/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2983 - acc: 0.8492 - val_loss: 1.8138 - val_acc: 0.6800\n",
            "Epoch 673/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2555 - acc: 0.8909 - val_loss: 2.0822 - val_acc: 0.7200\n",
            "Epoch 674/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.2741 - acc: 0.8791 - val_loss: 1.4496 - val_acc: 0.7067\n",
            "Epoch 675/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2826 - acc: 0.8801 - val_loss: 1.2263 - val_acc: 0.7022\n",
            "Epoch 676/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3218 - acc: 0.8646 - val_loss: 1.4449 - val_acc: 0.7111\n",
            "Epoch 677/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3480 - acc: 0.8688 - val_loss: 1.3546 - val_acc: 0.6444\n",
            "Epoch 678/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2944 - acc: 0.8655 - val_loss: 1.9652 - val_acc: 0.7333\n",
            "Epoch 679/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2259 - acc: 0.9063 - val_loss: 1.7377 - val_acc: 0.7378\n",
            "Epoch 680/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.2767 - acc: 0.8927 - val_loss: 1.6931 - val_acc: 0.6622\n",
            "Epoch 681/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3113 - acc: 0.8827 - val_loss: 2.0221 - val_acc: 0.7022\n",
            "Epoch 682/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2779 - acc: 0.8812 - val_loss: 1.3321 - val_acc: 0.7111\n",
            "Epoch 683/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2850 - acc: 0.8932 - val_loss: 1.5485 - val_acc: 0.7289\n",
            "Epoch 684/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.2434 - acc: 0.8876 - val_loss: 2.1988 - val_acc: 0.7111\n",
            "Epoch 685/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2454 - acc: 0.9029 - val_loss: 1.3684 - val_acc: 0.7467\n",
            "Epoch 686/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2580 - acc: 0.8955 - val_loss: 1.8561 - val_acc: 0.6844\n",
            "Epoch 687/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3181 - acc: 0.8891 - val_loss: 3.4893 - val_acc: 0.6222\n",
            "Epoch 688/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3787 - acc: 0.8947 - val_loss: 1.5686 - val_acc: 0.6844\n",
            "Epoch 689/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3105 - acc: 0.8723 - val_loss: 1.7413 - val_acc: 0.7333\n",
            "Epoch 690/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2938 - acc: 0.8961 - val_loss: 1.6720 - val_acc: 0.6356\n",
            "Epoch 691/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3013 - acc: 0.8773 - val_loss: 1.7135 - val_acc: 0.7289\n",
            "Epoch 692/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3130 - acc: 0.8728 - val_loss: 1.8207 - val_acc: 0.6711\n",
            "Epoch 693/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.3123 - acc: 0.8777 - val_loss: 1.9092 - val_acc: 0.6978\n",
            "Epoch 694/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3408 - acc: 0.8520 - val_loss: 1.2042 - val_acc: 0.7067\n",
            "Epoch 695/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2231 - acc: 0.8990 - val_loss: 1.5145 - val_acc: 0.7244\n",
            "Epoch 696/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2909 - acc: 0.8939 - val_loss: 2.0898 - val_acc: 0.7200\n",
            "Epoch 697/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3202 - acc: 0.8870 - val_loss: 1.6784 - val_acc: 0.7156\n",
            "Epoch 698/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3160 - acc: 0.8792 - val_loss: 1.7523 - val_acc: 0.6622\n",
            "Epoch 699/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3844 - acc: 0.8745 - val_loss: 1.4584 - val_acc: 0.6800\n",
            "Epoch 700/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.2360 - acc: 0.9029 - val_loss: 1.8124 - val_acc: 0.7156\n",
            "Epoch 701/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2537 - acc: 0.8953 - val_loss: 1.2623 - val_acc: 0.7156\n",
            "Epoch 702/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3402 - acc: 0.8614 - val_loss: 1.2734 - val_acc: 0.7200\n",
            "Epoch 703/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.2890 - acc: 0.8883 - val_loss: 1.7754 - val_acc: 0.6800\n",
            "Epoch 704/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3212 - acc: 0.8813 - val_loss: 1.4397 - val_acc: 0.7200\n",
            "Epoch 705/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2814 - acc: 0.9061 - val_loss: 1.7015 - val_acc: 0.7244\n",
            "Epoch 706/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2777 - acc: 0.8791 - val_loss: 2.1978 - val_acc: 0.6578\n",
            "Epoch 707/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3356 - acc: 0.8533 - val_loss: 1.7817 - val_acc: 0.6933\n",
            "Epoch 708/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2754 - acc: 0.8886 - val_loss: 1.7801 - val_acc: 0.6489\n",
            "Epoch 709/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2691 - acc: 0.8773 - val_loss: 1.7904 - val_acc: 0.6978\n",
            "Epoch 710/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2996 - acc: 0.8832 - val_loss: 1.4057 - val_acc: 0.6933\n",
            "Epoch 711/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2401 - acc: 0.8998 - val_loss: 1.8475 - val_acc: 0.6800\n",
            "Epoch 712/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4794 - acc: 0.8562 - val_loss: 1.7761 - val_acc: 0.6933\n",
            "Epoch 713/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3169 - acc: 0.8569 - val_loss: 2.3698 - val_acc: 0.6711\n",
            "Epoch 714/4000\n",
            "40/40 [==============================] - 16s 399ms/step - loss: 0.3062 - acc: 0.8673 - val_loss: 1.3175 - val_acc: 0.6800\n",
            "Epoch 715/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2331 - acc: 0.9167 - val_loss: 1.5653 - val_acc: 0.6889\n",
            "Epoch 716/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2980 - acc: 0.8998 - val_loss: 1.8660 - val_acc: 0.7067\n",
            "Epoch 717/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3046 - acc: 0.8875 - val_loss: 1.0527 - val_acc: 0.6978\n",
            "Epoch 718/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2621 - acc: 0.8823 - val_loss: 1.6491 - val_acc: 0.7022\n",
            "Epoch 719/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3036 - acc: 0.8650 - val_loss: 1.6710 - val_acc: 0.7022\n",
            "Epoch 720/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.2412 - acc: 0.9036 - val_loss: 1.6574 - val_acc: 0.6844\n",
            "Epoch 721/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3170 - acc: 0.8673 - val_loss: 1.5381 - val_acc: 0.7422\n",
            "Epoch 722/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2750 - acc: 0.8757 - val_loss: 2.1912 - val_acc: 0.6933\n",
            "Epoch 723/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2635 - acc: 0.8986 - val_loss: 2.0621 - val_acc: 0.6622\n",
            "Epoch 724/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3450 - acc: 0.8516 - val_loss: 1.4549 - val_acc: 0.6622\n",
            "Epoch 725/4000\n",
            "40/40 [==============================] - 16s 401ms/step - loss: 0.3583 - acc: 0.8765 - val_loss: 1.9975 - val_acc: 0.6444\n",
            "Epoch 726/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3034 - acc: 0.8970 - val_loss: 1.5598 - val_acc: 0.7022\n",
            "Epoch 727/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2807 - acc: 0.8697 - val_loss: 2.2984 - val_acc: 0.7111\n",
            "Epoch 728/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2697 - acc: 0.8969 - val_loss: 1.4734 - val_acc: 0.6756\n",
            "Epoch 729/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3182 - acc: 0.8620 - val_loss: 1.4736 - val_acc: 0.7156\n",
            "Epoch 730/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.1974 - acc: 0.9198 - val_loss: 1.5942 - val_acc: 0.6800\n",
            "Epoch 731/4000\n",
            "40/40 [==============================] - 17s 412ms/step - loss: 0.2675 - acc: 0.8638 - val_loss: 2.1855 - val_acc: 0.7022\n",
            "Epoch 732/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3898 - acc: 0.8753 - val_loss: 1.4861 - val_acc: 0.7111\n",
            "Epoch 733/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2332 - acc: 0.8879 - val_loss: 1.8636 - val_acc: 0.6978\n",
            "Epoch 734/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2794 - acc: 0.8584 - val_loss: 1.4057 - val_acc: 0.6933\n",
            "Epoch 735/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3644 - acc: 0.8441 - val_loss: 1.5735 - val_acc: 0.7244\n",
            "Epoch 736/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.3148 - acc: 0.8827 - val_loss: 1.2264 - val_acc: 0.7333\n",
            "Epoch 737/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3339 - acc: 0.8671 - val_loss: 1.5725 - val_acc: 0.6933\n",
            "Epoch 738/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3811 - acc: 0.8604 - val_loss: 1.6381 - val_acc: 0.7289\n",
            "Epoch 739/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2824 - acc: 0.8887 - val_loss: 1.2565 - val_acc: 0.6844\n",
            "Epoch 740/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3315 - acc: 0.8759 - val_loss: 1.3719 - val_acc: 0.7200\n",
            "Epoch 741/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.2584 - acc: 0.8902 - val_loss: 1.5246 - val_acc: 0.6889\n",
            "Epoch 742/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2737 - acc: 0.8947 - val_loss: 1.2012 - val_acc: 0.7378\n",
            "Epoch 743/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3386 - acc: 0.8872 - val_loss: 1.6823 - val_acc: 0.6844\n",
            "Epoch 744/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2889 - acc: 0.8713 - val_loss: 1.3788 - val_acc: 0.7422\n",
            "Epoch 745/4000\n",
            "40/40 [==============================] - 16s 414ms/step - loss: 0.2460 - acc: 0.8963 - val_loss: 1.9725 - val_acc: 0.6933\n",
            "Epoch 746/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2769 - acc: 0.8841 - val_loss: 1.5810 - val_acc: 0.6622\n",
            "Epoch 747/4000\n",
            "40/40 [==============================] - 16s 401ms/step - loss: 0.2935 - acc: 0.8716 - val_loss: 1.2378 - val_acc: 0.7156\n",
            "Epoch 748/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2396 - acc: 0.9059 - val_loss: 1.5408 - val_acc: 0.7333\n",
            "Epoch 749/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.2264 - acc: 0.8985 - val_loss: 1.4920 - val_acc: 0.7156\n",
            "Epoch 750/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2702 - acc: 0.8773 - val_loss: 1.6626 - val_acc: 0.7022\n",
            "Epoch 751/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3051 - acc: 0.8892 - val_loss: 1.6531 - val_acc: 0.7422\n",
            "Epoch 752/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2634 - acc: 0.8920 - val_loss: 2.7685 - val_acc: 0.6933\n",
            "Epoch 753/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3197 - acc: 0.8931 - val_loss: 1.7788 - val_acc: 0.7067\n",
            "Epoch 754/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.2818 - acc: 0.8676 - val_loss: 1.5126 - val_acc: 0.6711\n",
            "Epoch 755/4000\n",
            "40/40 [==============================] - 17s 419ms/step - loss: 0.2912 - acc: 0.8809 - val_loss: 2.3885 - val_acc: 0.6978\n",
            "Epoch 756/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2957 - acc: 0.8741 - val_loss: 3.5280 - val_acc: 0.6267\n",
            "Epoch 757/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2611 - acc: 0.8643 - val_loss: 2.5104 - val_acc: 0.6622\n",
            "Epoch 758/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3834 - acc: 0.8622 - val_loss: 1.7891 - val_acc: 0.7244\n",
            "Epoch 759/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2733 - acc: 0.9020 - val_loss: 1.9101 - val_acc: 0.6489\n",
            "Epoch 760/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2489 - acc: 0.8790 - val_loss: 2.0124 - val_acc: 0.6800\n",
            "Epoch 761/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2380 - acc: 0.9057 - val_loss: 2.2426 - val_acc: 0.7067\n",
            "Epoch 762/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2046 - acc: 0.9202 - val_loss: 1.3932 - val_acc: 0.7022\n",
            "Epoch 763/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2728 - acc: 0.9142 - val_loss: 1.4815 - val_acc: 0.7200\n",
            "Epoch 764/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3559 - acc: 0.8835 - val_loss: 1.4117 - val_acc: 0.6978\n",
            "Epoch 765/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2592 - acc: 0.8833 - val_loss: 1.4193 - val_acc: 0.6978\n",
            "Epoch 766/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2869 - acc: 0.8630 - val_loss: 1.3058 - val_acc: 0.7067\n",
            "Epoch 767/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2274 - acc: 0.9078 - val_loss: 1.5267 - val_acc: 0.7067\n",
            "Epoch 768/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2303 - acc: 0.9144 - val_loss: 1.6754 - val_acc: 0.7067\n",
            "Epoch 769/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2377 - acc: 0.8935 - val_loss: 1.4990 - val_acc: 0.7200\n",
            "Epoch 770/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2475 - acc: 0.9043 - val_loss: 1.6369 - val_acc: 0.7422\n",
            "Epoch 771/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2328 - acc: 0.8960 - val_loss: 1.7951 - val_acc: 0.7378\n",
            "Epoch 772/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2621 - acc: 0.9099 - val_loss: 1.1532 - val_acc: 0.6978\n",
            "Epoch 773/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2211 - acc: 0.9040 - val_loss: 1.5513 - val_acc: 0.6444\n",
            "Epoch 774/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2924 - acc: 0.8629 - val_loss: 1.0978 - val_acc: 0.7111\n",
            "Epoch 775/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2399 - acc: 0.8975 - val_loss: 1.0091 - val_acc: 0.7378\n",
            "Epoch 776/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3163 - acc: 0.8975 - val_loss: 1.4245 - val_acc: 0.6800\n",
            "Epoch 777/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2934 - acc: 0.8664 - val_loss: 1.7175 - val_acc: 0.7333\n",
            "Epoch 778/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2733 - acc: 0.8772 - val_loss: 1.7927 - val_acc: 0.7111\n",
            "Epoch 779/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3173 - acc: 0.8769 - val_loss: 2.7437 - val_acc: 0.6756\n",
            "Epoch 780/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4185 - acc: 0.8610 - val_loss: 2.2040 - val_acc: 0.7022\n",
            "Epoch 781/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2814 - acc: 0.8693 - val_loss: 1.2423 - val_acc: 0.6933\n",
            "Epoch 782/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2549 - acc: 0.8825 - val_loss: 2.2836 - val_acc: 0.6400\n",
            "Epoch 783/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2513 - acc: 0.8879 - val_loss: 2.0609 - val_acc: 0.7422\n",
            "Epoch 784/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3676 - acc: 0.8656 - val_loss: 1.4213 - val_acc: 0.6844\n",
            "Epoch 785/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2306 - acc: 0.9192 - val_loss: 1.9256 - val_acc: 0.7156\n",
            "Epoch 786/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3055 - acc: 0.8774 - val_loss: 1.4348 - val_acc: 0.7111\n",
            "Epoch 787/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.2086 - acc: 0.9206 - val_loss: 2.0313 - val_acc: 0.6978\n",
            "Epoch 788/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.2568 - acc: 0.9103 - val_loss: 1.6651 - val_acc: 0.7067\n",
            "Epoch 789/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.4327 - acc: 0.8536 - val_loss: 1.7348 - val_acc: 0.7333\n",
            "Epoch 790/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.4026 - acc: 0.8677 - val_loss: 1.8024 - val_acc: 0.6978\n",
            "Epoch 791/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2356 - acc: 0.9012 - val_loss: 3.3684 - val_acc: 0.6578\n",
            "Epoch 792/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3683 - acc: 0.9001 - val_loss: 1.8483 - val_acc: 0.6889\n",
            "Epoch 793/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2439 - acc: 0.9137 - val_loss: 1.8456 - val_acc: 0.6622\n",
            "Epoch 794/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2828 - acc: 0.8724 - val_loss: 1.8691 - val_acc: 0.6800\n",
            "Epoch 795/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2532 - acc: 0.8815 - val_loss: 2.1418 - val_acc: 0.6889\n",
            "Epoch 796/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.3091 - acc: 0.8656 - val_loss: 1.7909 - val_acc: 0.6933\n",
            "Epoch 797/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.2558 - acc: 0.8907 - val_loss: 1.7734 - val_acc: 0.6356\n",
            "Epoch 798/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3767 - acc: 0.8347 - val_loss: 1.7044 - val_acc: 0.6844\n",
            "Epoch 799/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2781 - acc: 0.9026 - val_loss: 2.5429 - val_acc: 0.6622\n",
            "Epoch 800/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.3609 - acc: 0.8720 - val_loss: 2.2128 - val_acc: 0.7244\n",
            "Epoch 801/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3340 - acc: 0.8830 - val_loss: 1.8928 - val_acc: 0.7111\n",
            "Epoch 802/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2879 - acc: 0.8913 - val_loss: 1.9478 - val_acc: 0.6622\n",
            "Epoch 803/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2456 - acc: 0.9052 - val_loss: 1.8147 - val_acc: 0.6844\n",
            "Epoch 804/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3298 - acc: 0.8681 - val_loss: 1.8425 - val_acc: 0.6889\n",
            "Epoch 805/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2576 - acc: 0.8965 - val_loss: 2.4676 - val_acc: 0.6756\n",
            "Epoch 806/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2205 - acc: 0.9194 - val_loss: 2.5309 - val_acc: 0.7156\n",
            "Epoch 807/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3557 - acc: 0.8850 - val_loss: 1.5868 - val_acc: 0.6489\n",
            "Epoch 808/4000\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.3279 - acc: 0.8578 - val_loss: 1.7304 - val_acc: 0.7067\n",
            "Epoch 809/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2585 - acc: 0.8989 - val_loss: 1.8388 - val_acc: 0.7200\n",
            "Epoch 810/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3343 - acc: 0.8679 - val_loss: 1.8569 - val_acc: 0.7022\n",
            "Epoch 811/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2757 - acc: 0.8620 - val_loss: 2.2148 - val_acc: 0.7022\n",
            "Epoch 812/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2550 - acc: 0.9029 - val_loss: 1.9781 - val_acc: 0.6978\n",
            "Epoch 813/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2711 - acc: 0.8769 - val_loss: 1.4811 - val_acc: 0.6756\n",
            "Epoch 814/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2727 - acc: 0.8819 - val_loss: 1.6186 - val_acc: 0.7022\n",
            "Epoch 815/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2895 - acc: 0.8964 - val_loss: 1.4553 - val_acc: 0.7111\n",
            "Epoch 816/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3356 - acc: 0.8723 - val_loss: 1.1303 - val_acc: 0.7200\n",
            "Epoch 817/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2999 - acc: 0.8771 - val_loss: 1.4143 - val_acc: 0.6844\n",
            "Epoch 818/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2653 - acc: 0.8788 - val_loss: 1.5726 - val_acc: 0.6667\n",
            "Epoch 819/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2632 - acc: 0.8880 - val_loss: 1.6039 - val_acc: 0.6756\n",
            "Epoch 820/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2521 - acc: 0.8923 - val_loss: 3.0167 - val_acc: 0.5733\n",
            "Epoch 821/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2438 - acc: 0.8801 - val_loss: 1.4432 - val_acc: 0.6533\n",
            "Epoch 822/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3606 - acc: 0.8330 - val_loss: 2.1503 - val_acc: 0.6978\n",
            "Epoch 823/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2963 - acc: 0.8857 - val_loss: 2.3768 - val_acc: 0.6578\n",
            "Epoch 824/4000\n",
            "40/40 [==============================] - 16s 401ms/step - loss: 0.2970 - acc: 0.8689 - val_loss: 1.2592 - val_acc: 0.6978\n",
            "Epoch 825/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2708 - acc: 0.8852 - val_loss: 1.4058 - val_acc: 0.6844\n",
            "Epoch 826/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2118 - acc: 0.8975 - val_loss: 2.1050 - val_acc: 0.6400\n",
            "Epoch 827/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2431 - acc: 0.9203 - val_loss: 1.7964 - val_acc: 0.6578\n",
            "Epoch 828/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2776 - acc: 0.8800 - val_loss: 2.5743 - val_acc: 0.6667\n",
            "Epoch 829/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2992 - acc: 0.8747 - val_loss: 3.1280 - val_acc: 0.6667\n",
            "Epoch 830/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3557 - acc: 0.8690 - val_loss: 1.8211 - val_acc: 0.6800\n",
            "Epoch 831/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3220 - acc: 0.8893 - val_loss: 1.6655 - val_acc: 0.7111\n",
            "Epoch 832/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2192 - acc: 0.9178 - val_loss: 2.0137 - val_acc: 0.7022\n",
            "Epoch 833/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.4034 - acc: 0.8628 - val_loss: 2.4346 - val_acc: 0.6711\n",
            "Epoch 834/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2751 - acc: 0.8928 - val_loss: 1.4875 - val_acc: 0.6844\n",
            "Epoch 835/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2626 - acc: 0.8789 - val_loss: 1.7557 - val_acc: 0.7289\n",
            "Epoch 836/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2269 - acc: 0.8961 - val_loss: 1.6229 - val_acc: 0.6844\n",
            "Epoch 837/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2898 - acc: 0.8948 - val_loss: 1.3828 - val_acc: 0.7067\n",
            "Epoch 838/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2771 - acc: 0.8811 - val_loss: 1.3784 - val_acc: 0.7067\n",
            "Epoch 839/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2166 - acc: 0.9100 - val_loss: 2.1393 - val_acc: 0.7556\n",
            "Epoch 840/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3893 - acc: 0.8805 - val_loss: 2.3979 - val_acc: 0.7067\n",
            "Epoch 841/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2846 - acc: 0.8905 - val_loss: 1.5478 - val_acc: 0.7200\n",
            "Epoch 842/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3105 - acc: 0.8852 - val_loss: 2.1947 - val_acc: 0.6400\n",
            "Epoch 843/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2890 - acc: 0.8673 - val_loss: 1.5195 - val_acc: 0.6667\n",
            "Epoch 844/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.3356 - acc: 0.8591 - val_loss: 1.7502 - val_acc: 0.6711\n",
            "Epoch 845/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2397 - acc: 0.8967 - val_loss: 1.5845 - val_acc: 0.6711\n",
            "Epoch 846/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.3669 - acc: 0.8795 - val_loss: 1.5461 - val_acc: 0.7067\n",
            "Epoch 847/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2891 - acc: 0.8960 - val_loss: 1.5779 - val_acc: 0.6978\n",
            "Epoch 848/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3407 - acc: 0.8748 - val_loss: 1.5991 - val_acc: 0.6933\n",
            "Epoch 849/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3167 - acc: 0.8843 - val_loss: 2.2962 - val_acc: 0.7022\n",
            "Epoch 850/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2373 - acc: 0.9078 - val_loss: 2.4220 - val_acc: 0.6356\n",
            "Epoch 851/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2255 - acc: 0.9181 - val_loss: 2.1051 - val_acc: 0.6756\n",
            "Epoch 852/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3285 - acc: 0.8608 - val_loss: 1.3057 - val_acc: 0.6933\n",
            "Epoch 853/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3080 - acc: 0.8777 - val_loss: 1.6920 - val_acc: 0.6978\n",
            "Epoch 854/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3331 - acc: 0.8690 - val_loss: 1.9006 - val_acc: 0.6933\n",
            "Epoch 855/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2490 - acc: 0.8931 - val_loss: 1.9005 - val_acc: 0.6667\n",
            "Epoch 856/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2810 - acc: 0.9010 - val_loss: 1.5420 - val_acc: 0.6800\n",
            "Epoch 857/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.3083 - acc: 0.9053 - val_loss: 1.2076 - val_acc: 0.7067\n",
            "Epoch 858/4000\n",
            "40/40 [==============================] - 16s 418ms/step - loss: 0.2822 - acc: 0.9081 - val_loss: 1.5474 - val_acc: 0.6978\n",
            "Epoch 859/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2434 - acc: 0.8955 - val_loss: 1.6842 - val_acc: 0.7156\n",
            "Epoch 860/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2988 - acc: 0.8779 - val_loss: 1.3804 - val_acc: 0.6756\n",
            "Epoch 861/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3497 - acc: 0.8750 - val_loss: 1.6521 - val_acc: 0.6978\n",
            "Epoch 862/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3297 - acc: 0.8697 - val_loss: 1.6439 - val_acc: 0.7467\n",
            "Epoch 863/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2754 - acc: 0.8937 - val_loss: 1.1014 - val_acc: 0.6800\n",
            "Epoch 864/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2408 - acc: 0.8963 - val_loss: 2.7077 - val_acc: 0.6800\n",
            "Epoch 865/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2769 - acc: 0.8879 - val_loss: 1.8806 - val_acc: 0.6533\n",
            "Epoch 866/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2438 - acc: 0.8870 - val_loss: 2.4184 - val_acc: 0.6933\n",
            "Epoch 867/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.4661 - acc: 0.8445 - val_loss: 2.1371 - val_acc: 0.6756\n",
            "Epoch 868/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2608 - acc: 0.8877 - val_loss: 1.9767 - val_acc: 0.7156\n",
            "Epoch 869/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3286 - acc: 0.8567 - val_loss: 1.7375 - val_acc: 0.7156\n",
            "Epoch 870/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2344 - acc: 0.9007 - val_loss: 1.7505 - val_acc: 0.7156\n",
            "Epoch 871/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.3243 - acc: 0.8784 - val_loss: 1.8385 - val_acc: 0.7200\n",
            "Epoch 872/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3069 - acc: 0.9036 - val_loss: 1.3758 - val_acc: 0.7067\n",
            "Epoch 873/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3798 - acc: 0.8762 - val_loss: 2.0175 - val_acc: 0.7200\n",
            "Epoch 874/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2725 - acc: 0.8775 - val_loss: 1.5051 - val_acc: 0.7156\n",
            "Epoch 875/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3234 - acc: 0.8918 - val_loss: 2.6156 - val_acc: 0.6489\n",
            "Epoch 876/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2538 - acc: 0.8938 - val_loss: 1.4103 - val_acc: 0.6711\n",
            "Epoch 877/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3663 - acc: 0.8790 - val_loss: 2.1387 - val_acc: 0.6933\n",
            "Epoch 878/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2399 - acc: 0.8711 - val_loss: 2.1501 - val_acc: 0.6844\n",
            "Epoch 879/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3053 - acc: 0.8733 - val_loss: 2.5461 - val_acc: 0.6844\n",
            "Epoch 880/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2877 - acc: 0.8953 - val_loss: 1.6729 - val_acc: 0.6756\n",
            "Epoch 881/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3220 - acc: 0.8791 - val_loss: 2.3109 - val_acc: 0.7067\n",
            "Epoch 882/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2997 - acc: 0.8970 - val_loss: 1.7420 - val_acc: 0.7378\n",
            "Epoch 883/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3503 - acc: 0.8681 - val_loss: 1.6980 - val_acc: 0.6800\n",
            "Epoch 884/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2846 - acc: 0.8721 - val_loss: 2.0489 - val_acc: 0.6844\n",
            "Epoch 885/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.2511 - acc: 0.9150 - val_loss: 1.5285 - val_acc: 0.6978\n",
            "Epoch 886/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2342 - acc: 0.9053 - val_loss: 2.0288 - val_acc: 0.7067\n",
            "Epoch 887/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2669 - acc: 0.8840 - val_loss: 1.7493 - val_acc: 0.6844\n",
            "Epoch 888/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2995 - acc: 0.8641 - val_loss: 1.4380 - val_acc: 0.6622\n",
            "Epoch 889/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2729 - acc: 0.8921 - val_loss: 2.0281 - val_acc: 0.7022\n",
            "Epoch 890/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2487 - acc: 0.9079 - val_loss: 1.6156 - val_acc: 0.6756\n",
            "Epoch 891/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2607 - acc: 0.8934 - val_loss: 1.3806 - val_acc: 0.7244\n",
            "Epoch 892/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.3096 - acc: 0.8737 - val_loss: 1.9231 - val_acc: 0.6978\n",
            "Epoch 893/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2636 - acc: 0.9037 - val_loss: 2.2825 - val_acc: 0.6933\n",
            "Epoch 894/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.3261 - acc: 0.8755 - val_loss: 1.9794 - val_acc: 0.7289\n",
            "Epoch 895/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2948 - acc: 0.8671 - val_loss: 2.4330 - val_acc: 0.6800\n",
            "Epoch 896/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2820 - acc: 0.8686 - val_loss: 2.4220 - val_acc: 0.7111\n",
            "Epoch 897/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2161 - acc: 0.9133 - val_loss: 2.4150 - val_acc: 0.6444\n",
            "Epoch 898/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2893 - acc: 0.8843 - val_loss: 1.6725 - val_acc: 0.6800\n",
            "Epoch 899/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.4005 - acc: 0.8387 - val_loss: 1.5256 - val_acc: 0.7467\n",
            "Epoch 900/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2303 - acc: 0.9268 - val_loss: 2.0530 - val_acc: 0.6978\n",
            "Epoch 901/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2767 - acc: 0.8782 - val_loss: 1.8681 - val_acc: 0.7067\n",
            "Epoch 902/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2711 - acc: 0.8918 - val_loss: 1.8836 - val_acc: 0.7200\n",
            "Epoch 903/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2351 - acc: 0.9066 - val_loss: 1.7964 - val_acc: 0.6578\n",
            "Epoch 904/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2620 - acc: 0.9011 - val_loss: 1.1185 - val_acc: 0.6933\n",
            "Epoch 905/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2686 - acc: 0.8928 - val_loss: 1.5286 - val_acc: 0.6400\n",
            "Epoch 906/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2824 - acc: 0.9028 - val_loss: 1.7930 - val_acc: 0.6622\n",
            "Epoch 907/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2308 - acc: 0.8962 - val_loss: 1.5597 - val_acc: 0.6933\n",
            "Epoch 908/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3146 - acc: 0.8889 - val_loss: 1.4532 - val_acc: 0.6756\n",
            "Epoch 909/4000\n",
            "40/40 [==============================] - 16s 415ms/step - loss: 0.2620 - acc: 0.8888 - val_loss: 1.4533 - val_acc: 0.7022\n",
            "Epoch 910/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3163 - acc: 0.8735 - val_loss: 2.0985 - val_acc: 0.7111\n",
            "Epoch 911/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.2377 - acc: 0.9177 - val_loss: 1.8878 - val_acc: 0.6800\n",
            "Epoch 912/4000\n",
            "40/40 [==============================] - 16s 394ms/step - loss: 0.3046 - acc: 0.8736 - val_loss: 1.3962 - val_acc: 0.7067\n",
            "Epoch 913/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2129 - acc: 0.8974 - val_loss: 2.6090 - val_acc: 0.6889\n",
            "Epoch 914/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2992 - acc: 0.8715 - val_loss: 1.9702 - val_acc: 0.7022\n",
            "Epoch 915/4000\n",
            "40/40 [==============================] - 16s 416ms/step - loss: 0.2715 - acc: 0.8967 - val_loss: 1.4694 - val_acc: 0.6889\n",
            "Epoch 916/4000\n",
            "40/40 [==============================] - 16s 402ms/step - loss: 0.2805 - acc: 0.9053 - val_loss: 1.6880 - val_acc: 0.6933\n",
            "Epoch 917/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2229 - acc: 0.9094 - val_loss: 1.4953 - val_acc: 0.7111\n",
            "Epoch 918/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2415 - acc: 0.9161 - val_loss: 1.7498 - val_acc: 0.7244\n",
            "Epoch 919/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2626 - acc: 0.8711 - val_loss: 1.6909 - val_acc: 0.6844\n",
            "Epoch 920/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3391 - acc: 0.8831 - val_loss: 2.3820 - val_acc: 0.7067\n",
            "Epoch 921/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3485 - acc: 0.8738 - val_loss: 2.0620 - val_acc: 0.6578\n",
            "Epoch 922/4000\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2775 - acc: 0.8845 - val_loss: 1.5608 - val_acc: 0.7244\n",
            "Epoch 923/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2410 - acc: 0.8937 - val_loss: 1.7153 - val_acc: 0.6889\n",
            "Epoch 924/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2305 - acc: 0.8916 - val_loss: 1.8542 - val_acc: 0.6622\n",
            "Epoch 925/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2870 - acc: 0.8736 - val_loss: 2.3481 - val_acc: 0.6711\n",
            "Epoch 926/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2490 - acc: 0.8946 - val_loss: 1.8186 - val_acc: 0.6800\n",
            "Epoch 927/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2384 - acc: 0.8729 - val_loss: 2.0043 - val_acc: 0.6978\n",
            "Epoch 928/4000\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.3714 - acc: 0.8839 - val_loss: 1.5438 - val_acc: 0.6711\n",
            "Epoch 929/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.2910 - acc: 0.8972 - val_loss: 1.7845 - val_acc: 0.7244\n",
            "Epoch 930/4000\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.2376 - acc: 0.9252 - val_loss: 1.5315 - val_acc: 0.6978\n",
            "Epoch 931/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3011 - acc: 0.8851 - val_loss: 1.8536 - val_acc: 0.7378\n",
            "Epoch 932/4000\n",
            "40/40 [==============================] - 16s 406ms/step - loss: 0.3024 - acc: 0.8889 - val_loss: 2.8723 - val_acc: 0.7067\n",
            "Epoch 933/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2824 - acc: 0.9070 - val_loss: 1.9123 - val_acc: 0.6711\n",
            "Epoch 934/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2411 - acc: 0.8810 - val_loss: 2.1100 - val_acc: 0.6844\n",
            "Epoch 935/4000\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.3762 - acc: 0.9284 - val_loss: 1.9830 - val_acc: 0.7156\n",
            "Epoch 936/4000\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.2113 - acc: 0.9167 - val_loss: 1.8483 - val_acc: 0.6889\n",
            "Epoch 937/4000\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.2808 - acc: 0.8901 - val_loss: 1.8454 - val_acc: 0.6711\n",
            "Epoch 938/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3092 - acc: 0.8880 - val_loss: 2.3303 - val_acc: 0.6533\n",
            "Epoch 939/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3021 - acc: 0.8843 - val_loss: 2.3278 - val_acc: 0.6978\n",
            "Epoch 940/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.3058 - acc: 0.9039 - val_loss: 2.0262 - val_acc: 0.6622\n",
            "Epoch 941/4000\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.2638 - acc: 0.8985 - val_loss: 1.6667 - val_acc: 0.7022\n",
            "Epoch 942/4000\n",
            "40/40 [==============================] - 17s 411ms/step - loss: 0.2783 - acc: 0.8941 - val_loss: 1.8005 - val_acc: 0.7022\n",
            "Epoch 943/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.3262 - acc: 0.8963 - val_loss: 2.0110 - val_acc: 0.7022\n",
            "Epoch 944/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2598 - acc: 0.8790 - val_loss: 1.7942 - val_acc: 0.7111\n",
            "Epoch 945/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.2737 - acc: 0.8911 - val_loss: 1.5384 - val_acc: 0.6889\n",
            "Epoch 946/4000\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 0.3474 - acc: 0.8900 - val_loss: 1.6958 - val_acc: 0.7378\n",
            "Epoch 947/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2439 - acc: 0.8730 - val_loss: 1.6573 - val_acc: 0.7200\n",
            "Epoch 948/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2154 - acc: 0.9174 - val_loss: 1.7795 - val_acc: 0.6622\n",
            "Epoch 949/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.3149 - acc: 0.8665 - val_loss: 2.3091 - val_acc: 0.6756\n",
            "Epoch 950/4000\n",
            "40/40 [==============================] - 16s 409ms/step - loss: 0.2863 - acc: 0.8893 - val_loss: 1.4348 - val_acc: 0.6756\n",
            "Epoch 951/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2694 - acc: 0.9017 - val_loss: 1.9336 - val_acc: 0.7111\n",
            "Epoch 952/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2537 - acc: 0.9014 - val_loss: 1.9826 - val_acc: 0.7067\n",
            "Epoch 953/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2814 - acc: 0.8662 - val_loss: 2.7052 - val_acc: 0.6489\n",
            "Epoch 954/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.2830 - acc: 0.9053 - val_loss: 1.8149 - val_acc: 0.6889\n",
            "Epoch 955/4000\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.2367 - acc: 0.8948 - val_loss: 1.7312 - val_acc: 0.6711\n",
            "Epoch 956/4000\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2274 - acc: 0.8978 - val_loss: 1.6437 - val_acc: 0.7244\n",
            "Epoch 957/4000\n",
            "40/40 [==============================] - 17s 410ms/step - loss: 0.2685 - acc: 0.8890 - val_loss: 1.6473 - val_acc: 0.6444\n",
            "Epoch 958/4000\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.2930 - acc: 0.8684 - val_loss: 1.5595 - val_acc: 0.7156\n",
            "Epoch 959/4000\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.2925 - acc: 0.8950 - val_loss: 1.5494 - val_acc: 0.7156\n",
            "Epoch 960/4000\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.3561 - acc: 0.8664 - val_loss: 1.4459 - val_acc: 0.7156\n",
            "Epoch 961/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2820 - acc: 0.8875 - val_loss: 1.6090 - val_acc: 0.6889\n",
            "Epoch 962/4000\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2419 - acc: 0.8871 - val_loss: 1.4726 - val_acc: 0.7244\n",
            "Epoch 963/4000\n",
            "24/40 [=================>............] - ETA: 5s - loss: 0.2518 - acc: 0.8957"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_6411/1161767489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_lab13/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hist = model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch = 40,\n",
        "  epochs = 4000,\n",
        "  validation_data = val_generator,\n",
        "  validation_steps= 15\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 웰시코기 학습 3 후기\n",
        "- DropOut층을 다양하게 추가하기 vs L1 or L2규제 사용하기\n",
        "    - 다른 규제를 사용해보자\n",
        "    - 학습 4는 L2 규제를 2번 추가해본다"
      ],
      "metadata": {
        "id": "d45m-2MTHJ69"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b59786d"
      },
      "source": [
        "# 웰시코기 학습 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 전처리\n",
        "- 스케일링 이미지 증식\n",
        "- 이미지 크기 300 x 300\n",
        "- batch_size = 10\n",
        "- 과적합 방지\n",
        "    - DropOut + L2 규제 2회"
      ],
      "metadata": {
        "id": "qnILYJrKQsKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d64de132"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bdd448f",
        "outputId": "7aaf02cb-42be-4dd6-8d68-ed39190984bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 620 images belonging to 2 classes.\n",
            "Found 247 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 학습 이미지를 생성\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  rotation_range = 40,\n",
        "  width_shift_range= 0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# 검증 이미지는 증식하지 않는다.\n",
        "# 검증 데이터는 학습 과정에서 절대로 사용되어선 안된다.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  target_size = (300, 300), \n",
        "  batch_size = 10,\n",
        "  class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "  val_path,\n",
        "  target_size = (300, 300), \n",
        "  batch_size = 10,\n",
        "  class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네트워크 구성 및 규제 추가\n",
        "- DropOut과 L2규제 2회 추가"
      ],
      "metadata": {
        "id": "kd1kKzPjSlmK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c370647"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "28a83009",
        "outputId": "e04b18e9-413d-4d56-c9df-525c115c9bed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 10:44:24.398147: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-26 10:44:24.399190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-26 10:44:24.458892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:24.459515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-03-26 10:44:24.459544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-26 10:44:24.462535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-26 10:44:24.462633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-26 10:44:24.464352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-26 10:44:24.464714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-26 10:44:24.466594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-26 10:44:24.467323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-26 10:44:24.467516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-26 10:44:24.467627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:24.468243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:24.468779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-03-26 10:44:24.469277: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-26 10:44:24.469472: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-26 10:44:24.469600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:24.470162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-03-26 10:44:24.470179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-26 10:44:24.470200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-26 10:44:24.470211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-26 10:44:24.470222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-26 10:44:24.470234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-26 10:44:24.470245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-26 10:44:24.470258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-26 10:44:24.470270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-26 10:44:24.470328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:24.470902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:24.471455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-03-26 10:44:24.471487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-26 10:44:25.090581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-03-26 10:44:25.090613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-03-26 10:44:25.090619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-03-26 10:44:25.090853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:25.091521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:25.092092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 10:44:25.092630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Convolution Layer\n",
        "model.add( tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add( tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add( tf.keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "# feature map -> input\n",
        "model.add( tf.keras.layers.Flatten() )\n",
        "\n",
        "# DropOut Layer\n",
        "model.add( tf.keras.layers.Dropout(0.5) )\n",
        "\n",
        "# Neural Network\n",
        "model.add( tf.keras.layers.Dense(256, kernel_regularizer = regularizers.l2(0.001),\n",
        "                                 activation='relu') ) # hidden layer\n",
        "# Neural Network\n",
        "model.add( tf.keras.layers.Dense(1, kernel_regularizer = regularizers.l2(0.001),\n",
        "                                 activation='sigmoid') )# output layer\n",
        "\n",
        "\n",
        "# optimaze\n",
        "model.compile(\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['acc'],\n",
        "  optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "8e45a471",
        "outputId": "ab4bfd5c-b811-40c8-c2d5-d5ea27fff74f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 10:44:32.094198: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-03-26 10:44:32.111106: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 10:44:32.882673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-26 10:44:33.419243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-26 10:44:33.425027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 15s 286ms/step - loss: 1.1653 - acc: 0.4672 - val_loss: 0.9884 - val_acc: 0.5800\n",
            "Epoch 2/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.9571 - acc: 0.5365 - val_loss: 0.8686 - val_acc: 0.6400\n",
            "Epoch 3/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.8514 - acc: 0.5843 - val_loss: 0.7970 - val_acc: 0.5800\n",
            "Epoch 4/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.7737 - acc: 0.6213 - val_loss: 0.7554 - val_acc: 0.6000\n",
            "Epoch 5/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.7602 - acc: 0.6253 - val_loss: 0.6944 - val_acc: 0.6600\n",
            "Epoch 6/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.7399 - acc: 0.5878 - val_loss: 0.6840 - val_acc: 0.6267\n",
            "Epoch 7/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.6879 - acc: 0.6582 - val_loss: 0.6251 - val_acc: 0.7467\n",
            "Epoch 8/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.6763 - acc: 0.6648 - val_loss: 0.6894 - val_acc: 0.6267\n",
            "Epoch 9/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.7157 - acc: 0.6398 - val_loss: 0.6579 - val_acc: 0.7200\n",
            "Epoch 10/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.7014 - acc: 0.6529 - val_loss: 0.6461 - val_acc: 0.6400\n",
            "Epoch 11/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.7099 - acc: 0.6384 - val_loss: 0.6442 - val_acc: 0.6867\n",
            "Epoch 12/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.6953 - acc: 0.6431 - val_loss: 0.6623 - val_acc: 0.6800\n",
            "Epoch 13/3000\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.6537 - acc: 0.6858 - val_loss: 0.6719 - val_acc: 0.6800\n",
            "Epoch 14/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.6884 - acc: 0.6601 - val_loss: 0.6194 - val_acc: 0.7267\n",
            "Epoch 15/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.6648 - acc: 0.6788 - val_loss: 0.6858 - val_acc: 0.6800\n",
            "Epoch 16/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.7026 - acc: 0.6315 - val_loss: 0.6424 - val_acc: 0.6800\n",
            "Epoch 17/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.6519 - acc: 0.6676 - val_loss: 0.5899 - val_acc: 0.7200\n",
            "Epoch 18/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.6511 - acc: 0.6426 - val_loss: 0.6318 - val_acc: 0.6933\n",
            "Epoch 19/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.6765 - acc: 0.6387 - val_loss: 0.6537 - val_acc: 0.6333\n",
            "Epoch 20/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.6418 - acc: 0.6900 - val_loss: 0.6357 - val_acc: 0.6933\n",
            "Epoch 21/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.6632 - acc: 0.6481 - val_loss: 0.6448 - val_acc: 0.6733\n",
            "Epoch 22/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.6485 - acc: 0.6602 - val_loss: 0.6267 - val_acc: 0.6933\n",
            "Epoch 23/3000\n",
            "40/40 [==============================] - 12s 291ms/step - loss: 0.6400 - acc: 0.6698 - val_loss: 0.5964 - val_acc: 0.6933\n",
            "Epoch 24/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.6413 - acc: 0.7038 - val_loss: 0.5654 - val_acc: 0.7400\n",
            "Epoch 25/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.6628 - acc: 0.6546 - val_loss: 0.6502 - val_acc: 0.6533\n",
            "Epoch 26/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.6456 - acc: 0.6507 - val_loss: 0.6480 - val_acc: 0.6600\n",
            "Epoch 27/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.6236 - acc: 0.6912 - val_loss: 0.6269 - val_acc: 0.7000\n",
            "Epoch 28/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.6581 - acc: 0.6568 - val_loss: 0.6007 - val_acc: 0.7000\n",
            "Epoch 29/3000\n",
            "40/40 [==============================] - 11s 288ms/step - loss: 0.6392 - acc: 0.6932 - val_loss: 0.7325 - val_acc: 0.6667\n",
            "Epoch 30/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.6403 - acc: 0.6860 - val_loss: 0.6141 - val_acc: 0.6933\n",
            "Epoch 31/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.6648 - acc: 0.6356 - val_loss: 0.6130 - val_acc: 0.7200\n",
            "Epoch 32/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.6248 - acc: 0.6905 - val_loss: 0.5725 - val_acc: 0.7133\n",
            "Epoch 33/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.6483 - acc: 0.6658 - val_loss: 0.6124 - val_acc: 0.7000\n",
            "Epoch 34/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.6042 - acc: 0.6974 - val_loss: 0.6004 - val_acc: 0.7067\n",
            "Epoch 35/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.6660 - acc: 0.6540 - val_loss: 0.6512 - val_acc: 0.6667\n",
            "Epoch 36/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5922 - acc: 0.6910 - val_loss: 0.5674 - val_acc: 0.7533\n",
            "Epoch 37/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5941 - acc: 0.7022 - val_loss: 0.5807 - val_acc: 0.7133\n",
            "Epoch 38/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.6410 - acc: 0.6556 - val_loss: 0.6264 - val_acc: 0.6867\n",
            "Epoch 39/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.6108 - acc: 0.6932 - val_loss: 0.6194 - val_acc: 0.6800\n",
            "Epoch 40/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5521 - acc: 0.7317 - val_loss: 0.5748 - val_acc: 0.7000\n",
            "Epoch 41/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5930 - acc: 0.7023 - val_loss: 0.6202 - val_acc: 0.6867\n",
            "Epoch 42/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.6157 - acc: 0.6766 - val_loss: 0.6680 - val_acc: 0.6667\n",
            "Epoch 43/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6146 - acc: 0.6754 - val_loss: 0.5864 - val_acc: 0.6933\n",
            "Epoch 44/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.6150 - acc: 0.6762 - val_loss: 0.6367 - val_acc: 0.6867\n",
            "Epoch 45/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.6278 - acc: 0.6571 - val_loss: 0.6455 - val_acc: 0.6733\n",
            "Epoch 46/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.6604 - acc: 0.6712 - val_loss: 0.6733 - val_acc: 0.6800\n",
            "Epoch 47/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.6291 - acc: 0.6600 - val_loss: 0.6327 - val_acc: 0.6733\n",
            "Epoch 48/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.6109 - acc: 0.6541 - val_loss: 0.6121 - val_acc: 0.6933\n",
            "Epoch 49/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.6235 - acc: 0.6559 - val_loss: 0.6011 - val_acc: 0.7067\n",
            "Epoch 50/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5909 - acc: 0.7011 - val_loss: 0.6302 - val_acc: 0.6933\n",
            "Epoch 51/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5727 - acc: 0.7339 - val_loss: 0.6573 - val_acc: 0.6600\n",
            "Epoch 52/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6023 - acc: 0.6983 - val_loss: 0.5813 - val_acc: 0.7333\n",
            "Epoch 53/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.6304 - acc: 0.6697 - val_loss: 0.5851 - val_acc: 0.7533\n",
            "Epoch 54/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5970 - acc: 0.6744 - val_loss: 0.5844 - val_acc: 0.6933\n",
            "Epoch 55/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.6446 - acc: 0.6384 - val_loss: 0.6506 - val_acc: 0.6800\n",
            "Epoch 56/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6380 - acc: 0.6589 - val_loss: 0.6048 - val_acc: 0.6733\n",
            "Epoch 57/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5792 - acc: 0.7351 - val_loss: 0.6139 - val_acc: 0.6933\n",
            "Epoch 58/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5887 - acc: 0.6980 - val_loss: 0.6023 - val_acc: 0.6800\n",
            "Epoch 59/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5602 - acc: 0.7384 - val_loss: 0.5680 - val_acc: 0.7133\n",
            "Epoch 60/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.6003 - acc: 0.7269 - val_loss: 0.5623 - val_acc: 0.7200\n",
            "Epoch 61/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5824 - acc: 0.6948 - val_loss: 0.6221 - val_acc: 0.6600\n",
            "Epoch 62/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.6202 - acc: 0.6731 - val_loss: 0.5859 - val_acc: 0.7000\n",
            "Epoch 63/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5850 - acc: 0.7239 - val_loss: 0.6028 - val_acc: 0.7000\n",
            "Epoch 64/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6061 - acc: 0.6810 - val_loss: 0.6126 - val_acc: 0.6733\n",
            "Epoch 65/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5412 - acc: 0.7308 - val_loss: 0.6111 - val_acc: 0.7000\n",
            "Epoch 66/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.5895 - acc: 0.7018 - val_loss: 0.6797 - val_acc: 0.6333\n",
            "Epoch 67/3000\n",
            "40/40 [==============================] - 11s 271ms/step - loss: 0.5689 - acc: 0.7191 - val_loss: 0.6213 - val_acc: 0.6800\n",
            "Epoch 68/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.6535 - acc: 0.6179 - val_loss: 0.5840 - val_acc: 0.7133\n",
            "Epoch 69/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5861 - acc: 0.6974 - val_loss: 0.5841 - val_acc: 0.7000\n",
            "Epoch 70/3000\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.5977 - acc: 0.7104 - val_loss: 0.5849 - val_acc: 0.6867\n",
            "Epoch 71/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.6065 - acc: 0.6982 - val_loss: 0.6260 - val_acc: 0.6600\n",
            "Epoch 72/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6151 - acc: 0.7297 - val_loss: 0.6475 - val_acc: 0.6533\n",
            "Epoch 73/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5726 - acc: 0.7184 - val_loss: 0.6136 - val_acc: 0.6733\n",
            "Epoch 74/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.6132 - acc: 0.6973 - val_loss: 0.6186 - val_acc: 0.6867\n",
            "Epoch 75/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5559 - acc: 0.7296 - val_loss: 0.6084 - val_acc: 0.7133\n",
            "Epoch 76/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5914 - acc: 0.7026 - val_loss: 0.5926 - val_acc: 0.7133\n",
            "Epoch 77/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5694 - acc: 0.7200 - val_loss: 0.6991 - val_acc: 0.6733\n",
            "Epoch 78/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.5723 - acc: 0.7192 - val_loss: 0.6280 - val_acc: 0.6800\n",
            "Epoch 79/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.6069 - acc: 0.6787 - val_loss: 0.6547 - val_acc: 0.6600\n",
            "Epoch 80/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5733 - acc: 0.7061 - val_loss: 0.5908 - val_acc: 0.7000\n",
            "Epoch 81/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.5797 - acc: 0.6915 - val_loss: 0.5948 - val_acc: 0.6733\n",
            "Epoch 82/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5994 - acc: 0.6916 - val_loss: 0.5812 - val_acc: 0.7200\n",
            "Epoch 83/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.6122 - acc: 0.6836 - val_loss: 0.5949 - val_acc: 0.7067\n",
            "Epoch 84/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.6229 - acc: 0.6806 - val_loss: 0.5459 - val_acc: 0.7467\n",
            "Epoch 85/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.6428 - acc: 0.6584 - val_loss: 0.6377 - val_acc: 0.6733\n",
            "Epoch 86/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5731 - acc: 0.7358 - val_loss: 0.6095 - val_acc: 0.6800\n",
            "Epoch 87/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5908 - acc: 0.6775 - val_loss: 0.6063 - val_acc: 0.7000\n",
            "Epoch 88/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.6070 - acc: 0.6840 - val_loss: 0.6348 - val_acc: 0.7133\n",
            "Epoch 89/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5473 - acc: 0.7432 - val_loss: 0.6551 - val_acc: 0.6800\n",
            "Epoch 90/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5694 - acc: 0.7228 - val_loss: 0.5960 - val_acc: 0.7133\n",
            "Epoch 91/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5681 - acc: 0.7014 - val_loss: 0.5931 - val_acc: 0.7000\n",
            "Epoch 92/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5304 - acc: 0.7552 - val_loss: 0.5975 - val_acc: 0.7133\n",
            "Epoch 93/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5757 - acc: 0.7337 - val_loss: 0.5699 - val_acc: 0.7267\n",
            "Epoch 94/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5462 - acc: 0.7321 - val_loss: 0.6296 - val_acc: 0.7200\n",
            "Epoch 95/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.6607 - acc: 0.6742 - val_loss: 0.7699 - val_acc: 0.6533\n",
            "Epoch 96/3000\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.5925 - acc: 0.6940 - val_loss: 0.6436 - val_acc: 0.6667\n",
            "Epoch 97/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5556 - acc: 0.7174 - val_loss: 0.6315 - val_acc: 0.7067\n",
            "Epoch 98/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.5698 - acc: 0.7099 - val_loss: 0.5922 - val_acc: 0.6867\n",
            "Epoch 99/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5386 - acc: 0.7479 - val_loss: 0.6366 - val_acc: 0.6533\n",
            "Epoch 100/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.6223 - acc: 0.6606 - val_loss: 0.6113 - val_acc: 0.7067\n",
            "Epoch 101/3000\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.5278 - acc: 0.7744 - val_loss: 0.6317 - val_acc: 0.7000\n",
            "Epoch 102/3000\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 0.5822 - acc: 0.6815 - val_loss: 0.6649 - val_acc: 0.7000\n",
            "Epoch 103/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5756 - acc: 0.7082 - val_loss: 0.6483 - val_acc: 0.6867\n",
            "Epoch 104/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5827 - acc: 0.7312 - val_loss: 0.6313 - val_acc: 0.6933\n",
            "Epoch 105/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5870 - acc: 0.6940 - val_loss: 0.6704 - val_acc: 0.6600\n",
            "Epoch 106/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5683 - acc: 0.7311 - val_loss: 0.6390 - val_acc: 0.7067\n",
            "Epoch 107/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5760 - acc: 0.7083 - val_loss: 0.6506 - val_acc: 0.6800\n",
            "Epoch 108/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5814 - acc: 0.6992 - val_loss: 0.6412 - val_acc: 0.7133\n",
            "Epoch 109/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.6305 - acc: 0.6914 - val_loss: 0.6081 - val_acc: 0.7067\n",
            "Epoch 110/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5173 - acc: 0.7661 - val_loss: 0.6525 - val_acc: 0.7000\n",
            "Epoch 111/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5309 - acc: 0.7350 - val_loss: 0.6214 - val_acc: 0.7133\n",
            "Epoch 112/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.6295 - acc: 0.7071 - val_loss: 0.6570 - val_acc: 0.6733\n",
            "Epoch 113/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6530 - acc: 0.6539 - val_loss: 0.6295 - val_acc: 0.7000\n",
            "Epoch 114/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.6215 - acc: 0.7092 - val_loss: 0.5490 - val_acc: 0.7400\n",
            "Epoch 115/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5295 - acc: 0.7234 - val_loss: 0.6394 - val_acc: 0.6867\n",
            "Epoch 116/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5668 - acc: 0.7198 - val_loss: 0.6201 - val_acc: 0.7067\n",
            "Epoch 117/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5521 - acc: 0.7494 - val_loss: 0.6254 - val_acc: 0.6933\n",
            "Epoch 118/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5488 - acc: 0.7057 - val_loss: 0.6407 - val_acc: 0.6867\n",
            "Epoch 119/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5742 - acc: 0.7430 - val_loss: 0.6352 - val_acc: 0.7067\n",
            "Epoch 120/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5016 - acc: 0.8068 - val_loss: 0.6164 - val_acc: 0.7467\n",
            "Epoch 121/3000\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 0.5971 - acc: 0.7116 - val_loss: 0.6305 - val_acc: 0.7333\n",
            "Epoch 122/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.6104 - acc: 0.6985 - val_loss: 0.6493 - val_acc: 0.6533\n",
            "Epoch 123/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5562 - acc: 0.7581 - val_loss: 0.5706 - val_acc: 0.7333\n",
            "Epoch 124/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5368 - acc: 0.7508 - val_loss: 0.6124 - val_acc: 0.7000\n",
            "Epoch 125/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.4921 - acc: 0.8057 - val_loss: 0.6108 - val_acc: 0.7133\n",
            "Epoch 126/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5607 - acc: 0.7493 - val_loss: 0.6752 - val_acc: 0.6733\n",
            "Epoch 127/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5641 - acc: 0.6944 - val_loss: 0.6692 - val_acc: 0.7133\n",
            "Epoch 128/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.5973 - acc: 0.7328 - val_loss: 0.6524 - val_acc: 0.7067\n",
            "Epoch 129/3000\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.5580 - acc: 0.7305 - val_loss: 0.7295 - val_acc: 0.6667\n",
            "Epoch 130/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5544 - acc: 0.7436 - val_loss: 0.7643 - val_acc: 0.6800\n",
            "Epoch 131/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5819 - acc: 0.7022 - val_loss: 0.6426 - val_acc: 0.7267\n",
            "Epoch 132/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5852 - acc: 0.6933 - val_loss: 0.6762 - val_acc: 0.6733\n",
            "Epoch 133/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5957 - acc: 0.6766 - val_loss: 0.6330 - val_acc: 0.7000\n",
            "Epoch 134/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5413 - acc: 0.7325 - val_loss: 0.6911 - val_acc: 0.7267\n",
            "Epoch 135/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5778 - acc: 0.7242 - val_loss: 0.6512 - val_acc: 0.7267\n",
            "Epoch 136/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5600 - acc: 0.7372 - val_loss: 0.6637 - val_acc: 0.6733\n",
            "Epoch 137/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5770 - acc: 0.7207 - val_loss: 0.6031 - val_acc: 0.7467\n",
            "Epoch 138/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5629 - acc: 0.7169 - val_loss: 0.6614 - val_acc: 0.6733\n",
            "Epoch 139/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5115 - acc: 0.7769 - val_loss: 0.7526 - val_acc: 0.6533\n",
            "Epoch 140/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5933 - acc: 0.7001 - val_loss: 0.5873 - val_acc: 0.7333\n",
            "Epoch 141/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5643 - acc: 0.6989 - val_loss: 0.7604 - val_acc: 0.6933\n",
            "Epoch 142/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5975 - acc: 0.6749 - val_loss: 0.6378 - val_acc: 0.7333\n",
            "Epoch 143/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5799 - acc: 0.7159 - val_loss: 0.7697 - val_acc: 0.6533\n",
            "Epoch 144/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5609 - acc: 0.7276 - val_loss: 0.6693 - val_acc: 0.6800\n",
            "Epoch 145/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5985 - acc: 0.6764 - val_loss: 0.5513 - val_acc: 0.7533\n",
            "Epoch 146/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5491 - acc: 0.7296 - val_loss: 0.7311 - val_acc: 0.6667\n",
            "Epoch 147/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5771 - acc: 0.7457 - val_loss: 0.6830 - val_acc: 0.7000\n",
            "Epoch 148/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.5500 - acc: 0.7358 - val_loss: 0.7894 - val_acc: 0.6600\n",
            "Epoch 149/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5442 - acc: 0.7398 - val_loss: 0.7058 - val_acc: 0.7133\n",
            "Epoch 150/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5351 - acc: 0.7649 - val_loss: 0.6767 - val_acc: 0.6600\n",
            "Epoch 151/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5346 - acc: 0.7431 - val_loss: 0.7198 - val_acc: 0.6800\n",
            "Epoch 152/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5244 - acc: 0.7421 - val_loss: 0.6509 - val_acc: 0.6800\n",
            "Epoch 153/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5614 - acc: 0.7237 - val_loss: 0.7433 - val_acc: 0.6733\n",
            "Epoch 154/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5340 - acc: 0.7417 - val_loss: 0.6070 - val_acc: 0.7133\n",
            "Epoch 155/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5440 - acc: 0.7265 - val_loss: 0.6656 - val_acc: 0.6667\n",
            "Epoch 156/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5728 - acc: 0.7508 - val_loss: 0.6597 - val_acc: 0.6733\n",
            "Epoch 157/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5372 - acc: 0.7756 - val_loss: 0.7200 - val_acc: 0.7067\n",
            "Epoch 158/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5452 - acc: 0.7396 - val_loss: 0.7340 - val_acc: 0.7067\n",
            "Epoch 159/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5414 - acc: 0.7513 - val_loss: 0.6183 - val_acc: 0.7133\n",
            "Epoch 160/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5948 - acc: 0.7653 - val_loss: 0.5744 - val_acc: 0.7067\n",
            "Epoch 161/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5374 - acc: 0.7703 - val_loss: 0.7547 - val_acc: 0.6400\n",
            "Epoch 162/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5801 - acc: 0.6874 - val_loss: 0.7025 - val_acc: 0.6867\n",
            "Epoch 163/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4977 - acc: 0.7875 - val_loss: 0.5776 - val_acc: 0.7400\n",
            "Epoch 164/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5095 - acc: 0.7893 - val_loss: 0.6574 - val_acc: 0.7333\n",
            "Epoch 165/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5183 - acc: 0.7775 - val_loss: 0.6663 - val_acc: 0.7000\n",
            "Epoch 166/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5056 - acc: 0.7912 - val_loss: 0.6375 - val_acc: 0.7000\n",
            "Epoch 167/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5111 - acc: 0.7522 - val_loss: 0.5958 - val_acc: 0.7333\n",
            "Epoch 168/3000\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.4935 - acc: 0.7838 - val_loss: 0.6341 - val_acc: 0.7133\n",
            "Epoch 169/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.5274 - acc: 0.7614 - val_loss: 0.7129 - val_acc: 0.7067\n",
            "Epoch 170/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5579 - acc: 0.7382 - val_loss: 0.6147 - val_acc: 0.7400\n",
            "Epoch 171/3000\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.5284 - acc: 0.7538 - val_loss: 0.6363 - val_acc: 0.7200\n",
            "Epoch 172/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5434 - acc: 0.7449 - val_loss: 0.7197 - val_acc: 0.6333\n",
            "Epoch 173/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.5294 - acc: 0.7277 - val_loss: 0.6763 - val_acc: 0.7133\n",
            "Epoch 174/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5285 - acc: 0.7379 - val_loss: 0.7058 - val_acc: 0.6800\n",
            "Epoch 175/3000\n",
            "40/40 [==============================] - 12s 290ms/step - loss: 0.5182 - acc: 0.7455 - val_loss: 0.6654 - val_acc: 0.7067\n",
            "Epoch 176/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.5274 - acc: 0.7591 - val_loss: 0.6629 - val_acc: 0.7000\n",
            "Epoch 177/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5798 - acc: 0.6951 - val_loss: 0.6120 - val_acc: 0.7067\n",
            "Epoch 178/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5380 - acc: 0.7711 - val_loss: 0.6615 - val_acc: 0.7267\n",
            "Epoch 179/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5705 - acc: 0.7428 - val_loss: 0.6783 - val_acc: 0.6600\n",
            "Epoch 180/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4802 - acc: 0.7785 - val_loss: 0.7753 - val_acc: 0.6667\n",
            "Epoch 181/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.5734 - acc: 0.7269 - val_loss: 0.6638 - val_acc: 0.7133\n",
            "Epoch 182/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5535 - acc: 0.7287 - val_loss: 0.6526 - val_acc: 0.7267\n",
            "Epoch 183/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5235 - acc: 0.7477 - val_loss: 0.7397 - val_acc: 0.7133\n",
            "Epoch 184/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5135 - acc: 0.7675 - val_loss: 0.6955 - val_acc: 0.6600\n",
            "Epoch 185/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5444 - acc: 0.7269 - val_loss: 0.6606 - val_acc: 0.6800\n",
            "Epoch 186/3000\n",
            "40/40 [==============================] - 12s 290ms/step - loss: 0.5157 - acc: 0.7531 - val_loss: 0.6859 - val_acc: 0.6933\n",
            "Epoch 187/3000\n",
            "40/40 [==============================] - 12s 289ms/step - loss: 0.5689 - acc: 0.7116 - val_loss: 0.6586 - val_acc: 0.7400\n",
            "Epoch 188/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5480 - acc: 0.7354 - val_loss: 0.7412 - val_acc: 0.6933\n",
            "Epoch 189/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4562 - acc: 0.7963 - val_loss: 0.6733 - val_acc: 0.7000\n",
            "Epoch 190/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5338 - acc: 0.7490 - val_loss: 0.6763 - val_acc: 0.7133\n",
            "Epoch 191/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5037 - acc: 0.8137 - val_loss: 0.8752 - val_acc: 0.6867\n",
            "Epoch 192/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.6146 - acc: 0.7352 - val_loss: 0.6446 - val_acc: 0.6467\n",
            "Epoch 193/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4928 - acc: 0.8002 - val_loss: 0.8112 - val_acc: 0.6933\n",
            "Epoch 194/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5396 - acc: 0.7602 - val_loss: 0.5553 - val_acc: 0.7200\n",
            "Epoch 195/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5387 - acc: 0.7409 - val_loss: 0.7351 - val_acc: 0.6867\n",
            "Epoch 196/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4697 - acc: 0.7890 - val_loss: 0.7092 - val_acc: 0.6933\n",
            "Epoch 197/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5120 - acc: 0.7729 - val_loss: 0.6410 - val_acc: 0.6800\n",
            "Epoch 198/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5026 - acc: 0.7674 - val_loss: 0.7110 - val_acc: 0.6667\n",
            "Epoch 199/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5526 - acc: 0.7245 - val_loss: 0.9019 - val_acc: 0.6600\n",
            "Epoch 200/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5544 - acc: 0.7380 - val_loss: 0.7767 - val_acc: 0.6867\n",
            "Epoch 201/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5013 - acc: 0.7595 - val_loss: 0.6111 - val_acc: 0.7133\n",
            "Epoch 202/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5306 - acc: 0.7569 - val_loss: 0.6561 - val_acc: 0.7000\n",
            "Epoch 203/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5259 - acc: 0.7789 - val_loss: 0.7838 - val_acc: 0.6533\n",
            "Epoch 204/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5226 - acc: 0.7597 - val_loss: 0.6369 - val_acc: 0.7000\n",
            "Epoch 205/3000\n",
            "40/40 [==============================] - 12s 289ms/step - loss: 0.4611 - acc: 0.8008 - val_loss: 0.6680 - val_acc: 0.7133\n",
            "Epoch 206/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5261 - acc: 0.7525 - val_loss: 0.6882 - val_acc: 0.6800\n",
            "Epoch 207/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.6046 - acc: 0.7269 - val_loss: 0.8391 - val_acc: 0.6667\n",
            "Epoch 208/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5209 - acc: 0.7568 - val_loss: 0.7635 - val_acc: 0.6467\n",
            "Epoch 209/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5148 - acc: 0.7769 - val_loss: 0.5978 - val_acc: 0.7333\n",
            "Epoch 210/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5237 - acc: 0.7717 - val_loss: 0.6535 - val_acc: 0.7000\n",
            "Epoch 211/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4907 - acc: 0.8162 - val_loss: 0.7091 - val_acc: 0.6867\n",
            "Epoch 212/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5111 - acc: 0.7380 - val_loss: 0.7962 - val_acc: 0.7067\n",
            "Epoch 213/3000\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.5178 - acc: 0.7606 - val_loss: 0.7256 - val_acc: 0.6933\n",
            "Epoch 214/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5146 - acc: 0.7814 - val_loss: 0.6376 - val_acc: 0.7133\n",
            "Epoch 215/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5435 - acc: 0.7472 - val_loss: 0.7630 - val_acc: 0.6533\n",
            "Epoch 216/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4893 - acc: 0.7943 - val_loss: 0.7309 - val_acc: 0.6933\n",
            "Epoch 217/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4848 - acc: 0.7693 - val_loss: 0.6913 - val_acc: 0.7000\n",
            "Epoch 218/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5556 - acc: 0.7557 - val_loss: 0.6290 - val_acc: 0.7133\n",
            "Epoch 219/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5059 - acc: 0.7335 - val_loss: 0.7327 - val_acc: 0.6667\n",
            "Epoch 220/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5226 - acc: 0.7504 - val_loss: 0.6848 - val_acc: 0.7000\n",
            "Epoch 221/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5228 - acc: 0.7597 - val_loss: 0.6601 - val_acc: 0.7067\n",
            "Epoch 222/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4913 - acc: 0.7596 - val_loss: 0.8082 - val_acc: 0.6800\n",
            "Epoch 223/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5218 - acc: 0.7788 - val_loss: 0.8482 - val_acc: 0.6733\n",
            "Epoch 224/3000\n",
            "40/40 [==============================] - 12s 289ms/step - loss: 0.5483 - acc: 0.7466 - val_loss: 0.7469 - val_acc: 0.7200\n",
            "Epoch 225/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4879 - acc: 0.7801 - val_loss: 0.7012 - val_acc: 0.6600\n",
            "Epoch 226/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5087 - acc: 0.7753 - val_loss: 0.8399 - val_acc: 0.6733\n",
            "Epoch 227/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5086 - acc: 0.7592 - val_loss: 0.7695 - val_acc: 0.6333\n",
            "Epoch 228/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5039 - acc: 0.7854 - val_loss: 0.7741 - val_acc: 0.6867\n",
            "Epoch 229/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4798 - acc: 0.7701 - val_loss: 0.6669 - val_acc: 0.7067\n",
            "Epoch 230/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4834 - acc: 0.8009 - val_loss: 0.7994 - val_acc: 0.6867\n",
            "Epoch 231/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5254 - acc: 0.7870 - val_loss: 0.9923 - val_acc: 0.6400\n",
            "Epoch 232/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5598 - acc: 0.7343 - val_loss: 0.7598 - val_acc: 0.6667\n",
            "Epoch 233/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4690 - acc: 0.8002 - val_loss: 0.6379 - val_acc: 0.7467\n",
            "Epoch 234/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4869 - acc: 0.8067 - val_loss: 0.6909 - val_acc: 0.6933\n",
            "Epoch 235/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5371 - acc: 0.7665 - val_loss: 0.8474 - val_acc: 0.6600\n",
            "Epoch 236/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4690 - acc: 0.7881 - val_loss: 0.9975 - val_acc: 0.6467\n",
            "Epoch 237/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4542 - acc: 0.7922 - val_loss: 0.7945 - val_acc: 0.6533\n",
            "Epoch 238/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.5435 - acc: 0.7204 - val_loss: 0.8003 - val_acc: 0.6600\n",
            "Epoch 239/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5182 - acc: 0.7551 - val_loss: 0.7398 - val_acc: 0.6933\n",
            "Epoch 240/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5338 - acc: 0.7725 - val_loss: 0.7591 - val_acc: 0.6733\n",
            "Epoch 241/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4815 - acc: 0.7844 - val_loss: 0.8104 - val_acc: 0.6867\n",
            "Epoch 242/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5197 - acc: 0.7405 - val_loss: 0.8750 - val_acc: 0.6067\n",
            "Epoch 243/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5761 - acc: 0.7035 - val_loss: 0.7188 - val_acc: 0.7200\n",
            "Epoch 244/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5184 - acc: 0.7498 - val_loss: 0.8262 - val_acc: 0.6933\n",
            "Epoch 245/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4694 - acc: 0.8135 - val_loss: 0.7434 - val_acc: 0.6733\n",
            "Epoch 246/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5400 - acc: 0.7320 - val_loss: 0.7344 - val_acc: 0.6667\n",
            "Epoch 247/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5132 - acc: 0.7565 - val_loss: 0.7476 - val_acc: 0.7000\n",
            "Epoch 248/3000\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.5782 - acc: 0.7181 - val_loss: 0.6824 - val_acc: 0.6800\n",
            "Epoch 249/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5053 - acc: 0.7453 - val_loss: 0.7708 - val_acc: 0.6933\n",
            "Epoch 250/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5449 - acc: 0.7394 - val_loss: 0.8820 - val_acc: 0.6133\n",
            "Epoch 251/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5033 - acc: 0.7612 - val_loss: 0.8300 - val_acc: 0.7000\n",
            "Epoch 252/3000\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 0.5653 - acc: 0.7305 - val_loss: 0.7903 - val_acc: 0.6733\n",
            "Epoch 253/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.4591 - acc: 0.8017 - val_loss: 0.7322 - val_acc: 0.7067\n",
            "Epoch 254/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5025 - acc: 0.7641 - val_loss: 0.7302 - val_acc: 0.7000\n",
            "Epoch 255/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5460 - acc: 0.7038 - val_loss: 0.7544 - val_acc: 0.6933\n",
            "Epoch 256/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4822 - acc: 0.8063 - val_loss: 0.6593 - val_acc: 0.7333\n",
            "Epoch 257/3000\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 0.5022 - acc: 0.7770 - val_loss: 0.7170 - val_acc: 0.6733\n",
            "Epoch 258/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5023 - acc: 0.7753 - val_loss: 0.8544 - val_acc: 0.6933\n",
            "Epoch 259/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4866 - acc: 0.7930 - val_loss: 0.6414 - val_acc: 0.7267\n",
            "Epoch 260/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5548 - acc: 0.7554 - val_loss: 0.7907 - val_acc: 0.7200\n",
            "Epoch 261/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4764 - acc: 0.7806 - val_loss: 0.7533 - val_acc: 0.6600\n",
            "Epoch 262/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5362 - acc: 0.7923 - val_loss: 0.9336 - val_acc: 0.6200\n",
            "Epoch 263/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5074 - acc: 0.7843 - val_loss: 0.7513 - val_acc: 0.6667\n",
            "Epoch 264/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5168 - acc: 0.7595 - val_loss: 0.7744 - val_acc: 0.6667\n",
            "Epoch 265/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4558 - acc: 0.8303 - val_loss: 0.6605 - val_acc: 0.7600\n",
            "Epoch 266/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5667 - acc: 0.7183 - val_loss: 0.7710 - val_acc: 0.6867\n",
            "Epoch 267/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5597 - acc: 0.7222 - val_loss: 0.7632 - val_acc: 0.6533\n",
            "Epoch 268/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.4453 - acc: 0.8178 - val_loss: 0.8223 - val_acc: 0.7267\n",
            "Epoch 269/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5576 - acc: 0.7046 - val_loss: 0.7045 - val_acc: 0.6867\n",
            "Epoch 270/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4544 - acc: 0.8112 - val_loss: 0.8856 - val_acc: 0.6533\n",
            "Epoch 271/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5297 - acc: 0.7624 - val_loss: 0.7784 - val_acc: 0.6867\n",
            "Epoch 272/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5300 - acc: 0.7910 - val_loss: 0.6869 - val_acc: 0.6733\n",
            "Epoch 273/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5064 - acc: 0.7538 - val_loss: 0.9126 - val_acc: 0.6800\n",
            "Epoch 274/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4948 - acc: 0.7698 - val_loss: 0.9688 - val_acc: 0.6067\n",
            "Epoch 275/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4847 - acc: 0.7720 - val_loss: 0.8103 - val_acc: 0.6733\n",
            "Epoch 276/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5311 - acc: 0.7580 - val_loss: 0.7755 - val_acc: 0.7200\n",
            "Epoch 277/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4833 - acc: 0.8025 - val_loss: 0.6751 - val_acc: 0.7267\n",
            "Epoch 278/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5013 - acc: 0.7703 - val_loss: 0.8363 - val_acc: 0.6600\n",
            "Epoch 279/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4984 - acc: 0.7502 - val_loss: 0.8781 - val_acc: 0.7200\n",
            "Epoch 280/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5140 - acc: 0.7309 - val_loss: 0.6756 - val_acc: 0.7400\n",
            "Epoch 281/3000\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 0.5362 - acc: 0.7422 - val_loss: 0.8145 - val_acc: 0.6400\n",
            "Epoch 282/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4381 - acc: 0.8041 - val_loss: 0.6243 - val_acc: 0.7333\n",
            "Epoch 283/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4747 - acc: 0.7700 - val_loss: 0.6986 - val_acc: 0.7000\n",
            "Epoch 284/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4850 - acc: 0.7915 - val_loss: 0.9883 - val_acc: 0.6600\n",
            "Epoch 285/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4780 - acc: 0.7926 - val_loss: 0.7561 - val_acc: 0.6800\n",
            "Epoch 286/3000\n",
            "40/40 [==============================] - 11s 288ms/step - loss: 0.5246 - acc: 0.7794 - val_loss: 0.6978 - val_acc: 0.7067\n",
            "Epoch 287/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4946 - acc: 0.7971 - val_loss: 0.7956 - val_acc: 0.6867\n",
            "Epoch 288/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.4784 - acc: 0.7943 - val_loss: 0.6803 - val_acc: 0.7200\n",
            "Epoch 289/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4951 - acc: 0.7985 - val_loss: 0.7052 - val_acc: 0.7133\n",
            "Epoch 290/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5238 - acc: 0.7368 - val_loss: 0.6647 - val_acc: 0.7400\n",
            "Epoch 291/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5213 - acc: 0.7735 - val_loss: 0.8261 - val_acc: 0.6733\n",
            "Epoch 292/3000\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 0.5260 - acc: 0.7712 - val_loss: 0.7889 - val_acc: 0.6733\n",
            "Epoch 293/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4791 - acc: 0.7806 - val_loss: 0.7267 - val_acc: 0.6800\n",
            "Epoch 294/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.5066 - acc: 0.7576 - val_loss: 0.6659 - val_acc: 0.7133\n",
            "Epoch 295/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5815 - acc: 0.7517 - val_loss: 0.7640 - val_acc: 0.6867\n",
            "Epoch 296/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4683 - acc: 0.8141 - val_loss: 0.8379 - val_acc: 0.6400\n",
            "Epoch 297/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4660 - acc: 0.8157 - val_loss: 0.6872 - val_acc: 0.7267\n",
            "Epoch 298/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4552 - acc: 0.7893 - val_loss: 0.7817 - val_acc: 0.7133\n",
            "Epoch 299/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5676 - acc: 0.7539 - val_loss: 0.8063 - val_acc: 0.6467\n",
            "Epoch 300/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4925 - acc: 0.7984 - val_loss: 0.7762 - val_acc: 0.6600\n",
            "Epoch 301/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5312 - acc: 0.7491 - val_loss: 0.8215 - val_acc: 0.6533\n",
            "Epoch 302/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4766 - acc: 0.7829 - val_loss: 0.7489 - val_acc: 0.6867\n",
            "Epoch 303/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5145 - acc: 0.7461 - val_loss: 0.9416 - val_acc: 0.6867\n",
            "Epoch 304/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4745 - acc: 0.8148 - val_loss: 0.8631 - val_acc: 0.6733\n",
            "Epoch 305/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4574 - acc: 0.8106 - val_loss: 0.7440 - val_acc: 0.7000\n",
            "Epoch 306/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5093 - acc: 0.7728 - val_loss: 0.8020 - val_acc: 0.6800\n",
            "Epoch 307/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5157 - acc: 0.7670 - val_loss: 0.8148 - val_acc: 0.7000\n",
            "Epoch 308/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4982 - acc: 0.7630 - val_loss: 0.9030 - val_acc: 0.7267\n",
            "Epoch 309/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4735 - acc: 0.7915 - val_loss: 0.8854 - val_acc: 0.6800\n",
            "Epoch 310/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5025 - acc: 0.7705 - val_loss: 0.7672 - val_acc: 0.6867\n",
            "Epoch 311/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5437 - acc: 0.7742 - val_loss: 0.7655 - val_acc: 0.7067\n",
            "Epoch 312/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5303 - acc: 0.7638 - val_loss: 0.8833 - val_acc: 0.7067\n",
            "Epoch 313/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5240 - acc: 0.7653 - val_loss: 0.6907 - val_acc: 0.7000\n",
            "Epoch 314/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4321 - acc: 0.8137 - val_loss: 0.8888 - val_acc: 0.6800\n",
            "Epoch 315/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4882 - acc: 0.7871 - val_loss: 0.7564 - val_acc: 0.6867\n",
            "Epoch 316/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4645 - acc: 0.7935 - val_loss: 0.9807 - val_acc: 0.6267\n",
            "Epoch 317/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4636 - acc: 0.8063 - val_loss: 0.8624 - val_acc: 0.7000\n",
            "Epoch 318/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5154 - acc: 0.7846 - val_loss: 0.8015 - val_acc: 0.7200\n",
            "Epoch 319/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.5196 - acc: 0.7966 - val_loss: 0.8430 - val_acc: 0.7133\n",
            "Epoch 320/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4548 - acc: 0.7982 - val_loss: 0.6869 - val_acc: 0.7400\n",
            "Epoch 321/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4970 - acc: 0.7996 - val_loss: 0.8301 - val_acc: 0.7267\n",
            "Epoch 322/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5674 - acc: 0.7182 - val_loss: 0.7840 - val_acc: 0.7000\n",
            "Epoch 323/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.5011 - acc: 0.7767 - val_loss: 0.7489 - val_acc: 0.7067\n",
            "Epoch 324/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.5197 - acc: 0.7510 - val_loss: 0.8070 - val_acc: 0.6933\n",
            "Epoch 325/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4903 - acc: 0.8027 - val_loss: 0.6806 - val_acc: 0.7600\n",
            "Epoch 326/3000\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.5349 - acc: 0.7970 - val_loss: 0.9078 - val_acc: 0.6400\n",
            "Epoch 327/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5223 - acc: 0.7601 - val_loss: 0.7892 - val_acc: 0.7133\n",
            "Epoch 328/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4258 - acc: 0.8041 - val_loss: 0.7947 - val_acc: 0.6667\n",
            "Epoch 329/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4246 - acc: 0.8357 - val_loss: 1.0184 - val_acc: 0.6667\n",
            "Epoch 330/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4465 - acc: 0.7860 - val_loss: 0.7447 - val_acc: 0.7067\n",
            "Epoch 331/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4790 - acc: 0.7956 - val_loss: 1.0177 - val_acc: 0.6800\n",
            "Epoch 332/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5244 - acc: 0.7550 - val_loss: 0.6795 - val_acc: 0.7467\n",
            "Epoch 333/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4463 - acc: 0.7980 - val_loss: 0.8227 - val_acc: 0.6933\n",
            "Epoch 334/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5126 - acc: 0.7728 - val_loss: 0.8401 - val_acc: 0.6600\n",
            "Epoch 335/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5058 - acc: 0.7782 - val_loss: 0.8840 - val_acc: 0.6933\n",
            "Epoch 336/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4914 - acc: 0.7521 - val_loss: 0.8466 - val_acc: 0.6667\n",
            "Epoch 337/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5690 - acc: 0.7482 - val_loss: 0.9873 - val_acc: 0.6667\n",
            "Epoch 338/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4488 - acc: 0.8019 - val_loss: 0.9231 - val_acc: 0.6533\n",
            "Epoch 339/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.5090 - acc: 0.7859 - val_loss: 0.7695 - val_acc: 0.6667\n",
            "Epoch 340/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4423 - acc: 0.7936 - val_loss: 0.9652 - val_acc: 0.6133\n",
            "Epoch 341/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4431 - acc: 0.8306 - val_loss: 0.9847 - val_acc: 0.6867\n",
            "Epoch 342/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4284 - acc: 0.8282 - val_loss: 0.9846 - val_acc: 0.6667\n",
            "Epoch 343/3000\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 0.4773 - acc: 0.8066 - val_loss: 0.8404 - val_acc: 0.6600\n",
            "Epoch 344/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4290 - acc: 0.8562 - val_loss: 1.0432 - val_acc: 0.6667\n",
            "Epoch 345/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4279 - acc: 0.8312 - val_loss: 0.8045 - val_acc: 0.6600\n",
            "Epoch 346/3000\n",
            "40/40 [==============================] - 11s 271ms/step - loss: 0.4693 - acc: 0.8150 - val_loss: 0.8888 - val_acc: 0.6533\n",
            "Epoch 347/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4919 - acc: 0.7701 - val_loss: 0.7688 - val_acc: 0.6933\n",
            "Epoch 348/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4569 - acc: 0.7957 - val_loss: 0.8743 - val_acc: 0.6733\n",
            "Epoch 349/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4768 - acc: 0.7789 - val_loss: 0.8429 - val_acc: 0.7067\n",
            "Epoch 350/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.4179 - acc: 0.8240 - val_loss: 0.8811 - val_acc: 0.7200\n",
            "Epoch 351/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5534 - acc: 0.7838 - val_loss: 0.8398 - val_acc: 0.6867\n",
            "Epoch 352/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4762 - acc: 0.7835 - val_loss: 1.1075 - val_acc: 0.6933\n",
            "Epoch 353/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4593 - acc: 0.8079 - val_loss: 0.7974 - val_acc: 0.7133\n",
            "Epoch 354/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4687 - acc: 0.7913 - val_loss: 0.7457 - val_acc: 0.7067\n",
            "Epoch 355/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4697 - acc: 0.7933 - val_loss: 0.8370 - val_acc: 0.6800\n",
            "Epoch 356/3000\n",
            "40/40 [==============================] - 12s 290ms/step - loss: 0.5375 - acc: 0.7597 - val_loss: 0.8181 - val_acc: 0.7133\n",
            "Epoch 357/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.5244 - acc: 0.8007 - val_loss: 0.8317 - val_acc: 0.6867\n",
            "Epoch 358/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4511 - acc: 0.8035 - val_loss: 0.8232 - val_acc: 0.6733\n",
            "Epoch 359/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.4948 - acc: 0.7706 - val_loss: 0.7681 - val_acc: 0.7067\n",
            "Epoch 360/3000\n",
            "40/40 [==============================] - 12s 289ms/step - loss: 0.4517 - acc: 0.8302 - val_loss: 0.8065 - val_acc: 0.7267\n",
            "Epoch 361/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4521 - acc: 0.8247 - val_loss: 0.8593 - val_acc: 0.7067\n",
            "Epoch 362/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.5077 - acc: 0.7797 - val_loss: 0.6543 - val_acc: 0.7200\n",
            "Epoch 363/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4953 - acc: 0.7715 - val_loss: 0.7790 - val_acc: 0.7200\n",
            "Epoch 364/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.5355 - acc: 0.8110 - val_loss: 1.1416 - val_acc: 0.6467\n",
            "Epoch 365/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4358 - acc: 0.8231 - val_loss: 0.9792 - val_acc: 0.7200\n",
            "Epoch 366/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4598 - acc: 0.7872 - val_loss: 0.8095 - val_acc: 0.7533\n",
            "Epoch 367/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4828 - acc: 0.7323 - val_loss: 0.8089 - val_acc: 0.7667\n",
            "Epoch 368/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4614 - acc: 0.8024 - val_loss: 0.9822 - val_acc: 0.6733\n",
            "Epoch 369/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.5215 - acc: 0.7629 - val_loss: 0.7967 - val_acc: 0.7067\n",
            "Epoch 370/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4804 - acc: 0.8102 - val_loss: 0.7892 - val_acc: 0.7000\n",
            "Epoch 371/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4830 - acc: 0.8048 - val_loss: 0.8567 - val_acc: 0.6800\n",
            "Epoch 372/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4849 - acc: 0.8014 - val_loss: 0.6778 - val_acc: 0.7800\n",
            "Epoch 373/3000\n",
            "40/40 [==============================] - 11s 271ms/step - loss: 0.4853 - acc: 0.7721 - val_loss: 0.7605 - val_acc: 0.7200\n",
            "Epoch 374/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4692 - acc: 0.8068 - val_loss: 0.7912 - val_acc: 0.6667\n",
            "Epoch 375/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4733 - acc: 0.8039 - val_loss: 0.6889 - val_acc: 0.7133\n",
            "Epoch 376/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4500 - acc: 0.7939 - val_loss: 0.8098 - val_acc: 0.6667\n",
            "Epoch 377/3000\n",
            "40/40 [==============================] - 12s 289ms/step - loss: 0.4757 - acc: 0.7996 - val_loss: 0.8645 - val_acc: 0.7267\n",
            "Epoch 378/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4578 - acc: 0.7775 - val_loss: 0.7556 - val_acc: 0.7400\n",
            "Epoch 379/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.5015 - acc: 0.8240 - val_loss: 0.8496 - val_acc: 0.6800\n",
            "Epoch 380/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4449 - acc: 0.8113 - val_loss: 0.8099 - val_acc: 0.6733\n",
            "Epoch 381/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5487 - acc: 0.7369 - val_loss: 0.8544 - val_acc: 0.6867\n",
            "Epoch 382/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4363 - acc: 0.7956 - val_loss: 0.9755 - val_acc: 0.6533\n",
            "Epoch 383/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4573 - acc: 0.8110 - val_loss: 0.9638 - val_acc: 0.6933\n",
            "Epoch 384/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4783 - acc: 0.7914 - val_loss: 0.9508 - val_acc: 0.7067\n",
            "Epoch 385/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.5268 - acc: 0.7680 - val_loss: 0.9356 - val_acc: 0.6533\n",
            "Epoch 386/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4858 - acc: 0.7667 - val_loss: 0.8707 - val_acc: 0.6467\n",
            "Epoch 387/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4466 - acc: 0.8003 - val_loss: 0.7188 - val_acc: 0.7000\n",
            "Epoch 388/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4948 - acc: 0.7864 - val_loss: 0.7399 - val_acc: 0.7067\n",
            "Epoch 389/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4454 - acc: 0.8396 - val_loss: 0.7705 - val_acc: 0.7133\n",
            "Epoch 390/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5091 - acc: 0.7846 - val_loss: 0.7954 - val_acc: 0.6867\n",
            "Epoch 391/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4503 - acc: 0.8241 - val_loss: 0.8479 - val_acc: 0.6667\n",
            "Epoch 392/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4850 - acc: 0.8085 - val_loss: 0.8507 - val_acc: 0.6933\n",
            "Epoch 393/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4656 - acc: 0.7946 - val_loss: 0.8887 - val_acc: 0.7267\n",
            "Epoch 394/3000\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 0.4523 - acc: 0.7996 - val_loss: 0.8800 - val_acc: 0.6933\n",
            "Epoch 395/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4855 - acc: 0.7843 - val_loss: 0.8538 - val_acc: 0.7067\n",
            "Epoch 396/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4867 - acc: 0.7671 - val_loss: 0.7326 - val_acc: 0.7067\n",
            "Epoch 397/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.5474 - acc: 0.7919 - val_loss: 1.1088 - val_acc: 0.6667\n",
            "Epoch 398/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4442 - acc: 0.8195 - val_loss: 0.9941 - val_acc: 0.6667\n",
            "Epoch 399/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4354 - acc: 0.8187 - val_loss: 0.8292 - val_acc: 0.7133\n",
            "Epoch 400/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4286 - acc: 0.8197 - val_loss: 0.7853 - val_acc: 0.7133\n",
            "Epoch 401/3000\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.4097 - acc: 0.8217 - val_loss: 0.8178 - val_acc: 0.7000\n",
            "Epoch 402/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4611 - acc: 0.7973 - val_loss: 1.0661 - val_acc: 0.6267\n",
            "Epoch 403/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4502 - acc: 0.7906 - val_loss: 0.9353 - val_acc: 0.6733\n",
            "Epoch 404/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4624 - acc: 0.8269 - val_loss: 1.0183 - val_acc: 0.6867\n",
            "Epoch 405/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4506 - acc: 0.7965 - val_loss: 0.6776 - val_acc: 0.7200\n",
            "Epoch 406/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.5207 - acc: 0.7719 - val_loss: 0.9342 - val_acc: 0.7067\n",
            "Epoch 407/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4674 - acc: 0.8032 - val_loss: 0.7366 - val_acc: 0.7400\n",
            "Epoch 408/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4055 - acc: 0.8500 - val_loss: 1.0250 - val_acc: 0.6733\n",
            "Epoch 409/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4568 - acc: 0.8168 - val_loss: 0.9048 - val_acc: 0.6467\n",
            "Epoch 410/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4093 - acc: 0.8047 - val_loss: 1.0562 - val_acc: 0.6600\n",
            "Epoch 411/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4514 - acc: 0.7732 - val_loss: 0.9334 - val_acc: 0.7133\n",
            "Epoch 412/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4667 - acc: 0.8253 - val_loss: 0.7726 - val_acc: 0.7133\n",
            "Epoch 413/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4314 - acc: 0.8252 - val_loss: 0.7179 - val_acc: 0.7267\n",
            "Epoch 414/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4363 - acc: 0.8064 - val_loss: 0.9912 - val_acc: 0.6467\n",
            "Epoch 415/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4414 - acc: 0.8294 - val_loss: 0.9010 - val_acc: 0.6933\n",
            "Epoch 416/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4896 - acc: 0.7754 - val_loss: 0.7829 - val_acc: 0.7000\n",
            "Epoch 417/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4630 - acc: 0.8204 - val_loss: 0.9402 - val_acc: 0.6933\n",
            "Epoch 418/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4444 - acc: 0.8075 - val_loss: 0.8049 - val_acc: 0.6933\n",
            "Epoch 419/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4369 - acc: 0.8279 - val_loss: 0.8404 - val_acc: 0.6933\n",
            "Epoch 420/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4015 - acc: 0.8318 - val_loss: 1.0100 - val_acc: 0.6667\n",
            "Epoch 421/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4853 - acc: 0.7957 - val_loss: 0.9267 - val_acc: 0.6933\n",
            "Epoch 422/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4540 - acc: 0.8126 - val_loss: 0.7891 - val_acc: 0.7133\n",
            "Epoch 423/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4170 - acc: 0.8376 - val_loss: 0.9793 - val_acc: 0.7333\n",
            "Epoch 424/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4514 - acc: 0.7735 - val_loss: 1.0538 - val_acc: 0.6533\n",
            "Epoch 425/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4443 - acc: 0.8060 - val_loss: 1.0968 - val_acc: 0.6733\n",
            "Epoch 426/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4340 - acc: 0.8254 - val_loss: 0.7004 - val_acc: 0.6867\n",
            "Epoch 427/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4480 - acc: 0.7937 - val_loss: 1.1439 - val_acc: 0.7133\n",
            "Epoch 428/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.4746 - acc: 0.7804 - val_loss: 1.0228 - val_acc: 0.7200\n",
            "Epoch 429/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4594 - acc: 0.7703 - val_loss: 0.9508 - val_acc: 0.6733\n",
            "Epoch 430/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4969 - acc: 0.7986 - val_loss: 0.9583 - val_acc: 0.6933\n",
            "Epoch 431/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4588 - acc: 0.8046 - val_loss: 0.8997 - val_acc: 0.7400\n",
            "Epoch 432/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4401 - acc: 0.8324 - val_loss: 1.0972 - val_acc: 0.6533\n",
            "Epoch 433/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4379 - acc: 0.8126 - val_loss: 0.9293 - val_acc: 0.7200\n",
            "Epoch 434/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4674 - acc: 0.7745 - val_loss: 0.8859 - val_acc: 0.7333\n",
            "Epoch 435/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.5180 - acc: 0.7836 - val_loss: 0.9283 - val_acc: 0.7200\n",
            "Epoch 436/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4192 - acc: 0.8321 - val_loss: 0.9884 - val_acc: 0.6867\n",
            "Epoch 437/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4283 - acc: 0.8344 - val_loss: 1.0117 - val_acc: 0.7200\n",
            "Epoch 438/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4435 - acc: 0.8436 - val_loss: 1.0090 - val_acc: 0.6867\n",
            "Epoch 439/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4341 - acc: 0.8253 - val_loss: 1.0940 - val_acc: 0.7000\n",
            "Epoch 440/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4268 - acc: 0.8152 - val_loss: 0.8338 - val_acc: 0.7267\n",
            "Epoch 441/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4711 - acc: 0.7901 - val_loss: 0.8102 - val_acc: 0.7067\n",
            "Epoch 442/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4926 - acc: 0.7764 - val_loss: 0.8642 - val_acc: 0.7000\n",
            "Epoch 443/3000\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.4497 - acc: 0.8072 - val_loss: 0.9453 - val_acc: 0.6333\n",
            "Epoch 444/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4533 - acc: 0.7966 - val_loss: 1.2016 - val_acc: 0.6667\n",
            "Epoch 445/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4964 - acc: 0.8134 - val_loss: 0.8834 - val_acc: 0.6200\n",
            "Epoch 446/3000\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.3992 - acc: 0.8498 - val_loss: 1.2554 - val_acc: 0.6333\n",
            "Epoch 447/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4733 - acc: 0.8011 - val_loss: 0.9479 - val_acc: 0.6733\n",
            "Epoch 448/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4671 - acc: 0.7962 - val_loss: 0.8183 - val_acc: 0.7800\n",
            "Epoch 449/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4196 - acc: 0.8224 - val_loss: 0.9300 - val_acc: 0.7067\n",
            "Epoch 450/3000\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.5155 - acc: 0.8039 - val_loss: 0.9494 - val_acc: 0.6800\n",
            "Epoch 451/3000\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.4529 - acc: 0.8066 - val_loss: 0.7230 - val_acc: 0.7333\n",
            "Epoch 452/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4822 - acc: 0.7873 - val_loss: 0.9643 - val_acc: 0.6867\n",
            "Epoch 453/3000\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 0.5304 - acc: 0.7953 - val_loss: 0.8834 - val_acc: 0.7267\n",
            "Epoch 454/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4204 - acc: 0.8223 - val_loss: 0.7416 - val_acc: 0.7000\n",
            "Epoch 455/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4405 - acc: 0.8095 - val_loss: 0.8654 - val_acc: 0.7267\n",
            "Epoch 456/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.5076 - acc: 0.8023 - val_loss: 0.6356 - val_acc: 0.7533\n",
            "Epoch 457/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.5390 - acc: 0.7958 - val_loss: 0.7998 - val_acc: 0.6600\n",
            "Epoch 458/3000\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 0.4308 - acc: 0.7981 - val_loss: 1.0207 - val_acc: 0.6533\n",
            "Epoch 459/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4076 - acc: 0.8265 - val_loss: 0.9373 - val_acc: 0.7133\n",
            "Epoch 460/3000\n",
            "40/40 [==============================] - 11s 276ms/step - loss: 0.4239 - acc: 0.8365 - val_loss: 1.1199 - val_acc: 0.6000\n",
            "Epoch 461/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4593 - acc: 0.8299 - val_loss: 0.9038 - val_acc: 0.7333\n",
            "Epoch 462/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4931 - acc: 0.7856 - val_loss: 0.8115 - val_acc: 0.7133\n",
            "Epoch 463/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4758 - acc: 0.7742 - val_loss: 0.8715 - val_acc: 0.6933\n",
            "Epoch 464/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4816 - acc: 0.7807 - val_loss: 0.8268 - val_acc: 0.6933\n",
            "Epoch 465/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4701 - acc: 0.7938 - val_loss: 0.8269 - val_acc: 0.6733\n",
            "Epoch 466/3000\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.4100 - acc: 0.8354 - val_loss: 0.8980 - val_acc: 0.7067\n",
            "Epoch 467/3000\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.4507 - acc: 0.8262 - val_loss: 0.9613 - val_acc: 0.6800\n",
            "Epoch 468/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4670 - acc: 0.7892 - val_loss: 0.9965 - val_acc: 0.6867\n",
            "Epoch 469/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4326 - acc: 0.8219 - val_loss: 0.8495 - val_acc: 0.6867\n",
            "Epoch 470/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4508 - acc: 0.7858 - val_loss: 0.9529 - val_acc: 0.6867\n",
            "Epoch 471/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4217 - acc: 0.8287 - val_loss: 0.9304 - val_acc: 0.6533\n",
            "Epoch 472/3000\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.4442 - acc: 0.8177 - val_loss: 0.8454 - val_acc: 0.6867\n",
            "Epoch 473/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4419 - acc: 0.7994 - val_loss: 0.9744 - val_acc: 0.6733\n",
            "Epoch 474/3000\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.4860 - acc: 0.7512 - val_loss: 0.8664 - val_acc: 0.7400\n",
            "Epoch 475/3000\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.4485 - acc: 0.8197 - val_loss: 1.0150 - val_acc: 0.6667\n",
            "Epoch 476/3000\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 0.4364 - acc: 0.8030 - val_loss: 0.9983 - val_acc: 0.6933\n",
            "Epoch 477/3000\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 0.4341 - acc: 0.8443 - val_loss: 0.9881 - val_acc: 0.6667\n",
            "Epoch 478/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4361 - acc: 0.8114 - val_loss: 1.1683 - val_acc: 0.6333\n",
            "Epoch 479/3000\n",
            "40/40 [==============================] - 11s 275ms/step - loss: 0.4399 - acc: 0.8111 - val_loss: 0.8942 - val_acc: 0.6933\n",
            "Epoch 480/3000\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 0.4304 - acc: 0.8371 - val_loss: 0.9745 - val_acc: 0.6333\n",
            "Epoch 481/3000\n",
            "40/40 [==============================] - 12s 296ms/step - loss: 0.4816 - acc: 0.7661 - val_loss: 0.9837 - val_acc: 0.6467\n",
            "Epoch 482/3000\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.4093 - acc: 0.8388 - val_loss: 0.9705 - val_acc: 0.7267\n",
            "Epoch 483/3000\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.4466 - acc: 0.8203 - val_loss: 0.9912 - val_acc: 0.7067\n",
            "Epoch 484/3000\n",
            "40/40 [==============================] - 11s 287ms/step - loss: 0.4247 - acc: 0.8319 - val_loss: 0.7814 - val_acc: 0.7333\n",
            "Epoch 485/3000\n",
            "40/40 [==============================] - 12s 289ms/step - loss: 0.4691 - acc: 0.7938 - val_loss: 0.8865 - val_acc: 0.7067\n",
            "Epoch 486/3000\n",
            "40/40 [==============================] - 12s 290ms/step - loss: 0.4227 - acc: 0.8183 - val_loss: 0.7175 - val_acc: 0.7533\n",
            "Epoch 487/3000\n",
            "40/40 [==============================] - 12s 295ms/step - loss: 0.4352 - acc: 0.8064 - val_loss: 0.8910 - val_acc: 0.7133\n",
            "Epoch 488/3000\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.4130 - acc: 0.8430 - val_loss: 0.7680 - val_acc: 0.7000\n",
            "Epoch 489/3000\n",
            "40/40 [==============================] - 12s 301ms/step - loss: 0.4801 - acc: 0.7985 - val_loss: 0.8324 - val_acc: 0.6800\n",
            "Epoch 490/3000\n",
            "40/40 [==============================] - 12s 293ms/step - loss: 0.4327 - acc: 0.8344 - val_loss: 0.8921 - val_acc: 0.7333\n",
            "Epoch 491/3000\n",
            "40/40 [==============================] - 12s 291ms/step - loss: 0.4631 - acc: 0.7989 - val_loss: 0.8730 - val_acc: 0.6800\n",
            "Epoch 492/3000\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4508 - acc: 0.7752"
          ]
        }
      ],
      "source": [
        "hist = model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch = 40,\n",
        "  epochs = 3000,\n",
        "  validation_data = val_generator,\n",
        "  validation_steps= 15\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 웰시코기 학습 4 후기\n",
        "- 과적합을 막지 못했다."
      ],
      "metadata": {
        "id": "0SZjnkrBR7KM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 학습 후기\n",
        "- 우선 성능이 매우 떨어진다.\n",
        "- 성능을 개선하기 위해 이미지 증식을 활용했지만, 과적합을 피할 수 없었다.\n",
        "    - 과적합을 제거하기 위한 노력\n",
        "        - DropOut 층 추가\n",
        "        - DropOut + L2 규제 2회 추가\n",
        "- 이미지 세트 자체가 문제일 수도 있다.\n",
        "- 멘토님께 다양한 이미지 전처리를 시도하도록 지도 받음\n",
        "    - https://lsjsj92.tistory.com/355\n",
        "    - https://kcy51156.tistory.com/55\n",
        "    - https://ivo-lee.tistory.com/91\n",
        "    - https://lsjsj92.tistory.com/355\n",
        "- 다양한 이미지 분석 딥러닝 알고리즘 활용하도록 지도 받음\n",
        "    - pytorch 사용해보자!\n",
        "        - https://ybworld.tistory.com/130\n",
        "        - https://ybworld.tistory.com/129"
      ],
      "metadata": {
        "id": "F2_EvaQxS6Yx"
      }
    }
  ]
}